--- .\app.py	(original)
+++ .\app.py	(reformatted)
@@ -267,6 +267,7 @@
 
     return "Started generation"
 
+
 @app.route("/participation")
 def index():
     return render_template("index.html")
@@ -462,24 +463,29 @@
 @app.route("/user/<username>", methods=["GET", "POST"])
 def user_id(username):
     if request.method == "POST":
-        return send_from_directory(CACHE_DIRECTORY, filename = username + ".pdf")
+        return send_from_directory(CACHE_DIRECTORY, filename=username + ".pdf")
     else:
         common.connect_db()
-        projects = list(scrape.Project.objects(author = username.lower()))
+        projects = list(scrape.Project.objects(author=username.lower()))
         studios = dict()
 
         keep_projects = list()
         for i, project in enumerate(projects):
             if project["studio_id"] not in studios:
-                studio = scrape.Studio.objects(studio_id = project["studio_id"]).first()
-                
+                studio = scrape.Studio.objects(
+                    studio_id=project["studio_id"]).first()
+
                 if studio is not None:
                     studios[project["studio_id"]] = studio
                     keep_projects.append(project)
             else:
                 keep_projects.append(project)
 
-        return render_template("username.html", projects=keep_projects, studios=studios, username=username)
+        return render_template("username.html",
+                               projects=keep_projects,
+                               studios=studios,
+                               username=username)
+
 
 @app.route("/prompts", methods=["GET"])
 @cache.cached(timeout=600, unless=authentication.session_active)
@@ -528,7 +534,8 @@
             data = json.load(f)
 
         for i, item in enumerate(data["content"]):
-            data["content"][i] = common.md(item) if isinstance(item, str) else item
+            data["content"][i] = common.md(item) if isinstance(item,
+                                                               str) else item
 
         return render_template("summary.html", data=data)
     else:
@@ -539,7 +546,8 @@
 @app.route("/summary/image")
 def summary_image():
     try:
-        with open("{}/cache/data/projects.jpg".format(PROJECT_DIRECTORY), "rb") as f:
+        with open("{}/cache/data/projects.jpg".format(PROJECT_DIRECTORY),
+                  "rb") as f:
             return f.read()
     except:
         return "Not found", 404
@@ -550,6 +558,7 @@
 def generate_summary():
     summary.generate_summary_page.delay()
     return "Started generation"
+
 
 # Static pages -- About, Strategies, Signup, Research
 @app.route("/")
--- .\docs\conf.py	(original)
+++ .\docs\conf.py	(reformatted)
@@ -32,16 +32,12 @@
 author = 'Creative Computing Lab'
 master_doc = 'index'
 
-
 # -- General configuration ---------------------------------------------------
 
 # Add any Sphinx extension module names here, as strings. They can be
 # extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
 # ones.
-extensions = [
-    'sphinx.ext.autodoc',
-    'sphinx.ext.napoleon'
-]
+extensions = ['sphinx.ext.autodoc', 'sphinx.ext.napoleon']
 
 # Add any paths that contain templates here, relative to this directory.
 templates_path = ['_templates']
@@ -50,7 +46,6 @@
 # directories to ignore when looking for source files.
 # This pattern also affects html_static_path and html_extra_path.
 exclude_patterns = ['_build', 'Thumbs.db', '.DS_Store']
-
 
 # -- Options for HTML output -------------------------------------------------
 
--- .\env\Lib\abc.py	(original)
+++ .\env\Lib\abc.py	(reformatted)
@@ -101,9 +101,14 @@
 
 
 try:
-    from _abc import (get_cache_token, _abc_init, _abc_register,
-                      _abc_instancecheck, _abc_subclasscheck, _get_dump,
-                      _reset_registry, _reset_caches)
+    from _abc import (get_cache_token,
+                      _abc_init,
+                      _abc_register,
+                      _abc_instancecheck,
+                      _abc_subclasscheck,
+                      _get_dump,
+                      _reset_registry,
+                      _reset_caches)
 except ImportError:
     from _py_abc import ABCMeta, get_cache_token
     ABCMeta.__module__ = 'abc'
@@ -146,7 +151,9 @@
             """Debug helper to print the ABC registry."""
             print(f"Class: {cls.__module__}.{cls.__qualname__}", file=file)
             print(f"Inv. counter: {get_cache_token()}", file=file)
-            (_abc_registry, _abc_cache, _abc_negative_cache,
+            (_abc_registry,
+             _abc_cache,
+             _abc_negative_cache,
              _abc_negative_cache_version) = _get_dump(cls)
             print(f"_abc_registry: {_abc_registry!r}", file=file)
             print(f"_abc_cache: {_abc_cache!r}", file=file)
--- .\env\Lib\base64.py	(original)
+++ .\env\Lib\base64.py	(reformatted)
@@ -350,9 +350,7 @@
         result = _A85START + result
     if wrapcol:
         wrapcol = max(2 if adobe else 1, wrapcol)
-        chunks = [
-            result[i:i + wrapcol] for i in range(0, len(result), wrapcol)
-        ]
+        chunks = [result[i:i + wrapcol] for i in range(0, len(result), wrapcol)]
         if adobe:
             if len(chunks[-1]) + 2 > wrapcol:
                 chunks.append(b'')
@@ -489,8 +487,8 @@
         try:
             out.append(packI(acc))
         except struct.error:
-            raise ValueError('base85 overflow in hunk starting at byte %d' %
-                             i) from None
+            raise ValueError('base85 overflow in hunk starting at byte %d'
+                             % i) from None
 
     result = b''.join(out)
     if padding:
@@ -539,11 +537,13 @@
         raise TypeError(msg) from err
     if m.format not in ('c', 'b', 'B'):
         msg = ("expected single byte elements, not %r from %s" %
-               (m.format, s.__class__.__name__))
+               (m.format,
+                s.__class__.__name__))
         raise TypeError(msg)
     if m.ndim != 1:
         msg = ("expected 1-D data, not %d-D data from %s" %
-               (m.ndim, s.__class__.__name__))
+               (m.ndim,
+                s.__class__.__name__))
         raise TypeError(msg)
 
 
@@ -563,7 +563,9 @@
     import warnings
     warnings.warn(
         "encodestring() is a deprecated alias since 3.1, "
-        "use encodebytes()", DeprecationWarning, 2)
+        "use encodebytes()",
+        DeprecationWarning,
+        2)
     return encodebytes(s)
 
 
@@ -578,7 +580,9 @@
     import warnings
     warnings.warn(
         "decodestring() is a deprecated alias since Python 3.1, "
-        "use decodebytes()", DeprecationWarning, 2)
+        "use decodebytes()",
+        DeprecationWarning,
+        2)
     return decodebytes(s)
 
 
@@ -598,9 +602,12 @@
         sys.exit(2)
     func = encode
     for o, a in opts:
-        if o == '-e': func = encode
-        if o == '-d': func = decode
-        if o == '-u': func = decode
+        if o == '-e':
+            func = encode
+        if o == '-d':
+            func = decode
+        if o == '-u':
+            func = decode
         if o == '-t':
             test()
             return
--- .\env\Lib\bisect.py	(original)
+++ .\env\Lib\bisect.py	(reformatted)
@@ -16,8 +16,10 @@
         hi = len(a)
     while lo < hi:
         mid = (lo + hi) // 2
-        if x < a[mid]: hi = mid
-        else: lo = mid + 1
+        if x < a[mid]:
+            hi = mid
+        else:
+            lo = mid + 1
     a.insert(lo, x)
 
 
@@ -38,8 +40,10 @@
         hi = len(a)
     while lo < hi:
         mid = (lo + hi) // 2
-        if x < a[mid]: hi = mid
-        else: lo = mid + 1
+        if x < a[mid]:
+            hi = mid
+        else:
+            lo = mid + 1
     return lo
 
 
@@ -58,8 +62,10 @@
         hi = len(a)
     while lo < hi:
         mid = (lo + hi) // 2
-        if a[mid] < x: lo = mid + 1
-        else: hi = mid
+        if a[mid] < x:
+            lo = mid + 1
+        else:
+            hi = mid
     a.insert(lo, x)
 
 
@@ -80,8 +86,10 @@
         hi = len(a)
     while lo < hi:
         mid = (lo + hi) // 2
-        if a[mid] < x: lo = mid + 1
-        else: hi = mid
+        if a[mid] < x:
+            lo = mid + 1
+        else:
+            hi = mid
     return lo
 
 
--- .\env\Lib\codecs.py	(original)
+++ .\env\Lib\codecs.py	(reformatted)
@@ -18,16 +18,50 @@
     raise SystemError('Failed to load the builtin codecs: %s' % why)
 
 __all__ = [
-    "register", "lookup", "open", "EncodedFile", "BOM", "BOM_BE", "BOM_LE",
-    "BOM32_BE", "BOM32_LE", "BOM64_BE", "BOM64_LE", "BOM_UTF8", "BOM_UTF16",
-    "BOM_UTF16_LE", "BOM_UTF16_BE", "BOM_UTF32", "BOM_UTF32_LE",
-    "BOM_UTF32_BE", "CodecInfo", "Codec", "IncrementalEncoder",
-    "IncrementalDecoder", "StreamReader", "StreamWriter", "StreamReaderWriter",
-    "StreamRecoder", "getencoder", "getdecoder", "getincrementalencoder",
-    "getincrementaldecoder", "getreader", "getwriter", "encode", "decode",
-    "iterencode", "iterdecode", "strict_errors", "ignore_errors",
-    "replace_errors", "xmlcharrefreplace_errors", "backslashreplace_errors",
-    "namereplace_errors", "register_error", "lookup_error"
+    "register",
+    "lookup",
+    "open",
+    "EncodedFile",
+    "BOM",
+    "BOM_BE",
+    "BOM_LE",
+    "BOM32_BE",
+    "BOM32_LE",
+    "BOM64_BE",
+    "BOM64_LE",
+    "BOM_UTF8",
+    "BOM_UTF16",
+    "BOM_UTF16_LE",
+    "BOM_UTF16_BE",
+    "BOM_UTF32",
+    "BOM_UTF32_LE",
+    "BOM_UTF32_BE",
+    "CodecInfo",
+    "Codec",
+    "IncrementalEncoder",
+    "IncrementalDecoder",
+    "StreamReader",
+    "StreamWriter",
+    "StreamReaderWriter",
+    "StreamRecoder",
+    "getencoder",
+    "getdecoder",
+    "getincrementalencoder",
+    "getincrementaldecoder",
+    "getreader",
+    "getwriter",
+    "encode",
+    "decode",
+    "iterencode",
+    "iterdecode",
+    "strict_errors",
+    "ignore_errors",
+    "replace_errors",
+    "xmlcharrefreplace_errors",
+    "backslashreplace_errors",
+    "namereplace_errors",
+    "register_error",
+    "lookup_error"
 ]
 
 ### Constants
@@ -766,13 +800,7 @@
     data_encoding = 'unknown'
     file_encoding = 'unknown'
 
-    def __init__(self,
-                 stream,
-                 encode,
-                 decode,
-                 Reader,
-                 Writer,
-                 errors='strict'):
+    def __init__(self, stream, encode, decode, Reader, Writer, errors='strict'):
         """ Creates a StreamRecoder instance which implements a two-way
             conversion: encode and decode work on the frontend (the
             data visible to .read() and .write()) while Reader and Writer
@@ -895,8 +923,7 @@
     if encoding is None:
         return file
     info = lookup(encoding)
-    srw = StreamReaderWriter(file, info.streamreader, info.streamwriter,
-                             errors)
+    srw = StreamReaderWriter(file, info.streamreader, info.streamwriter, errors)
     # Add attributes to simplify introspection
     srw.encoding = encoding
     return srw
@@ -930,8 +957,12 @@
         file_encoding = data_encoding
     data_info = lookup(data_encoding)
     file_info = lookup(file_encoding)
-    sr = StreamRecoder(file, data_info.encode, data_info.decode,
-                       file_info.streamreader, file_info.streamwriter, errors)
+    sr = StreamRecoder(file,
+                       data_info.encode,
+                       data_info.decode,
+                       file_info.streamreader,
+                       file_info.streamwriter,
+                       errors)
     # Add attributes to simplify introspection
     sr.data_encoding = data_encoding
     sr.file_encoding = file_encoding
--- .\env\Lib\copy.py	(original)
+++ .\env\Lib\copy.py	(reformatted)
@@ -117,9 +117,23 @@
     return x
 
 
-for t in (type(None), int, float, bool, complex, str, tuple, bytes, frozenset,
-          type, range, slice, types.BuiltinFunctionType, type(Ellipsis),
-          type(NotImplemented), types.FunctionType, weakref.ref):
+for t in (type(None),
+          int,
+          float,
+          bool,
+          complex,
+          str,
+          tuple,
+          bytes,
+          frozenset,
+          type,
+          range,
+          slice,
+          types.BuiltinFunctionType,
+          type(Ellipsis),
+          type(NotImplemented),
+          types.FunctionType,
+          weakref.ref):
     d[t] = _copy_immutable
 t = getattr(types, "CodeType", None)
 if t is not None:
@@ -179,8 +193,8 @@
                         if reductor:
                             rv = reductor()
                         else:
-                            raise Error("un(deep)copyable object of type %s" %
-                                        cls)
+                            raise Error("un(deep)copyable object of type %s"
+                                        % cls)
                 if isinstance(rv, str):
                     y = x
                 else:
--- .\env\Lib\copyreg.py	(original)
+++ .\env\Lib\copyreg.py	(reformatted)
@@ -5,7 +5,10 @@
 """
 
 __all__ = [
-    "pickle", "constructor", "add_extension", "remove_extension",
+    "pickle",
+    "constructor",
+    "add_extension",
+    "remove_extension",
     "clear_extension_cache"
 ]
 
@@ -77,9 +80,8 @@
         getstate = self.__getstate__
     except AttributeError:
         if getattr(self, "__slots__", None):
-            raise TypeError(
-                "a class that defines __slots__ without "
-                "defining __getstate__ cannot be pickled") from None
+            raise TypeError("a class that defines __slots__ without "
+                            "defining __getstate__ cannot be pickled") from None
         try:
             dict = self.__dict__
         except AttributeError:
@@ -185,10 +187,12 @@
         return  # Redundant registrations are benign
     if key in _extension_registry:
         raise ValueError("key %s is already registered with code %s" %
-                         (key, _extension_registry[key]))
+                         (key,
+                          _extension_registry[key]))
     if code in _inverted_registry:
         raise ValueError("code %s is already in use for key %s" %
-                         (code, _inverted_registry[code]))
+                         (code,
+                          _inverted_registry[code]))
     _extension_registry[key] = code
     _inverted_registry[code] = key
 
--- .\env\Lib\enum.py	(original)
+++ .\env\Lib\enum.py	(reformatted)
@@ -20,8 +20,11 @@
 
 def _is_descriptor(obj):
     """Returns True if obj is a descriptor, False otherwise."""
-    return (hasattr(obj, '__get__') or hasattr(obj, '__set__')
-            or hasattr(obj, '__delete__'))
+    return (hasattr(obj,
+                    '__get__') or hasattr(obj,
+                                          '__set__')
+            or hasattr(obj,
+                       '__delete__'))
 
 
 def _is_dunder(name):
@@ -98,7 +101,8 @@
                 if already:
                     raise ValueError(
                         '_ignore_ cannot specify already set names: %r' %
-                        (already, ))
+                        (already,
+                         ))
         elif _is_dunder(key):
             if key == '__order__':
                 key = '_order_'
@@ -114,7 +118,10 @@
             if isinstance(value, auto):
                 if value.value == _auto_null:
                     value.value = self._generate_next_value(
-                        key, 1, len(self._member_names), self._last_values[:])
+                        key,
+                        1,
+                        len(self._member_names),
+                        self._last_values[:])
                 value = value.value
             self._member_names.append(key)
             self._last_values.append(value)
@@ -137,7 +144,9 @@
         member_type, first_enum = metacls._get_mixins_(bases)
         if first_enum is not None:
             enum_dict['_generate_next_value_'] = getattr(
-                first_enum, '_generate_next_value_', None)
+                first_enum,
+                '_generate_next_value_',
+                None)
         return enum_dict
 
     def __new__(metacls, cls, bases, classdict):
@@ -169,8 +178,8 @@
             'mro',
         }
         if invalid_names:
-            raise ValueError('Invalid enum member name: {0}'.format(
-                ','.join(invalid_names)))
+            raise ValueError('Invalid enum member name: {0}'.format(','.join(
+                invalid_names)))
 
         # create a default docstring if one has not been provided
         if '__doc__' not in classdict:
@@ -186,8 +195,9 @@
         # if we can take the shortcut of storing members in the class dict
         dynamic_attributes = {
             k
-            for c in enum_class.mro() for k, v in c.__dict__.items()
-            if isinstance(v, DynamicClassAttribute)
+            for c in enum_class.mro() for k,
+            v in c.__dict__.items() if isinstance(v,
+                                                  DynamicClassAttribute)
         }
 
         # Reverse value->name map for hashable values.
@@ -205,8 +215,10 @@
         # pickle over __reduce__, and it handles all pickle protocols.
         if '__reduce_ex__' not in classdict:
             if member_type is not object:
-                methods = ('__getnewargs_ex__', '__getnewargs__',
-                           '__reduce_ex__', '__reduce__')
+                methods = ('__getnewargs_ex__',
+                           '__getnewargs__',
+                           '__reduce_ex__',
+                           '__reduce__')
                 if not any(m in member_type.__dict__ for m in methods):
                     _make_class_unpicklable(enum_class)
 
@@ -340,20 +352,24 @@
             import warnings
             warnings.warn(
                 "using non-Enums in containment checks will raise "
-                "TypeError in Python 3.8", DeprecationWarning, 2)
+                "TypeError in Python 3.8",
+                DeprecationWarning,
+                2)
         return isinstance(member, cls) and member._name_ in cls._member_map_
 
     def __delattr__(cls, attr):
         # nicer error message when someone tries to delete an attribute
         # (see issue19025).
         if attr in cls._member_map_:
-            raise AttributeError("%s: cannot delete Enum member." %
-                                 cls.__name__)
+            raise AttributeError("%s: cannot delete Enum member."
+                                 % cls.__name__)
         super().__delattr__(attr)
 
     def __dir__(self):
-        return (['__class__', '__doc__', '__members__', '__module__'] +
-                self._member_names_)
+        return (['__class__',
+                 '__doc__',
+                 '__members__',
+                 '__module__'] + self._member_names_)
 
     def __getattr__(cls, name):
         """Return the enum member matching `name`
@@ -394,8 +410,7 @@
         return "<enum %r>" % cls.__name__
 
     def __reversed__(cls):
-        return (cls._member_map_[name]
-                for name in reversed(cls._member_names_))
+        return (cls._member_map_[name] for name in reversed(cls._member_names_))
 
     def __setattr__(cls, name, value):
         """Block attempts to reassign Enum members.
@@ -438,12 +453,17 @@
         if isinstance(names, str):
             names = names.replace(',', ' ').split()
         if isinstance(names,
-                      (tuple, list)) and names and isinstance(names[0], str):
+                      (tuple,
+                       list)) and names and isinstance(names[0],
+                                                       str):
             original_names, names = names, []
             last_values = []
             for count, name in enumerate(original_names):
                 value = first_enum._generate_next_value_(
-                    name, start, count, last_values[:])
+                    name,
+                    start,
+                    count,
+                    last_values[:])
                 last_values.append(value)
                 names.append((name, value))
 
@@ -590,7 +610,8 @@
             elif exc is None:
                 exc = TypeError(
                     'error in %s._missing_: returned %r instead of None or a valid member'
-                    % (cls.__name__, result))
+                    % (cls.__name__,
+                       result))
             exc.__context__ = ve_exc
             raise exc
 
@@ -608,7 +629,8 @@
         raise ValueError("%r is not a valid %s" % (value, cls.__name__))
 
     def __repr__(self):
-        return "<%s.%s: %r>" % (self.__class__.__name__, self._name_,
+        return "<%s.%s: %r>" % (self.__class__.__name__,
+                                self._name_,
                                 self._value_)
 
     def __str__(self):
@@ -679,8 +701,8 @@
         # for a consistent reverse mapping of number to name when there
         # are multiple names for the same number rather than varying
         # between runs due to hash randomization of the module dictionary.
-        members = [(name, source[name]) for name in source.keys()
-                   if filter(name)]
+        members = [(name,
+                    source[name]) for name in source.keys() if filter(name)]
         try:
             # sort by value
             members.sort(key=lambda t: (t[1], t[0]))
@@ -720,8 +742,7 @@
                 high_bit = _high_bit(last_value)
                 break
             except Exception:
-                raise TypeError('Invalid Flag value: %r' %
-                                last_value) from None
+                raise TypeError('Invalid Flag value: %r' % last_value) from None
         return 2**(high_bit + 1)
 
     @classmethod
@@ -744,8 +765,7 @@
             # verify all bits are accounted for
             _, extra_flags = _decompose(cls, value)
             if extra_flags:
-                raise ValueError("%r is not a valid %s" %
-                                 (value, cls.__name__))
+                raise ValueError("%r is not a valid %s" % (value, cls.__name__))
             # construct a singleton enum pseudo-member
             pseudo_member = object.__new__(cls)
             pseudo_member._name_ = None
@@ -753,7 +773,8 @@
             # use setdefault in case another thread already created a composite
             # with this value
             pseudo_member = cls._value2member_map_.setdefault(
-                value, pseudo_member)
+                value,
+                pseudo_member)
         return pseudo_member
 
     def __contains__(self, other):
@@ -761,7 +782,9 @@
             import warnings
             warnings.warn(
                 "using non-Flags in containment checks will raise "
-                "TypeError in Python 3.8", DeprecationWarning, 2)
+                "TypeError in Python 3.8",
+                DeprecationWarning,
+                2)
             return False
         return other._value_ & self._value_ == other._value_
 
@@ -852,7 +875,8 @@
                 # use setdefault in case another thread already created a composite
                 # with this value
                 pseudo_member = cls._value2member_map_.setdefault(
-                    value, pseudo_member)
+                    value,
+                    pseudo_member)
         return pseudo_member
 
     def __or__(self, other):
@@ -893,9 +917,11 @@
             duplicates.append((name, member.name))
     if duplicates:
         alias_details = ', '.join(
-            ["%s -> %s" % (alias, name) for (alias, name) in duplicates])
-        raise ValueError('duplicate values found in %r: %s' %
-                         (enumeration, alias_details))
+            ["%s -> %s" % (alias,
+                           name) for (alias,
+                                      name) in duplicates])
+        raise ValueError('duplicate values found in %r: %s' % (enumeration,
+                                                               alias_details))
     return enumeration
 
 
@@ -909,13 +935,15 @@
     #             members added to it
     if negative:
         # only check for named flags
-        flags_to_check = [(m, v)
-                          for v, m in list(flag._value2member_map_.items())
+        flags_to_check = [(m,
+                           v) for v,
+                          m in list(flag._value2member_map_.items())
                           if m.name is not None]
     else:
         # check for named flags and powers-of-two flags
-        flags_to_check = [(m, v)
-                          for v, m in list(flag._value2member_map_.items())
+        flags_to_check = [(m,
+                           v) for v,
+                          m in list(flag._value2member_map_.items())
                           if m.name is not None or _power_of_two(v)]
     members = []
     for member, member_value in flags_to_check:
--- .\env\Lib\fnmatch.py	(original)
+++ .\env\Lib\fnmatch.py	(reformatted)
@@ -118,8 +118,9 @@
                     # Escape backslashes and hyphens for set difference (--).
                     # Hyphens that create ranges shouldn't be escaped.
                     stuff = '-'.join(
-                        s.replace('\\', r'\\').replace('-', r'\-')
-                        for s in chunks)
+                        s.replace('\\',
+                                  r'\\').replace('-',
+                                                 r'\-') for s in chunks)
                 # Escape set operations (&&, ~~ and ||).
                 stuff = re.sub(r'([&~|])', r'\\\1', stuff)
                 i = j + 1
--- .\env\Lib\functools.py	(original)
+++ .\env\Lib\functools.py	(reformatted)
@@ -10,9 +10,17 @@
 # See C source code for _functools credits/copyright
 
 __all__ = [
-    'update_wrapper', 'wraps', 'WRAPPER_ASSIGNMENTS', 'WRAPPER_UPDATES',
-    'total_ordering', 'cmp_to_key', 'lru_cache', 'reduce', 'partial',
-    'partialmethod', 'singledispatch'
+    'update_wrapper',
+    'wraps',
+    'WRAPPER_ASSIGNMENTS',
+    'WRAPPER_UPDATES',
+    'total_ordering',
+    'cmp_to_key',
+    'lru_cache',
+    'reduce',
+    'partial',
+    'partialmethod',
+    'singledispatch'
 ]
 
 try:
@@ -32,7 +40,10 @@
 # update_wrapper() and wraps() are tools to help write
 # wrapper functions that can handle naive introspection
 
-WRAPPER_ASSIGNMENTS = ('__module__', '__name__', '__qualname__', '__doc__',
+WRAPPER_ASSIGNMENTS = ('__module__',
+                       '__name__',
+                       '__qualname__',
+                       '__doc__',
                        '__annotations__')
 WRAPPER_UPDATES = ('__dict__', )
 
@@ -186,14 +197,30 @@
 
 
 _convert = {
-    '__lt__': [('__gt__', _gt_from_lt), ('__le__', _le_from_lt),
-               ('__ge__', _ge_from_lt)],
-    '__le__': [('__ge__', _ge_from_le), ('__lt__', _lt_from_le),
-               ('__gt__', _gt_from_le)],
-    '__gt__': [('__lt__', _lt_from_gt), ('__ge__', _ge_from_gt),
-               ('__le__', _le_from_gt)],
-    '__ge__': [('__le__', _le_from_ge), ('__gt__', _gt_from_ge),
-               ('__lt__', _lt_from_ge)]
+    '__lt__': [('__gt__',
+                _gt_from_lt),
+               ('__le__',
+                _le_from_lt),
+               ('__ge__',
+                _ge_from_lt)],
+    '__le__': [('__ge__',
+                _ge_from_le),
+               ('__lt__',
+                _lt_from_le),
+               ('__gt__',
+                _gt_from_le)],
+    '__gt__': [('__lt__',
+                _lt_from_gt),
+               ('__ge__',
+                _ge_from_gt),
+               ('__le__',
+                _le_from_gt)],
+    '__ge__': [('__le__',
+                _le_from_ge),
+               ('__gt__',
+                _gt_from_ge),
+               ('__lt__',
+                _lt_from_ge)]
 }
 
 
@@ -202,8 +229,11 @@
     # Find user-defined comparisons (not those inherited from object).
     roots = {
         op
-        for op in _convert
-        if getattr(cls, op, None) is not getattr(object, op, None)
+        for op in _convert if getattr(cls,
+                                      op,
+                                      None) is not getattr(object,
+                                                           op,
+                                                           None)
     }
     if not roots:
         raise ValueError(
@@ -269,8 +299,7 @@
 
     def __new__(*args, **keywords):
         if not args:
-            raise TypeError(
-                "descriptor '__new__' of partial needs an argument")
+            raise TypeError("descriptor '__new__' of partial needs an argument")
         if len(args) < 2:
             raise TypeError("type 'partial' takes at least one argument")
         cls, func, *args = args
@@ -322,9 +351,12 @@
         if len(state) != 4:
             raise TypeError(f"expected 4 items in state, got {len(state)}")
         func, args, kwds, namespace = state
-        if (not callable(func) or not isinstance(args, tuple)
-                or (kwds is not None and not isinstance(kwds, dict)) or
-            (namespace is not None and not isinstance(namespace, dict))):
+        if (not callable(func) or not isinstance(args,
+                                                 tuple)
+                or (kwds is not None and not isinstance(kwds,
+                                                        dict))
+                or (namespace is not None and not isinstance(namespace,
+                                                             dict))):
             raise TypeError("invalid partial state")
 
         args = tuple(args)  # just in case it's a subclass
@@ -357,8 +389,7 @@
     """
     def __init__(self, func, *args, **keywords):
         if not callable(func) and not hasattr(func, "__get__"):
-            raise TypeError(
-                "{!r} is not callable or a descriptor".format(func))
+            raise TypeError("{!r} is not callable or a descriptor".format(func))
 
         # func could be a descriptor like classmethod which isn't callable,
         # so we can't inherit from partial (it verifies func is callable)
@@ -377,8 +408,9 @@
 
     def __repr__(self):
         args = ", ".join(map(repr, self.args))
-        keywords = ", ".join("{}={!r}".format(k, v)
-                             for k, v in self.keywords.items())
+        keywords = ", ".join("{}={!r}".format(k,
+                                              v) for k,
+                             v in self.keywords.items())
         format_string = "{module}.{cls}({func}, {args}, {keywords})"
         return format_string.format(module=self.__class__.__module__,
                                     cls=self.__class__.__qualname__,
@@ -449,8 +481,12 @@
 def _make_key(args,
               kwds,
               typed,
-              kwd_mark=(object(), ),
-              fasttypes={int, str, frozenset, type(None)},
+              kwd_mark=(object(),
+                        ),
+              fasttypes={int,
+                         str,
+                         frozenset,
+                         type(None)},
               tuple=tuple,
               type=type,
               len=len):
@@ -703,8 +739,10 @@
     abstract_bases = []
     other_bases = list(cls.__bases__[boundary:])
     for base in abcs:
-        if issubclass(cls, base) and not any(
-                issubclass(b, base) for b in cls.__bases__):
+        if issubclass(
+                cls,
+                base) and not any(issubclass(b,
+                                             base) for b in cls.__bases__):
             # If *cls* is the class that introduces behaviour described by
             # an ABC *base*, insert said ABC to its MRO.
             abstract_bases.append(base)
@@ -713,9 +751,9 @@
     explicit_c3_mros = [_c3_mro(base, abcs=abcs) for base in explicit_bases]
     abstract_c3_mros = [_c3_mro(base, abcs=abcs) for base in abstract_bases]
     other_c3_mros = [_c3_mro(base, abcs=abcs) for base in other_bases]
-    return _c3_merge([[cls]] + explicit_c3_mros + abstract_c3_mros +
-                     other_c3_mros + [explicit_bases] + [abstract_bases] +
-                     [other_bases])
+    return _c3_merge([[cls]] + explicit_c3_mros + abstract_c3_mros
+                     + other_c3_mros + [explicit_bases] + [abstract_bases]
+                     + [other_bases])
 
 
 def _compose_mro(cls, types):
@@ -729,8 +767,10 @@
 
     # Remove entries which are already present in the __mro__ or unrelated.
     def is_related(typ):
-        return (typ not in bases and hasattr(typ, '__mro__')
-                and issubclass(cls, typ))
+        return (typ not in bases and hasattr(typ,
+                                             '__mro__')
+                and issubclass(cls,
+                               typ))
 
     types = [n for n in types if is_related(n)]
 
@@ -781,9 +821,11 @@
             # If *match* is an implicit ABC but there is another unrelated,
             # equally matching implicit ABC, refuse the temptation to guess.
             if (t in registry and t not in cls.__mro__
-                    and match not in cls.__mro__ and not issubclass(match, t)):
-                raise RuntimeError("Ambiguous dispatch: {} or {}".format(
-                    match, t))
+                    and match not in cls.__mro__ and not issubclass(match,
+                                                                    t)):
+                raise RuntimeError("Ambiguous dispatch: {} or {}"
+                                   .format(match,
+                                           t))
             break
         if t in registry:
             match = t
--- .\env\Lib\genericpath.py	(original)
+++ .\env\Lib\genericpath.py	(reformatted)
@@ -7,8 +7,17 @@
 import stat
 
 __all__ = [
-    'commonprefix', 'exists', 'getatime', 'getctime', 'getmtime', 'getsize',
-    'isdir', 'isfile', 'samefile', 'sameopenfile', 'samestat'
+    'commonprefix',
+    'exists',
+    'getatime',
+    'getctime',
+    'getmtime',
+    'getsize',
+    'isdir',
+    'isfile',
+    'samefile',
+    'sameopenfile',
+    'samestat'
 ]
 
 
@@ -69,7 +78,8 @@
 # Return the longest prefix of all list elements.
 def commonprefix(m):
     "Given a list of pathnames, returns the longest common leading component"
-    if not m: return ''
+    if not m:
+        return ''
     # Some people pass in a list of pathname parts to operate in an OS-agnostic
     # fashion; don't try to translate in that case as that's an abuse of the
     # API and they are already doing what they need to be OS-agnostic and so
@@ -149,7 +159,8 @@
             hasbytes = True
         else:
             raise TypeError('%s() argument must be str or bytes, not %r' %
-                            (funcname, s.__class__.__name__)) from None
+                            (funcname,
+                             s.__class__.__name__)) from None
     if hasstr and hasbytes:
         raise TypeError(
             "Can't mix strings and bytes in path components") from None
--- .\env\Lib\hashlib.py	(original)
+++ .\env\Lib\hashlib.py	(reformatted)
@@ -55,15 +55,28 @@
 
 # This tuple and __get_builtin_constructor() must be modified if a new
 # always available algorithm is added.
-__always_supported = ('md5', 'sha1', 'sha224', 'sha256', 'sha384', 'sha512',
-                      'blake2b', 'blake2s', 'sha3_224', 'sha3_256', 'sha3_384',
-                      'sha3_512', 'shake_128', 'shake_256')
+__always_supported = ('md5',
+                      'sha1',
+                      'sha224',
+                      'sha256',
+                      'sha384',
+                      'sha512',
+                      'blake2b',
+                      'blake2s',
+                      'sha3_224',
+                      'sha3_256',
+                      'sha3_384',
+                      'sha3_512',
+                      'shake_128',
+                      'shake_256')
 
 algorithms_guaranteed = set(__always_supported)
 algorithms_available = set(__always_supported)
 
-__all__ = __always_supported + ('new', 'algorithms_guaranteed',
-                                'algorithms_available', 'pbkdf2_hmac')
+__all__ = __always_supported + ('new',
+                                'algorithms_guaranteed',
+                                'algorithms_available',
+                                'pbkdf2_hmac')
 
 __builtin_constructor_cache = {}
 
@@ -93,7 +106,11 @@
             cache['blake2b'] = _blake2.blake2b
             cache['blake2s'] = _blake2.blake2s
         elif name in {
-                'sha3_224', 'sha3_256', 'sha3_384', 'sha3_512', 'shake_128',
+                'sha3_224',
+                'sha3_256',
+                'sha3_384',
+                'sha3_512',
+                'shake_128',
                 'shake_256'
         }:
             import _sha3
@@ -160,8 +177,8 @@
     import _hashlib
     new = __hash_new
     __get_hash = __get_openssl_constructor
-    algorithms_available = algorithms_available.union(
-        _hashlib.openssl_md_meth_names)
+    algorithms_available = algorithms_available.union(_hashlib
+                                                      .openssl_md_meth_names)
 except ImportError:
     new = __py_new
     __get_hash = __get_builtin_constructor
--- .\env\Lib\heapq.py	(original)
+++ .\env\Lib\heapq.py	(reformatted)
@@ -125,8 +125,14 @@
 """
 
 __all__ = [
-    'heappush', 'heappop', 'heapify', 'heapreplace', 'merge', 'nlargest',
-    'nsmallest', 'heappushpop'
+    'heappush',
+    'heappop',
+    'heapify',
+    'heapreplace',
+    'merge',
+    'nlargest',
+    'nsmallest',
+    'heappushpop'
 ]
 
 
--- .\env\Lib\hmac.py	(original)
+++ .\env\Lib\hmac.py	(reformatted)
@@ -45,14 +45,16 @@
         """
 
         if not isinstance(key, (bytes, bytearray)):
-            raise TypeError("key: expected bytes or bytearray, but got %r" %
-                            type(key).__name__)
+            raise TypeError("key: expected bytes or bytearray, but got %r"
+                            % type(key).__name__)
 
         if digestmod is None:
             _warnings.warn(
                 "HMAC() without an explicit digestmod argument "
                 "is deprecated since Python 3.4, and will be removed "
-                "in 3.8", DeprecationWarning, 2)
+                "in 3.8",
+                DeprecationWarning,
+                2)
             digestmod = _hashlib.md5
 
         if callable(digestmod):
@@ -71,13 +73,17 @@
             if blocksize < 16:
                 _warnings.warn(
                     'block_size of %d seems too small; using our '
-                    'default of %d.' % (blocksize, self.blocksize),
-                    RuntimeWarning, 2)
+                    'default of %d.' % (blocksize,
+                                        self.blocksize),
+                    RuntimeWarning,
+                    2)
                 blocksize = self.blocksize
         else:
             _warnings.warn(
                 'No block_size attribute on given digest object; '
-                'Assuming %d.' % (self.blocksize), RuntimeWarning, 2)
+                'Assuming %d.' % (self.blocksize),
+                RuntimeWarning,
+                2)
             blocksize = self.blocksize
 
         # self.blocksize is the default blocksize. self.block_size is
@@ -166,7 +172,8 @@
 
     Note: key and msg must be a bytes or bytearray objects.
     """
-    if (_hashopenssl is not None and isinstance(digest, str)
+    if (_hashopenssl is not None and isinstance(digest,
+                                                str)
             and digest in _openssl_md_meths):
         return _hashopenssl.hmac_digest(key, msg, digest)
 
--- .\env\Lib\imp.py	(original)
+++ .\env\Lib\imp.py	(reformatted)
@@ -6,8 +6,14 @@
 
 """
 # (Probably) need to stay in _imp
-from _imp import (lock_held, acquire_lock, release_lock, get_frozen_object,
-                  is_frozen_package, init_frozen, is_builtin, is_frozen,
+from _imp import (lock_held,
+                  acquire_lock,
+                  release_lock,
+                  get_frozen_object,
+                  is_frozen_package,
+                  init_frozen,
+                  is_builtin,
+                  is_frozen,
                   _fix_co_filename)
 try:
     from _imp import create_dynamic
@@ -194,8 +200,8 @@
 def load_package(name, path):
     """**DEPRECATED**"""
     if os.path.isdir(path):
-        extensions = (machinery.SOURCE_SUFFIXES[:] +
-                      machinery.BYTECODE_SUFFIXES[:])
+        extensions = (machinery.SOURCE_SUFFIXES[:]
+                      + machinery.BYTECODE_SUFFIXES[:])
         for extension in extensions:
             init_path = os.path.join(path, '__init__' + extension)
             if os.path.exists(init_path):
--- .\env\Lib\io.py	(original)
+++ .\env\Lib\io.py	(reformatted)
@@ -42,19 +42,42 @@
               "Benjamin Peterson <benjamin@python.org>")
 
 __all__ = [
-    "BlockingIOError", "open", "IOBase", "RawIOBase", "FileIO", "BytesIO",
-    "StringIO", "BufferedIOBase", "BufferedReader", "BufferedWriter",
-    "BufferedRWPair", "BufferedRandom", "TextIOBase", "TextIOWrapper",
-    "UnsupportedOperation", "SEEK_SET", "SEEK_CUR", "SEEK_END"
+    "BlockingIOError",
+    "open",
+    "IOBase",
+    "RawIOBase",
+    "FileIO",
+    "BytesIO",
+    "StringIO",
+    "BufferedIOBase",
+    "BufferedReader",
+    "BufferedWriter",
+    "BufferedRWPair",
+    "BufferedRandom",
+    "TextIOBase",
+    "TextIOWrapper",
+    "UnsupportedOperation",
+    "SEEK_SET",
+    "SEEK_CUR",
+    "SEEK_END"
 ]
 
 import _io
 import abc
 
-from _io import (DEFAULT_BUFFER_SIZE, BlockingIOError, UnsupportedOperation,
-                 open, FileIO, BytesIO, StringIO, BufferedReader,
-                 BufferedWriter, BufferedRWPair, BufferedRandom,
-                 IncrementalNewlineDecoder, TextIOWrapper)
+from _io import (DEFAULT_BUFFER_SIZE,
+                 BlockingIOError,
+                 UnsupportedOperation,
+                 open,
+                 FileIO,
+                 BytesIO,
+                 StringIO,
+                 BufferedReader,
+                 BufferedWriter,
+                 BufferedRWPair,
+                 BufferedRandom,
+                 IncrementalNewlineDecoder,
+                 TextIOWrapper)
 
 OpenWrapper = _io.open  # for compatibility with _pyio
 
@@ -88,7 +111,10 @@
 
 RawIOBase.register(FileIO)
 
-for klass in (BytesIO, BufferedReader, BufferedWriter, BufferedRandom,
+for klass in (BytesIO,
+              BufferedReader,
+              BufferedWriter,
+              BufferedRandom,
               BufferedRWPair):
     BufferedIOBase.register(klass)
 
--- .\env\Lib\keyword.py	(original)
+++ .\env\Lib\keyword.py	(reformatted)
@@ -59,8 +59,10 @@
 
     args = sys.argv[1:]
     iptfile = args and args[0] or "Python/graminit.c"
-    if len(args) > 1: optfile = args[1]
-    else: optfile = "Lib/keyword.py"
+    if len(args) > 1:
+        optfile = args[1]
+    else:
+        optfile = "Lib/keyword.py"
 
     # load the output skeleton from the target, taking care to preserve its
     # newline convention.
--- .\env\Lib\linecache.py	(original)
+++ .\env\Lib\linecache.py	(reformatted)
@@ -109,9 +109,10 @@
                     # No luck, the PEP302 loader cannot find the source
                     # for this module.
                     return []
-                cache[filename] = (len(data), None,
-                                   [line + '\n'
-                                    for line in data.splitlines()], fullname)
+                cache[filename] = (len(data),
+                                   None,
+                                   [line + '\n' for line in data.splitlines()],
+                                   fullname)
                 return cache[filename][2]
 
         # Try looking through the module search path, which is only useful
--- .\env\Lib\locale.py	(original)
+++ .\env\Lib\locale.py	(reformatted)
@@ -25,10 +25,28 @@
 # Yuck:  LC_MESSAGES is non-standard:  can't tell whether it exists before
 # trying the import.  So __all__ is also fiddled at the end of the file.
 __all__ = [
-    "getlocale", "getdefaultlocale", "getpreferredencoding", "Error",
-    "setlocale", "resetlocale", "localeconv", "strcoll", "strxfrm", "str",
-    "atof", "atoi", "format", "format_string", "currency", "normalize",
-    "LC_CTYPE", "LC_COLLATE", "LC_TIME", "LC_MONETARY", "LC_NUMERIC", "LC_ALL",
+    "getlocale",
+    "getdefaultlocale",
+    "getpreferredencoding",
+    "Error",
+    "setlocale",
+    "resetlocale",
+    "localeconv",
+    "strcoll",
+    "strxfrm",
+    "str",
+    "atof",
+    "atoi",
+    "format",
+    "format_string",
+    "currency",
+    "normalize",
+    "LC_CTYPE",
+    "LC_COLLATE",
+    "LC_TIME",
+    "LC_MONETARY",
+    "LC_NUMERIC",
+    "LC_ALL",
     "CHAR_MAX"
 ]
 
@@ -244,7 +262,10 @@
             else:
                 starcount = perc.group('modifiers').count('*')
                 new_val.append(
-                    _format(perc.group(), val[i], grouping, monetary,
+                    _format(perc.group(),
+                            val[i],
+                            grouping,
+                            monetary,
                             *val[i + 1:i + 1 + starcount]))
                 i += (1 + starcount)
     val = tuple(new_val)
--- .\env\Lib\ntpath.py	(original)
+++ .\env\Lib\ntpath.py	(reformatted)
@@ -24,13 +24,44 @@
 from genericpath import *
 
 __all__ = [
-    "normcase", "isabs", "join", "splitdrive", "split", "splitext", "basename",
-    "dirname", "commonprefix", "getsize", "getmtime", "getatime", "getctime",
-    "islink", "exists", "lexists", "isdir", "isfile", "ismount", "expanduser",
-    "expandvars", "normpath", "abspath", "curdir", "pardir", "sep", "pathsep",
-    "defpath", "altsep", "extsep", "devnull", "realpath",
-    "supports_unicode_filenames", "relpath", "samefile", "sameopenfile",
-    "samestat", "commonpath"
+    "normcase",
+    "isabs",
+    "join",
+    "splitdrive",
+    "split",
+    "splitext",
+    "basename",
+    "dirname",
+    "commonprefix",
+    "getsize",
+    "getmtime",
+    "getatime",
+    "getctime",
+    "islink",
+    "exists",
+    "lexists",
+    "isdir",
+    "isfile",
+    "ismount",
+    "expanduser",
+    "expandvars",
+    "normpath",
+    "abspath",
+    "curdir",
+    "pardir",
+    "sep",
+    "pathsep",
+    "defpath",
+    "altsep",
+    "extsep",
+    "devnull",
+    "realpath",
+    "supports_unicode_filenames",
+    "relpath",
+    "samefile",
+    "sameopenfile",
+    "samestat",
+    "commonpath"
 ]
 
 
@@ -555,7 +586,8 @@
 # realpath is a no-op on systems without islink support
 realpath = abspath
 # Win9x family and earlier have no Unicode filename support.
-supports_unicode_filenames = (hasattr(sys, "getwindowsversion")
+supports_unicode_filenames = (hasattr(sys,
+                                      "getwindowsversion")
                               and sys.getwindowsversion()[3] >= 2)
 
 
@@ -585,7 +617,8 @@
         path_drive, path_rest = splitdrive(path_abs)
         if normcase(start_drive) != normcase(path_drive):
             raise ValueError("path is on mount %r, start on mount %r" %
-                             (path_drive, start_drive))
+                             (path_drive,
+                              start_drive))
 
         start_list = [x for x in start_rest.split(sep) if x]
         path_list = [x for x in path_rest.split(sep) if x]
@@ -600,7 +633,10 @@
         if not rel_list:
             return curdir
         return join(*rel_list)
-    except (TypeError, ValueError, AttributeError, BytesWarning,
+    except (TypeError,
+            ValueError,
+            AttributeError,
+            BytesWarning,
             DeprecationWarning):
         genericpath._check_arg_types('relpath', path, start)
         raise
@@ -635,7 +671,8 @@
 
     try:
         drivesplits = [
-            splitdrive(p.replace(altsep, sep).lower()) for p in paths
+            splitdrive(p.replace(altsep,
+                                 sep).lower()) for p in paths
         ]
         split_paths = [p.split(sep) for d, p in drivesplits]
 
@@ -654,8 +691,7 @@
         common = path.split(sep)
         common = [c for c in common if c and c != curdir]
 
-        split_paths = [[c for c in s if c and c != curdir]
-                       for s in split_paths]
+        split_paths = [[c for c in s if c and c != curdir] for s in split_paths]
         s1 = min(split_paths)
         s2 = max(split_paths)
         for i, c in enumerate(s1):
--- .\env\Lib\operator.py	(original)
+++ .\env\Lib\operator.py	(reformatted)
@@ -11,13 +11,60 @@
 """
 
 __all__ = [
-    'abs', 'add', 'and_', 'attrgetter', 'concat', 'contains', 'countOf',
-    'delitem', 'eq', 'floordiv', 'ge', 'getitem', 'gt', 'iadd', 'iand',
-    'iconcat', 'ifloordiv', 'ilshift', 'imatmul', 'imod', 'imul', 'index',
-    'indexOf', 'inv', 'invert', 'ior', 'ipow', 'irshift', 'is_', 'is_not',
-    'isub', 'itemgetter', 'itruediv', 'ixor', 'le', 'length_hint', 'lshift',
-    'lt', 'matmul', 'methodcaller', 'mod', 'mul', 'ne', 'neg', 'not_', 'or_',
-    'pos', 'pow', 'rshift', 'setitem', 'sub', 'truediv', 'truth', 'xor'
+    'abs',
+    'add',
+    'and_',
+    'attrgetter',
+    'concat',
+    'contains',
+    'countOf',
+    'delitem',
+    'eq',
+    'floordiv',
+    'ge',
+    'getitem',
+    'gt',
+    'iadd',
+    'iand',
+    'iconcat',
+    'ifloordiv',
+    'ilshift',
+    'imatmul',
+    'imod',
+    'imul',
+    'index',
+    'indexOf',
+    'inv',
+    'invert',
+    'ior',
+    'ipow',
+    'irshift',
+    'is_',
+    'is_not',
+    'isub',
+    'itemgetter',
+    'itruediv',
+    'ixor',
+    'le',
+    'length_hint',
+    'lshift',
+    'lt',
+    'matmul',
+    'methodcaller',
+    'mod',
+    'mul',
+    'ne',
+    'neg',
+    'not_',
+    'or_',
+    'pos',
+    'pow',
+    'rshift',
+    'setitem',
+    'sub',
+    'truediv',
+    'truth',
+    'xor'
 ]
 
 from builtins import abs as _abs
@@ -233,8 +280,8 @@
     integer >= 0.
     """
     if not isinstance(default, int):
-        msg = ("'%s' object cannot be interpreted as an integer" %
-               type(default).__name__)
+        msg = ("'%s' object cannot be interpreted as an integer"
+               % type(default).__name__)
         raise TypeError(msg)
 
     try:
@@ -302,8 +349,9 @@
 
     def __repr__(self):
         return '%s.%s(%s)' % (self.__class__.__module__,
-                              self.__class__.__qualname__, ', '.join(
-                                  map(repr, self._attrs)))
+                              self.__class__.__qualname__,
+                              ', '.join(map(repr,
+                                            self._attrs)))
 
     def __reduce__(self):
         return self.__class__, self._attrs
@@ -338,8 +386,9 @@
 
     def __repr__(self):
         return '%s.%s(%s)' % (self.__class__.__module__,
-                              self.__class__.__name__, ', '.join(
-                                  map(repr, self._items)))
+                              self.__class__.__name__,
+                              ', '.join(map(repr,
+                                            self._items)))
 
     def __reduce__(self):
         return self.__class__, self._items
@@ -373,7 +422,8 @@
         args.extend(map(repr, self._args))
         args.extend('%s=%r' % (k, v) for k, v in self._kwargs.items())
         return '%s.%s(%s)' % (self.__class__.__module__,
-                              self.__class__.__name__, ', '.join(args))
+                              self.__class__.__name__,
+                              ', '.join(args))
 
     def __reduce__(self):
         if not self._kwargs:
--- .\env\Lib\os.py	(original)
+++ .\env\Lib\os.py	(reformatted)
@@ -30,9 +30,25 @@
 
 # Note:  more names are added to __all__ later.
 __all__ = [
-    "altsep", "curdir", "pardir", "sep", "pathsep", "linesep", "defpath",
-    "name", "path", "devnull", "SEEK_SET", "SEEK_CUR", "SEEK_END", "fsencode",
-    "fsdecode", "get_exec_path", "fdopen", "popen", "extsep"
+    "altsep",
+    "curdir",
+    "pardir",
+    "sep",
+    "pathsep",
+    "linesep",
+    "defpath",
+    "name",
+    "path",
+    "devnull",
+    "SEEK_SET",
+    "SEEK_CUR",
+    "SEEK_END",
+    "fsencode",
+    "fsdecode",
+    "get_exec_path",
+    "fdopen",
+    "popen",
+    "extsep"
 ]
 
 
@@ -93,7 +109,13 @@
     raise ImportError('no os specific module found')
 
 sys.modules['os.path'] = path
-from os.path import (curdir, pardir, sep, pathsep, defpath, extsep, altsep,
+from os.path import (curdir,
+                     pardir,
+                     sep,
+                     pathsep,
+                     defpath,
+                     extsep,
+                     altsep,
                      devnull)
 
 del _names
@@ -475,9 +497,15 @@
         topfd = open(top, O_RDONLY, dir_fd=dir_fd)
         try:
             if (follow_symlinks or (st.S_ISDIR(orig_st.st_mode)
-                                    and path.samestat(orig_st, stat(topfd)))):
-                yield from _fwalk(topfd, top, isinstance(top, bytes), topdown,
-                                  onerror, follow_symlinks)
+                                    and path.samestat(orig_st,
+                                                      stat(topfd)))):
+                yield from _fwalk(topfd,
+                                  top,
+                                  isinstance(top,
+                                             bytes),
+                                  topdown,
+                                  onerror,
+                                  follow_symlinks)
         finally:
             close(topfd)
 
@@ -531,8 +559,12 @@
             try:
                 if follow_symlinks or path.samestat(orig_st, stat(dirfd)):
                     dirpath = path.join(toppath, name)
-                    yield from _fwalk(dirfd, dirpath, isbytes, topdown,
-                                      onerror, follow_symlinks)
+                    yield from _fwalk(dirfd,
+                                      dirpath,
+                                      isbytes,
+                                      topdown,
+                                      onerror,
+                                      follow_symlinks)
             finally:
                 close(dirfd)
 
@@ -686,8 +718,14 @@
 
 
 class _Environ(MutableMapping):
-    def __init__(self, data, encodekey, decodekey, encodevalue, decodevalue,
-                 putenv, unsetenv):
+    def __init__(self,
+                 data,
+                 encodekey,
+                 decodekey,
+                 encodevalue,
+                 decodevalue,
+                 putenv,
+                 unsetenv):
         self.encodekey = encodekey
         self.decodekey = decodekey
         self.encodevalue = encodevalue
@@ -730,8 +768,9 @@
 
     def __repr__(self):
         return 'environ({{{}}})'.format(', '.join(
-            ('{!r}: {!r}'.format(self.decodekey(key), self.decodevalue(value))
-             for key, value in self._data.items())))
+            ('{!r}: {!r}'.format(self.decodekey(key),
+                                 self.decodevalue(value)) for key,
+             value in self._data.items())))
 
     def copy(self):
         return dict(self)
@@ -790,8 +829,7 @@
 
         encodekey = encode
         data = environ
-    return _Environ(data, encodekey, decode, encode, decode, _putenv,
-                    _unsetenv)
+    return _Environ(data, encodekey, decode, encode, decode, _putenv, _unsetenv)
 
 
 # unicode environ
@@ -817,8 +855,13 @@
         return value
 
     # bytes environ
-    environb = _Environ(environ._data, _check_bytes, bytes, _check_bytes,
-                        bytes, _putenv, _unsetenv)
+    environb = _Environ(environ._data,
+                        _check_bytes,
+                        bytes,
+                        _check_bytes,
+                        bytes,
+                        _putenv,
+                        _unsetenv)
     del _check_bytes
 
     def getenvb(key, default=None):
--- .\env\Lib\posixpath.py	(original)
+++ .\env\Lib\posixpath.py	(reformatted)
@@ -29,12 +29,43 @@
 from genericpath import *
 
 __all__ = [
-    "normcase", "isabs", "join", "splitdrive", "split", "splitext", "basename",
-    "dirname", "commonprefix", "getsize", "getmtime", "getatime", "getctime",
-    "islink", "exists", "lexists", "isdir", "isfile", "ismount", "expanduser",
-    "expandvars", "normpath", "abspath", "samefile", "sameopenfile",
-    "samestat", "curdir", "pardir", "sep", "pathsep", "defpath", "altsep",
-    "extsep", "devnull", "realpath", "supports_unicode_filenames", "relpath",
+    "normcase",
+    "isabs",
+    "join",
+    "splitdrive",
+    "split",
+    "splitext",
+    "basename",
+    "dirname",
+    "commonprefix",
+    "getsize",
+    "getmtime",
+    "getatime",
+    "getctime",
+    "islink",
+    "exists",
+    "lexists",
+    "isdir",
+    "isfile",
+    "ismount",
+    "expanduser",
+    "expandvars",
+    "normpath",
+    "abspath",
+    "samefile",
+    "sameopenfile",
+    "samestat",
+    "curdir",
+    "pardir",
+    "sep",
+    "pathsep",
+    "defpath",
+    "altsep",
+    "extsep",
+    "devnull",
+    "realpath",
+    "supports_unicode_filenames",
+    "relpath",
     "commonpath"
 ]
 
@@ -536,8 +567,7 @@
         except ValueError:
             raise ValueError("Can't mix absolute and relative paths") from None
 
-        split_paths = [[c for c in s if c and c != curdir]
-                       for s in split_paths]
+        split_paths = [[c for c in s if c and c != curdir] for s in split_paths]
         s1 = min(split_paths)
         s2 = max(split_paths)
         common = s1
--- .\env\Lib\random.py	(original)
+++ .\env\Lib\random.py	(reformatted)
@@ -49,11 +49,30 @@
 import os as _os
 
 __all__ = [
-    "Random", "seed", "random", "uniform", "randint", "choice", "sample",
-    "randrange", "shuffle", "normalvariate", "lognormvariate", "expovariate",
-    "vonmisesvariate", "gammavariate", "triangular", "gauss", "betavariate",
-    "paretovariate", "weibullvariate", "getstate", "setstate", "getrandbits",
-    "choices", "SystemRandom"
+    "Random",
+    "seed",
+    "random",
+    "uniform",
+    "randint",
+    "choice",
+    "sample",
+    "randrange",
+    "shuffle",
+    "normalvariate",
+    "lognormvariate",
+    "expovariate",
+    "vonmisesvariate",
+    "gammavariate",
+    "triangular",
+    "gauss",
+    "betavariate",
+    "paretovariate",
+    "weibullvariate",
+    "getstate",
+    "setstate",
+    "getrandbits",
+    "choices",
+    "SystemRandom"
 ]
 
 NV_MAGICCONST = 4 * _exp(-0.5) / _sqrt(2.0)
@@ -150,8 +169,8 @@
             super().setstate(internalstate)
         else:
             raise ValueError("state with version %s passed to "
-                             "Random.setstate() of version %s" %
-                             (version, self.VERSION))
+                             "Random.setstate() of version %s" % (version,
+                                                                  self.VERSION))
 
 ## ---- Methods below this point do not need to be overridden when
 ## ---- subclassing for the purpose of using a different core generator.
@@ -200,7 +219,9 @@
             return istart + self._randbelow(width)
         if step == 1:
             raise ValueError("empty range for randrange() (%d,%d, %d)" %
-                             (istart, istop, width))
+                             (istart,
+                              istop,
+                              width))
 
         # Non-unit step argument supplied.
         istep = _int(step)
@@ -246,10 +267,9 @@
         # There's an overridden random() method but no new getrandbits() method,
         # so we can only use random() from here.
         if n >= maxsize:
-            _warn(
-                "Underlying random() generator does not supply \n"
-                "enough bits to choose from a population range this large.\n"
-                "To remove the range limitation, add a getrandbits() method.")
+            _warn("Underlying random() generator does not supply \n"
+                  "enough bits to choose from a population range this large.\n"
+                  "To remove the range limitation, add a getrandbits() method.")
             return int(random() * n)
         if n == 0:
             raise ValueError("Boundary cannot be zero")
@@ -340,8 +360,7 @@
             for i in range(k):  # invariant:  non-selected at [0,n-i)
                 j = randbelow(n - i)
                 result[i] = pool[j]
-                pool[j] = pool[n - i -
-                               1]  # move non-selected item into vacancy
+                pool[j] = pool[n - i - 1]  # move non-selected item into vacancy
         else:
             selected = set()
             selected_add = selected.add
@@ -378,7 +397,9 @@
         hi = len(cum_weights) - 1
         return [
             population[bisect(cum_weights,
-                              random() * total, 0, hi)] for i in range(k)
+                              random() * total,
+                              0,
+                              hi)] for i in range(k)
         ]
 
 ## -------------------- real-valued distributions  -------------------
--- .\env\Lib\re.py	(original)
+++ .\env\Lib\re.py	(reformatted)
@@ -392,9 +392,15 @@
         for phrase, action in lexicon:
             gid = s.opengroup()
             p.append(
-                sre_parse.SubPattern(s, [
-                    (SUBPATTERN, (gid, 0, 0, sre_parse.parse(phrase, flags))),
-                ]))
+                sre_parse.SubPattern(s,
+                                     [
+                                         (SUBPATTERN,
+                                          (gid,
+                                           0,
+                                           0,
+                                           sre_parse.parse(phrase,
+                                                           flags))),
+                                     ]))
             s.closegroup(gid, p[-1])
         p = sre_parse.SubPattern(s, [(BRANCH, (None, p))])
         self.scanner = sre_compile.compile(p)
--- .\env\Lib\reprlib.py	(original)
+++ .\env\Lib\reprlib.py	(reformatted)
@@ -70,9 +70,11 @@
             newlevel = level - 1
             repr1 = self.repr1
             pieces = [repr1(elem, newlevel) for elem in islice(x, maxiter)]
-            if n > maxiter: pieces.append('...')
+            if n > maxiter:
+                pieces.append('...')
             s = ', '.join(pieces)
-            if n == 1 and trail: right = trail + right
+            if n == 1 and trail:
+                right = trail + right
         return '%s%s%s' % (left, s, right)
 
     def repr_tuple(self, x, level):
@@ -97,7 +99,10 @@
         if not x:
             return 'frozenset()'
         x = _possibly_sorted(x)
-        return self._repr_iterable(x, level, 'frozenset({', '})',
+        return self._repr_iterable(x,
+                                   level,
+                                   'frozenset({',
+                                   '})',
                                    self.maxfrozenset)
 
     def repr_deque(self, x, level):
@@ -105,8 +110,10 @@
 
     def repr_dict(self, x, level):
         n = len(x)
-        if n == 0: return '{}'
-        if level <= 0: return '{...}'
+        if n == 0:
+            return '{}'
+        if level <= 0:
+            return '{...}'
         newlevel = level - 1
         repr1 = self.repr1
         pieces = []
@@ -114,7 +121,8 @@
             keyrepr = repr1(key, newlevel)
             valrepr = repr1(x[key], newlevel)
             pieces.append('%s: %s' % (keyrepr, valrepr))
-        if n > self.maxdict: pieces.append('...')
+        if n > self.maxdict:
+            pieces.append('...')
         s = ', '.join(pieces)
         return '{%s}' % (s, )
 
--- .\env\Lib\rlcompleter.py	(original)
+++ .\env\Lib\rlcompleter.py	(reformatted)
@@ -117,7 +117,12 @@
                 if word in {'finally', 'try'}:
                     word = word + ':'
                 elif word not in {
-                        'False', 'None', 'True', 'break', 'continue', 'pass',
+                        'False',
+                        'None',
+                        'True',
+                        'break',
+                        'continue',
+                        'pass',
                         'else'
                 }:
                     word = word + ' '
--- .\env\Lib\shutil.py	(original)
+++ .\env\Lib\shutil.py	(reformatted)
@@ -43,12 +43,31 @@
     getgrnam = None
 
 __all__ = [
-    "copyfileobj", "copyfile", "copymode", "copystat", "copy", "copy2",
-    "copytree", "move", "rmtree", "Error", "SpecialFileError", "ExecError",
-    "make_archive", "get_archive_formats", "register_archive_format",
-    "unregister_archive_format", "get_unpack_formats",
-    "register_unpack_format", "unregister_unpack_format", "unpack_archive",
-    "ignore_patterns", "chown", "which", "get_terminal_size", "SameFileError"
+    "copyfileobj",
+    "copyfile",
+    "copymode",
+    "copystat",
+    "copy",
+    "copy2",
+    "copytree",
+    "move",
+    "rmtree",
+    "Error",
+    "SpecialFileError",
+    "ExecError",
+    "make_archive",
+    "get_archive_formats",
+    "register_archive_format",
+    "unregister_archive_format",
+    "get_unpack_formats",
+    "register_unpack_format",
+    "unregister_unpack_format",
+    "unpack_archive",
+    "ignore_patterns",
+    "chown",
+    "which",
+    "get_terminal_size",
+    "SameFileError"
 ]
 # disk_usage is added later, if available on the platform
 
@@ -97,8 +116,8 @@
             return False
 
     # All other platforms: check for same pathname.
-    return (os.path.normcase(os.path.abspath(src)) == os.path.normcase(
-        os.path.abspath(dst)))
+    return (os.path.normcase(os.path.abspath(src)) ==
+            os.path.normcase(os.path.abspath(dst)))
 
 
 def copyfile(src, dst, *, follow_symlinks=True):
@@ -216,7 +235,8 @@
     st = lookup("stat")(src, follow_symlinks=follow)
     mode = stat.S_IMODE(st.st_mode)
     lookup("utime")(dst,
-                    ns=(st.st_atime_ns, st.st_mtime_ns),
+                    ns=(st.st_atime_ns,
+                        st.st_mtime_ns),
                     follow_symlinks=follow)
     try:
         lookup("chmod")(dst, mode, follow_symlinks=follow)
@@ -364,7 +384,10 @@
                         continue
                     # otherwise let the copy occurs. copy2 will raise an error
                     if os.path.isdir(srcname):
-                        copytree(srcname, dstname, symlinks, ignore,
+                        copytree(srcname,
+                                 dstname,
+                                 symlinks,
+                                 ignore,
                                  copy_function)
                     else:
                         copy_function(srcname, dstname)
@@ -475,10 +498,12 @@
                 onerror(os.unlink, fullname, sys.exc_info())
 
 
-_use_fd_functions = (
-    {os.open, os.stat, os.unlink, os.rmdir} <= os.supports_dir_fd
-    and os.scandir in os.supports_fd
-    and os.stat in os.supports_follow_symlinks)
+_use_fd_functions = ({os.open,
+                      os.stat,
+                      os.unlink,
+                      os.rmdir} <= os.supports_dir_fd
+                     and os.scandir in os.supports_fd
+                     and os.stat in os.supports_follow_symlinks)
 
 
 def rmtree(path, ignore_errors=False, onerror=None):
@@ -603,7 +628,8 @@
         elif os.path.isdir(src):
             if _destinsrc(src, dst):
                 raise Error("Cannot move a directory '%s' into itself"
-                            " '%s'." % (src, dst))
+                            " '%s'." % (src,
+                                        dst))
             copytree(src, real_dst, copy_function=copy_function, symlinks=True)
             rmtree(src)
         else:
@@ -738,7 +764,8 @@
             os.makedirs(archive_dir)
 
     if logger is not None:
-        logger.info("creating '%s' and adding '%s' to it", zip_filename,
+        logger.info("creating '%s' and adding '%s' to it",
+                    zip_filename,
                     base_dir)
 
     if not dry_run:
@@ -767,20 +794,29 @@
 
 
 _ARCHIVE_FORMATS = {
-    'tar': (_make_tarball, [('compress', None)], "uncompressed tar file"),
+    'tar': (_make_tarball,
+            [('compress',
+              None)],
+            "uncompressed tar file"),
 }
 
 if _ZLIB_SUPPORTED:
-    _ARCHIVE_FORMATS['gztar'] = (_make_tarball, [('compress', 'gzip')],
+    _ARCHIVE_FORMATS['gztar'] = (_make_tarball,
+                                 [('compress',
+                                   'gzip')],
                                  "gzip'ed tar-file")
     _ARCHIVE_FORMATS['zip'] = (_make_zipfile, [], "ZIP file")
 
 if _BZ2_SUPPORTED:
-    _ARCHIVE_FORMATS['bztar'] = (_make_tarball, [('compress', 'bzip2')],
+    _ARCHIVE_FORMATS['bztar'] = (_make_tarball,
+                                 [('compress',
+                                   'bzip2')],
                                  "bzip2'ed tar-file")
 
 if _LZMA_SUPPORTED:
-    _ARCHIVE_FORMATS['xztar'] = (_make_tarball, [('compress', 'xz')],
+    _ARCHIVE_FORMATS['xztar'] = (_make_tarball,
+                                 [('compress',
+                                   'xz')],
                                  "xz'ed tar-file")
 
 
@@ -789,8 +825,9 @@
 
     Each element of the returned sequence is a tuple (name, description)
     """
-    formats = [(name, registry[2])
-               for name, registry in _ARCHIVE_FORMATS.items()]
+    formats = [(name,
+                registry[2]) for name,
+               registry in _ARCHIVE_FORMATS.items()]
     formats.sort()
     return formats
 
@@ -889,8 +926,10 @@
     Each element of the returned sequence is a tuple
     (name, extensions, description)
     """
-    formats = [(name, info[0], info[3])
-               for name, info in _UNPACK_FORMATS.items()]
+    formats = [(name,
+                info[0],
+                info[3]) for name,
+               info in _UNPACK_FORMATS.items()]
     formats.sort()
     return formats
 
@@ -906,8 +945,8 @@
     for extension in extensions:
         if extension in existing_extensions:
             msg = '%s is already registered for "%s"'
-            raise RegistryError(msg %
-                                (extension, existing_extensions[extension]))
+            raise RegistryError(msg % (extension,
+                                       existing_extensions[extension]))
 
     if not callable(function):
         raise TypeError('The registered function must be a callable')
@@ -993,8 +1032,8 @@
     try:
         tarobj = tarfile.open(filename)
     except tarfile.TarError:
-        raise ReadError("%s is not a compressed or uncompressed tar file" %
-                        filename)
+        raise ReadError("%s is not a compressed or uncompressed tar file"
+                        % filename)
     try:
         tarobj.extractall(extract_dir)
     finally:
@@ -1002,20 +1041,35 @@
 
 
 _UNPACK_FORMATS = {
-    'tar': (['.tar'], _unpack_tarfile, [], "uncompressed tar file"),
-    'zip': (['.zip'], _unpack_zipfile, [], "ZIP file"),
+    'tar': (['.tar'],
+            _unpack_tarfile,
+            [],
+            "uncompressed tar file"),
+    'zip': (['.zip'],
+            _unpack_zipfile,
+            [],
+            "ZIP file"),
 }
 
 if _ZLIB_SUPPORTED:
-    _UNPACK_FORMATS['gztar'] = (['.tar.gz', '.tgz'], _unpack_tarfile, [],
+    _UNPACK_FORMATS['gztar'] = (['.tar.gz',
+                                 '.tgz'],
+                                _unpack_tarfile,
+                                [],
                                 "gzip'ed tar-file")
 
 if _BZ2_SUPPORTED:
-    _UNPACK_FORMATS['bztar'] = (['.tar.bz2', '.tbz2'], _unpack_tarfile, [],
+    _UNPACK_FORMATS['bztar'] = (['.tar.bz2',
+                                 '.tbz2'],
+                                _unpack_tarfile,
+                                [],
                                 "bzip2'ed tar-file")
 
 if _LZMA_SUPPORTED:
-    _UNPACK_FORMATS['xztar'] = (['.tar.xz', '.txz'], _unpack_tarfile, [],
+    _UNPACK_FORMATS['xztar'] = (['.tar.xz',
+                                 '.txz'],
+                                _unpack_tarfile,
+                                [],
                                 "xz'ed tar-file")
 
 
@@ -1052,8 +1106,8 @@
         try:
             format_info = _UNPACK_FORMATS[format]
         except KeyError:
-            raise ValueError(
-                "Unknown unpack format '{0}'".format(format)) from None
+            raise ValueError("Unknown unpack format '{0}'".format(
+                format)) from None
 
         func = format_info[1]
         func(filename, extract_dir, **dict(format_info[2]))
@@ -1198,7 +1252,8 @@
     # Additionally check that `file` is not a directory, as on Windows
     # directories pass the os.access check.
     def _access_check(fn, mode):
-        return (os.path.exists(fn) and os.access(fn, mode)
+        return (os.path.exists(fn) and os.access(fn,
+                                                 mode)
                 and not os.path.isdir(fn))
 
     # If we're given a path with a directory part, look it up directly rather
--- .\env\Lib\site.py	(original)
+++ .\env\Lib\site.py	(reformatted)
@@ -103,8 +103,10 @@
 def abs__file__():
     """Set all module' __file__ attribute to an absolute path"""
     for m in sys.modules.values():
-        if (_is_jython and not isinstance(m, ModuleType)) or hasattr(
-                m, "__loader__"):
+        if (_is_jython and not isinstance(m,
+                                          ModuleType)) or hasattr(
+                                              m,
+                                              "__loader__"):
             # only modules need the abspath in Jython. and don't mess
             # with a PEP 302-supplied __file__
             continue
@@ -236,26 +238,38 @@
                         "/System/Library/Frameworks/"):  # Apple's Python
 
                     sitedirs = [
-                        os.path.join("/Library/Python", sys.version[:3],
+                        os.path.join("/Library/Python",
+                                     sys.version[:3],
                                      "site-packages"),
-                        os.path.join(prefix, "Extras", "lib", "python"),
+                        os.path.join(prefix,
+                                     "Extras",
+                                     "lib",
+                                     "python"),
                     ]
 
                 else:  # any other Python distros on OSX work this way
                     sitedirs = [
-                        os.path.join(prefix, "lib", "python" + sys.version[:3],
+                        os.path.join(prefix,
+                                     "lib",
+                                     "python" + sys.version[:3],
                                      "site-packages")
                     ]
 
             elif os.sep == "/":
                 sitedirs = [
-                    os.path.join(prefix, "lib", "python" + sys.version[:3],
+                    os.path.join(prefix,
+                                 "lib",
+                                 "python" + sys.version[:3],
                                  "site-packages"),
-                    os.path.join(prefix, "lib", "site-python"),
-                    os.path.join(prefix, "python" + sys.version[:3],
+                    os.path.join(prefix,
+                                 "lib",
+                                 "site-python"),
+                    os.path.join(prefix,
+                                 "python" + sys.version[:3],
                                  "lib-dynload"),
                 ]
-                lib64_dir = os.path.join(prefix, "lib64",
+                lib64_dir = os.path.join(prefix,
+                                         "lib64",
                                          "python" + sys.version[:3],
                                          "site-packages")
                 if os.path.exists(lib64_dir) and os.path.realpath(
@@ -274,21 +288,29 @@
                     pass
                 # Debian-specific dist-packages directories:
                 sitedirs.append(
-                    os.path.join(prefix, "local/lib",
-                                 "python" + sys.version[:3], "dist-packages"))
+                    os.path.join(prefix,
+                                 "local/lib",
+                                 "python" + sys.version[:3],
+                                 "dist-packages"))
                 if sys.version[0] == "2":
                     sitedirs.append(
-                        os.path.join(prefix, "lib", "python" + sys.version[:3],
+                        os.path.join(prefix,
+                                     "lib",
+                                     "python" + sys.version[:3],
                                      "dist-packages"))
                 else:
                     sitedirs.append(
-                        os.path.join(prefix, "lib", "python" + sys.version[0],
+                        os.path.join(prefix,
+                                     "lib",
+                                     "python" + sys.version[0],
                                      "dist-packages"))
                 sitedirs.append(os.path.join(prefix, "lib", "dist-python"))
             else:
                 sitedirs = [
                     prefix,
-                    os.path.join(prefix, "lib", "site-packages")
+                    os.path.join(prefix,
+                                 "lib",
+                                 "site-packages")
                 ]
             if sys.platform == "darwin":
                 # for framework builds *only* we add the standard Apple
@@ -298,8 +320,11 @@
                     home = os.environ.get("HOME")
                     if home:
                         sitedirs.append(
-                            os.path.join(home, "Library", "Python",
-                                         sys.version[:3], "site-packages"))
+                            os.path.join(home,
+                                         "Library",
+                                         "Python",
+                                         sys.version[:3],
+                                         "site-packages"))
             for sitedir in sitedirs:
                 if os.path.isdir(sitedir):
                     addsitedir(sitedir, known_paths)
@@ -367,14 +392,17 @@
             USER_BASE = env_base
         else:
             USER_BASE = joinuser("~", ".local")
-        USER_SITE = os.path.join(USER_BASE, "lib", "python" + sys.version[:3],
+        USER_SITE = os.path.join(USER_BASE,
+                                 "lib",
+                                 "python" + sys.version[:3],
                                  "site-packages")
 
     if ENABLE_USER_SITE and os.path.isdir(USER_SITE):
         addsitedir(USER_SITE, known_paths)
     if ENABLE_USER_SITE:
         for dist_libdir in ("lib", "local/lib"):
-            user_site = os.path.join(USER_BASE, dist_libdir,
+            user_site = os.path.join(USER_BASE,
+                                     dist_libdir,
                                      "python" + sys.version[:3],
                                      "dist-packages")
             if os.path.isdir(user_site):
@@ -518,8 +546,12 @@
     builtins.license = _Printer(
         "license",
         "See http://www.python.org/%.3s/license.html" % sys.version,
-        ["LICENSE.txt", "LICENSE"],
-        [os.path.join(here, os.pardir), here, os.curdir],
+        ["LICENSE.txt",
+         "LICENSE"],
+        [os.path.join(here,
+                      os.pardir),
+         here,
+         os.curdir],
     )
 
 
@@ -606,13 +638,17 @@
         else:
             cpyver = "%d.%d.%d" % sys.version_info[:3]
         paths = [
-            os.path.join(sys.real_prefix, "lib_pypy"),
-            os.path.join(sys.real_prefix, "lib-python", cpyver)
+            os.path.join(sys.real_prefix,
+                         "lib_pypy"),
+            os.path.join(sys.real_prefix,
+                         "lib-python",
+                         cpyver)
         ]
         if sys.pypy_version_info < (1, 9):
             paths.insert(
                 1,
-                os.path.join(sys.real_prefix, "lib-python",
+                os.path.join(sys.real_prefix,
+                             "lib-python",
                              "modified-%s" % cpyver))
         hardcoded_relative_dirs = paths[:]  # for the special 'darwin' case below
         #
@@ -623,15 +659,20 @@
                 paths.append(plat_path)
     elif sys.platform == "win32":
         paths = [
-            os.path.join(sys.real_prefix, "Lib"),
-            os.path.join(sys.real_prefix, "DLLs")
+            os.path.join(sys.real_prefix,
+                         "Lib"),
+            os.path.join(sys.real_prefix,
+                         "DLLs")
         ]
     else:
         paths = [
-            os.path.join(sys.real_prefix, "lib", "python" + sys.version[:3])
+            os.path.join(sys.real_prefix,
+                         "lib",
+                         "python" + sys.version[:3])
         ]
         hardcoded_relative_dirs = paths[:]  # for the special 'darwin' case below
-        lib64_path = os.path.join(sys.real_prefix, "lib64",
+        lib64_path = os.path.join(sys.real_prefix,
+                                  "lib64",
                                   "python" + sys.version[:3])
         if os.path.exists(lib64_path):
             if _is_64bit:
@@ -648,8 +689,10 @@
         except AttributeError:
             # This is a non-multiarch aware Python.  Fallback to the old way.
             arch = sys.platform
-        plat_path = os.path.join(sys.real_prefix, "lib",
-                                 "python" + sys.version[:3], "plat-%s" % arch)
+        plat_path = os.path.join(sys.real_prefix,
+                                 "lib",
+                                 "python" + sys.version[:3],
+                                 "plat-%s" % arch)
         if os.path.exists(plat_path):
             paths.append(plat_path)
     # This is hardcoded in the Python executable, but
@@ -663,9 +706,10 @@
     # but relative to sys.prefix, so we have to fix them up:
     if sys.platform == "darwin":
         hardcoded_paths = [
-            os.path.join(relative_dir, module)
-            for relative_dir in hardcoded_relative_dirs
-            for module in ("plat-darwin", "plat-mac",
+            os.path.join(relative_dir,
+                         module) for relative_dir in hardcoded_relative_dirs
+            for module in ("plat-darwin",
+                           "plat-mac",
                            "plat-mac/lib-scriptpackages")
         ]
 
@@ -790,7 +834,8 @@
     if _is_jython:
         fixclasspath()
     GLOBAL_SITE_PACKAGES = not os.path.exists(
-        os.path.join(os.path.dirname(__file__), "no-global-site-packages.txt"))
+        os.path.join(os.path.dirname(__file__),
+                     "no-global-site-packages.txt"))
     if not GLOBAL_SITE_PACKAGES:
         ENABLE_USER_SITE = False
     if ENABLE_USER_SITE is None:
--- .\env\Lib\sre_compile.py	(original)
+++ .\env\Lib\sre_compile.py	(reformatted)
@@ -143,8 +143,8 @@
                 emit(ANY)
         elif op in REPEATING_CODES:
             if flags & SRE_FLAG_TEMPLATE:
-                raise error("internal: unsupported template operator %r" %
-                            (op, ))
+                raise error("internal: unsupported template operator %r" % (op,
+                                                                            ))
             if _simple(av[2]):
                 if op is MAX_REPEAT:
                     emit(REPEAT_ONE)
@@ -644,8 +644,8 @@
 
 
 def _hex_code(code):
-    return '[%s]' % ', '.join('%#0*x' % (_sre.CODESIZE * 2 + 2, x)
-                              for x in code)
+    return '[%s]' % ', '.join('%#0*x' % (_sre.CODESIZE * 2 + 2,
+                                         x) for x in code)
 
 
 def dis(code):
@@ -660,8 +660,9 @@
             if to is not None:
                 labels.add(to)
                 args += ('(to %d)' % (to, ), )
-            print('%*d%s ' %
-                  (offset_width, start, ':' if start in labels else '.'),
+            print('%*d%s ' % (offset_width,
+                              start,
+                              ':' if start in labels else '.'),
                   end='  ' * (level - 1))
             print(*args)
 
@@ -677,12 +678,21 @@
             op = code[i]
             i += 1
             op = OPCODES[op]
-            if op in (SUCCESS, FAILURE, ANY, ANY_ALL, MAX_UNTIL, MIN_UNTIL,
+            if op in (SUCCESS,
+                      FAILURE,
+                      ANY,
+                      ANY_ALL,
+                      MAX_UNTIL,
+                      MIN_UNTIL,
                       NEGATE):
                 print_(op)
-            elif op in (LITERAL, NOT_LITERAL, LITERAL_IGNORE,
-                        NOT_LITERAL_IGNORE, LITERAL_UNI_IGNORE,
-                        NOT_LITERAL_UNI_IGNORE, LITERAL_LOC_IGNORE,
+            elif op in (LITERAL,
+                        NOT_LITERAL,
+                        LITERAL_IGNORE,
+                        NOT_LITERAL_IGNORE,
+                        LITERAL_UNI_IGNORE,
+                        NOT_LITERAL_UNI_IGNORE,
+                        LITERAL_LOC_IGNORE,
                         NOT_LITERAL_LOC_IGNORE):
                 arg = code[i]
                 i += 1
@@ -715,7 +725,8 @@
                 arg = code[i]
                 i += 1
                 mapping = list(b''.join(
-                    x.to_bytes(_sre.CODESIZE, sys.byteorder)
+                    x.to_bytes(_sre.CODESIZE,
+                               sys.byteorder)
                     for x in code[i:i + 256 // _sre.CODESIZE]))
                 print_(op, arg, mapping)
                 i += 256 // _sre.CODESIZE
@@ -724,7 +735,10 @@
                     print_2(_hex_code(code[i:i + 256 // _CODEBITS]))
                     i += 256 // _CODEBITS
                 level -= 1
-            elif op in (MARK, GROUPREF, GROUPREF_IGNORE, GROUPREF_UNI_IGNORE,
+            elif op in (MARK,
+                        GROUPREF,
+                        GROUPREF_IGNORE,
+                        GROUPREF_UNI_IGNORE,
                         GROUPREF_LOC_IGNORE):
                 arg = code[i]
                 i += 1
@@ -775,7 +789,8 @@
                     prefix = code[start:start + prefix_len]
                     print_2('  prefix',
                             '[%s]' % ', '.join('%#02x' % x for x in prefix),
-                            '(%r)' % ''.join(map(chr, prefix)))
+                            '(%r)' % ''.join(map(chr,
+                                                 prefix)))
                     start += prefix_len
                     print_2('  overlap', code[start:start + prefix_len])
                     start += prefix_len
@@ -814,5 +829,9 @@
     for k, i in groupindex.items():
         indexgroup[i] = k
 
-    return _sre.compile(pattern, flags | p.pattern.flags, code,
-                        p.pattern.groups - 1, groupindex, tuple(indexgroup))
+    return _sre.compile(pattern,
+                        flags | p.pattern.flags,
+                        code,
+                        p.pattern.groups - 1,
+                        groupindex,
+                        tuple(indexgroup))
--- .\env\Lib\sre_constants.py	(original)
+++ .\env\Lib\sre_constants.py	(reformatted)
@@ -47,8 +47,7 @@
             self.lineno = pattern.count(newline, 0, pos) + 1
             self.colno = pos - pattern.rfind(newline, 0, pos)
             if newline in pattern:
-                msg = '%s (line %d, column %d)' % (msg, self.lineno,
-                                                   self.colno)
+                msg = '%s (line %d, column %d)' % (msg, self.lineno, self.colno)
         else:
             self.lineno = self.colno = None
         super().__init__(msg)
@@ -168,10 +167,7 @@
 
 AT_MULTILINE = {AT_BEGINNING: AT_BEGINNING_LINE, AT_END: AT_END_LINE}
 
-AT_LOCALE = {
-    AT_BOUNDARY: AT_LOC_BOUNDARY,
-    AT_NON_BOUNDARY: AT_LOC_NON_BOUNDARY
-}
+AT_LOCALE = {AT_BOUNDARY: AT_LOC_BOUNDARY, AT_NON_BOUNDARY: AT_LOC_NON_BOUNDARY}
 
 AT_UNICODE = {
     AT_BOUNDARY: AT_UNI_BOUNDARY,
--- .\env\Lib\sre_parse.py	(original)
+++ .\env\Lib\sre_parse.py	(reformatted)
@@ -20,8 +20,7 @@
 
 OCTDIGITS = frozenset("01234567")
 HEXDIGITS = frozenset("0123456789abcdefABCDEF")
-ASCIILETTERS = frozenset(
-    "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ")
+ASCIILETTERS = frozenset("abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ")
 
 WHITESPACE = frozenset(" \t\n\r\v\f")
 
@@ -29,14 +28,22 @@
 _UNITCODES = frozenset({ANY, RANGE, IN, LITERAL, NOT_LITERAL, CATEGORY})
 
 ESCAPES = {
-    r"\a": (LITERAL, ord("\a")),
-    r"\b": (LITERAL, ord("\b")),
-    r"\f": (LITERAL, ord("\f")),
-    r"\n": (LITERAL, ord("\n")),
-    r"\r": (LITERAL, ord("\r")),
-    r"\t": (LITERAL, ord("\t")),
-    r"\v": (LITERAL, ord("\v")),
-    r"\\": (LITERAL, ord("\\"))
+    r"\a": (LITERAL,
+            ord("\a")),
+    r"\b": (LITERAL,
+            ord("\b")),
+    r"\f": (LITERAL,
+            ord("\f")),
+    r"\n": (LITERAL,
+            ord("\n")),
+    r"\r": (LITERAL,
+            ord("\r")),
+    r"\t": (LITERAL,
+            ord("\t")),
+    r"\v": (LITERAL,
+            ord("\v")),
+    r"\\": (LITERAL,
+            ord("\\"))
 }
 
 CATEGORIES = {
@@ -94,7 +101,9 @@
             ogid = self.groupdict.get(name, None)
             if ogid is not None:
                 raise error("redefinition of group name %r as group %d; "
-                            "was group %d" % (name, gid, ogid))
+                            "was group %d" % (name,
+                                              gid,
+                                              ogid))
             self.groupdict[name] = gid
         return gid
 
@@ -259,7 +268,8 @@
             try:
                 char += self.decoded_string[index]
             except IndexError:
-                raise error("bad escape (end of pattern)", self.string,
+                raise error("bad escape (end of pattern)",
+                            self.string,
                             len(self.string) - 1) from None
         self.index = index + 1
         self.next = char
@@ -331,22 +341,19 @@
             # hexadecimal escape (exactly two digits)
             escape += source.getwhile(2, HEXDIGITS)
             if len(escape) != 4:
-                raise source.error("incomplete escape %s" % escape,
-                                   len(escape))
+                raise source.error("incomplete escape %s" % escape, len(escape))
             return LITERAL, int(escape[2:], 16)
         elif c == "u" and source.istext:
             # unicode escape (exactly four digits)
             escape += source.getwhile(4, HEXDIGITS)
             if len(escape) != 6:
-                raise source.error("incomplete escape %s" % escape,
-                                   len(escape))
+                raise source.error("incomplete escape %s" % escape, len(escape))
             return LITERAL, int(escape[2:], 16)
         elif c == "U" and source.istext:
             # unicode escape (exactly eight digits)
             escape += source.getwhile(8, HEXDIGITS)
             if len(escape) != 10:
-                raise source.error("incomplete escape %s" % escape,
-                                   len(escape))
+                raise source.error("incomplete escape %s" % escape, len(escape))
             c = int(escape[2:], 16)
             chr(c)  # raise ValueError for invalid code
             return LITERAL, c
@@ -357,7 +364,8 @@
             if c > 0o377:
                 raise source.error(
                     'octal escape value %s outside of '
-                    'range 0-0o377' % escape, len(escape))
+                    'range 0-0o377' % escape,
+                    len(escape))
             return LITERAL, c
         elif c in DIGITS:
             raise ValueError
@@ -384,22 +392,19 @@
             # hexadecimal escape
             escape += source.getwhile(2, HEXDIGITS)
             if len(escape) != 4:
-                raise source.error("incomplete escape %s" % escape,
-                                   len(escape))
+                raise source.error("incomplete escape %s" % escape, len(escape))
             return LITERAL, int(escape[2:], 16)
         elif c == "u" and source.istext:
             # unicode escape (exactly four digits)
             escape += source.getwhile(4, HEXDIGITS)
             if len(escape) != 6:
-                raise source.error("incomplete escape %s" % escape,
-                                   len(escape))
+                raise source.error("incomplete escape %s" % escape, len(escape))
             return LITERAL, int(escape[2:], 16)
         elif c == "U" and source.istext:
             # unicode escape (exactly eight digits)
             escape += source.getwhile(8, HEXDIGITS)
             if len(escape) != 10:
-                raise source.error("incomplete escape %s" % escape,
-                                   len(escape))
+                raise source.error("incomplete escape %s" % escape, len(escape))
             c = int(escape[2:], 16)
             chr(c)  # raise ValueError for invalid code
             return LITERAL, c
@@ -419,7 +424,8 @@
                     if c > 0o377:
                         raise source.error(
                             'octal escape value %s outside of '
-                            'range 0-0o377' % escape, len(escape))
+                            'range 0-0o377' % escape,
+                            len(escape))
                     return LITERAL, c
             # not an octal escape, so this is a group reference
             group = int(escape[1:])
@@ -459,8 +465,11 @@
     start = source.tell()
     while True:
         itemsappend(
-            _parse(source, state, verbose, nested + 1, not nested
-                   and not items))
+            _parse(source,
+                   state,
+                   verbose,
+                   nested + 1,
+                   not nested and not items))
         if not sourcematch("|"):
             break
 
@@ -557,8 +566,8 @@
             ##              pass # handle character classes
             if source.next == '[':
                 import warnings
-                warnings.warn('Possible nested set at position %d' %
-                              source.tell(),
+                warnings.warn('Possible nested set at position %d'
+                              % source.tell(),
                               FutureWarning,
                               stacklevel=nested + 6)
             negate = sourcematch("^")
@@ -575,13 +584,13 @@
                 else:
                     if set and this in '-&~|' and source.next == this:
                         import warnings
-                        warnings.warn(
-                            'Possible set %s at position %d' %
-                            ('difference' if this == '-' else 'intersection'
-                             if this == '&' else 'symmetric difference'
-                             if this == '~' else 'union', source.tell() - 1),
-                            FutureWarning,
-                            stacklevel=nested + 6)
+                        warnings.warn('Possible set %s at position %d' % (
+                            'difference' if this == '-' else
+                            'intersection' if this == '&' else
+                            'symmetric difference' if this == '~' else 'union',
+                            source.tell() - 1),
+                                      FutureWarning,
+                                      stacklevel=nested + 6)
                     code1 = LITERAL, _ord(this)
                 if sourcematch("-"):
                     # potential range
@@ -675,9 +684,8 @@
                         raise OverflowError(
                             "the repetition number is too large")
                     if max < min:
-                        raise source.error(
-                            "min repeat greater than max repeat",
-                            source.tell() - here)
+                        raise source.error("min repeat greater than max repeat",
+                                           source.tell() - here)
             else:
                 raise AssertionError("unsupported quantifier %r" % (char, ))
             # figure out which item to repeat
@@ -778,9 +786,8 @@
                         if lookbehindgroups is None:
                             state.lookbehindgroups = None
                     if not sourcematch(")"):
-                        raise source.error(
-                            "missing ), unterminated subpattern",
-                            source.tell() - start)
+                        raise source.error("missing ), unterminated subpattern",
+                                           source.tell() - start)
                     if char == "=":
                         subpatternappend((ASSERT, (dir, p)))
                     else:
@@ -802,8 +809,7 @@
                                 raise ValueError
                         except ValueError:
                             msg = "bad character in group name %r" % condname
-                            raise source.error(msg,
-                                               len(condname) + 1) from None
+                            raise source.error(msg, len(condname) + 1) from None
                         if not condgroup:
                             raise source.error("bad group number",
                                                len(condname) + 1)
@@ -821,11 +827,12 @@
                     else:
                         item_no = None
                     if not source.match(")"):
-                        raise source.error(
-                            "missing ), unterminated subpattern",
-                            source.tell() - start)
-                    subpatternappend(
-                        (GROUPREF_EXISTS, (condgroup, item_yes, item_no)))
+                        raise source.error("missing ), unterminated subpattern",
+                                           source.tell() - start)
+                    subpatternappend((GROUPREF_EXISTS,
+                                      (condgroup,
+                                       item_yes,
+                                       item_no)))
                     continue
 
                 elif char in FLAGS or char == "-":
@@ -1068,7 +1075,8 @@
                         if c > 0o377:
                             raise s.error(
                                 'octal escape value %s outside of '
-                                'range 0-0o377' % this, len(this))
+                                'range 0-0o377' % this,
+                                len(this))
                         lappend(chr(c))
                 if not isoctal:
                     addgroup(int(this[1:]), len(this) - 1)
--- .\env\Lib\stat.py	(original)
+++ .\env\Lib\stat.py	(reformatted)
@@ -119,14 +119,54 @@
 SF_NOUNLINK = 0x00100000  # file may not be renamed or deleted
 SF_SNAPSHOT = 0x00200000  # file is a snapshot file
 
-_filemode_table = (((S_IFLNK, "l"), (S_IFREG, "-"), (S_IFBLK, "b"),
-                    (S_IFDIR, "d"), (S_IFCHR, "c"),
-                    (S_IFIFO, "p")), ((S_IRUSR, "r"), ), ((S_IWUSR, "w"), ),
-                   ((S_IXUSR | S_ISUID, "s"), (S_ISUID, "S"),
-                    (S_IXUSR, "x")), ((S_IRGRP, "r"), ), ((S_IWGRP, "w"), ),
-                   ((S_IXGRP | S_ISGID, "s"), (S_ISGID, "S"),
-                    (S_IXGRP, "x")), ((S_IROTH, "r"), ), ((S_IWOTH, "w"), ),
-                   ((S_IXOTH | S_ISVTX, "t"), (S_ISVTX, "T"), (S_IXOTH, "x")))
+_filemode_table = (((S_IFLNK,
+                     "l"),
+                    (S_IFREG,
+                     "-"),
+                    (S_IFBLK,
+                     "b"),
+                    (S_IFDIR,
+                     "d"),
+                    (S_IFCHR,
+                     "c"),
+                    (S_IFIFO,
+                     "p")),
+                   ((S_IRUSR,
+                     "r"),
+                    ),
+                   ((S_IWUSR,
+                     "w"),
+                    ),
+                   ((S_IXUSR | S_ISUID,
+                     "s"),
+                    (S_ISUID,
+                     "S"),
+                    (S_IXUSR,
+                     "x")),
+                   ((S_IRGRP,
+                     "r"),
+                    ),
+                   ((S_IWGRP,
+                     "w"),
+                    ),
+                   ((S_IXGRP | S_ISGID,
+                     "s"),
+                    (S_ISGID,
+                     "S"),
+                    (S_IXGRP,
+                     "x")),
+                   ((S_IROTH,
+                     "r"),
+                    ),
+                   ((S_IWOTH,
+                     "w"),
+                    ),
+                   ((S_IXOTH | S_ISVTX,
+                     "t"),
+                    (S_ISVTX,
+                     "T"),
+                    (S_IXOTH,
+                     "x")))
 
 
 def filemode(mode):
--- .\env\Lib\tarfile.py	(original)
+++ .\env\Lib\tarfile.py	(reformatted)
@@ -67,9 +67,20 @@
 
 # from tarfile import *
 __all__ = [
-    "TarFile", "TarInfo", "is_tarfile", "TarError", "ReadError",
-    "CompressionError", "StreamError", "ExtractError", "HeaderError",
-    "ENCODING", "USTAR_FORMAT", "GNU_FORMAT", "PAX_FORMAT", "DEFAULT_FORMAT",
+    "TarFile",
+    "TarInfo",
+    "is_tarfile",
+    "TarError",
+    "ReadError",
+    "CompressionError",
+    "StreamError",
+    "ExtractError",
+    "HeaderError",
+    "ENCODING",
+    "USTAR_FORMAT",
+    "GNU_FORMAT",
+    "PAX_FORMAT",
+    "DEFAULT_FORMAT",
     "open"
 ]
 
@@ -113,9 +124,18 @@
 # tarfile constants
 #---------------------------------------------------------
 # File types that tarfile supports:
-SUPPORTED_TYPES = (REGTYPE, AREGTYPE, LNKTYPE, SYMTYPE, DIRTYPE, FIFOTYPE,
-                   CONTTYPE, CHRTYPE, BLKTYPE, GNUTYPE_LONGNAME,
-                   GNUTYPE_LONGLINK, GNUTYPE_SPARSE)
+SUPPORTED_TYPES = (REGTYPE,
+                   AREGTYPE,
+                   LNKTYPE,
+                   SYMTYPE,
+                   DIRTYPE,
+                   FIFOTYPE,
+                   CONTTYPE,
+                   CHRTYPE,
+                   BLKTYPE,
+                   GNUTYPE_LONGNAME,
+                   GNUTYPE_LONGLINK,
+                   GNUTYPE_SPARSE)
 
 # File types that will be treated as a regular file.
 REGULAR_TYPES = (REGTYPE, AREGTYPE, CONTTYPE, GNUTYPE_SPARSE)
@@ -124,7 +144,13 @@
 GNU_TYPES = (GNUTYPE_LONGNAME, GNUTYPE_LONGLINK, GNUTYPE_SPARSE)
 
 # Fields from a pax header that override a TarInfo attribute.
-PAX_FIELDS = ("path", "linkpath", "size", "mtime", "uid", "gid", "uname",
+PAX_FIELDS = ("path",
+              "linkpath",
+              "size",
+              "mtime",
+              "uid",
+              "gid",
+              "uname",
               "gname")
 
 # Fields from a pax header that are affected by hdrcharset.
@@ -264,8 +290,7 @@
 def filemode(mode):
     """Deprecated in this location; use stat.filemode."""
     import warnings
-    warnings.warn("deprecated in favor of stat.filemode", DeprecationWarning,
-                  2)
+    warnings.warn("deprecated in favor of stat.filemode", DeprecationWarning, 2)
     return stat.filemode(mode)
 
 
@@ -430,8 +455,7 @@
                     self.cmp = lzma.LZMACompressor()
 
             elif comptype != "tar":
-                raise CompressionError("unknown compression type %r" %
-                                       comptype)
+                raise CompressionError("unknown compression type %r" % comptype)
 
         except:
             if not self._extfileobj:
@@ -446,9 +470,11 @@
     def _init_write_gz(self):
         """Initialize for writing with gzip compression.
         """
-        self.cmp = self.zlib.compressobj(9, self.zlib.DEFLATED,
+        self.cmp = self.zlib.compressobj(9,
+                                         self.zlib.DEFLATED,
                                          -self.zlib.MAX_WBITS,
-                                         self.zlib.DEF_MEM_LEVEL, 0)
+                                         self.zlib.DEF_MEM_LEVEL,
+                                         0)
         timestamp = struct.pack("<L", int(time.time()))
         self.__write(b"\037\213\010\010" + timestamp + b"\002\377")
         if self.name.endswith(".gz"):
@@ -492,8 +518,7 @@
                 self.buf = b""
                 if self.comptype == "gz":
                     self.fileobj.write(struct.pack("<L", self.crc))
-                    self.fileobj.write(struct.pack("<L",
-                                                   self.pos & 0xffffFFFF))
+                    self.fileobj.write(struct.pack("<L", self.pos & 0xffffFFFF))
         finally:
             if not self._extfileobj:
                 self.fileobj.close()
@@ -747,8 +772,10 @@
 
 class ExFileObject(io.BufferedReader):
     def __init__(self, tarfile, tarinfo):
-        fileobj = _FileInFile(tarfile.fileobj, tarinfo.offset_data,
-                              tarinfo.size, tarinfo.sparse)
+        fileobj = _FileInFile(tarfile.fileobj,
+                              tarinfo.offset_data,
+                              tarinfo.size,
+                              tarinfo.sparse)
         super().__init__(fileobj)
 
 
@@ -766,10 +793,26 @@
        usually created internally.
     """
 
-    __slots__ = ("name", "mode", "uid", "gid", "size", "mtime", "chksum",
-                 "type", "linkname", "uname", "gname", "devmajor", "devminor",
-                 "offset", "offset_data", "pax_headers", "sparse", "tarfile",
-                 "_sparse_structs", "_link_target")
+    __slots__ = ("name",
+                 "mode",
+                 "uid",
+                 "gid",
+                 "size",
+                 "mtime",
+                 "chksum",
+                 "type",
+                 "linkname",
+                 "uname",
+                 "gname",
+                 "devmajor",
+                 "devminor",
+                 "offset",
+                 "offset_data",
+                 "pax_headers",
+                 "sparse",
+                 "tarfile",
+                 "_sparse_structs",
+                 "_link_target")
 
     def __init__(self, name=""):
         """Construct a TarInfo object. name is the optional name
@@ -814,8 +857,7 @@
         self.linkname = linkname
 
     def __repr__(self):
-        return "<%s %r at %#x>" % (self.__class__.__name__, self.name,
-                                   id(self))
+        return "<%s %r at %#x>" % (self.__class__.__name__, self.name, id(self))
 
     def get_info(self):
         """Return the TarInfo's attributes as a dictionary.
@@ -880,12 +922,15 @@
         buf = b""
         if len(info["linkname"].encode(encoding, errors)) > LENGTH_LINK:
             buf += self._create_gnu_long_header(info["linkname"],
-                                                GNUTYPE_LONGLINK, encoding,
+                                                GNUTYPE_LONGLINK,
+                                                encoding,
                                                 errors)
 
         if len(info["name"].encode(encoding, errors)) > LENGTH_NAME:
-            buf += self._create_gnu_long_header(info["name"], GNUTYPE_LONGNAME,
-                                                encoding, errors)
+            buf += self._create_gnu_long_header(info["name"],
+                                                GNUTYPE_LONGNAME,
+                                                encoding,
+                                                errors)
 
         return buf + self._create_header(info, GNU_FORMAT, encoding, errors)
 
@@ -934,13 +979,13 @@
 
         # Create a pax extended header if necessary.
         if pax_headers:
-            buf = self._create_pax_generic_header(pax_headers, XHDTYPE,
+            buf = self._create_pax_generic_header(pax_headers,
+                                                  XHDTYPE,
                                                   encoding)
         else:
             buf = b""
 
-        return buf + self._create_header(info, USTAR_FORMAT, "ascii",
-                                         "replace")
+        return buf + self._create_header(info, USTAR_FORMAT, "ascii", "replace")
 
     @classmethod
     def create_pax_global_header(cls, pax_headers):
@@ -1181,7 +1226,8 @@
 
         # Patch the TarInfo object with saved global
         # header information.
-        self._apply_pax_info(tarfile.pax_headers, tarfile.encoding,
+        self._apply_pax_info(tarfile.pax_headers,
+                             tarfile.encoding,
                              tarfile.errors)
 
         return self
@@ -1291,14 +1337,19 @@
             # hdrcharset=BINARY header).
             # We first try the strict standard encoding, and if that fails we
             # fall back on the user's encoding and error handler.
-            keyword = self._decode_pax_field(keyword, "utf-8", "utf-8",
+            keyword = self._decode_pax_field(keyword,
+                                             "utf-8",
+                                             "utf-8",
                                              tarfile.errors)
             if keyword in PAX_NAME_FIELDS:
-                value = self._decode_pax_field(value, encoding,
+                value = self._decode_pax_field(value,
+                                               encoding,
                                                tarfile.encoding,
                                                tarfile.errors)
             else:
-                value = self._decode_pax_field(value, "utf-8", "utf-8",
+                value = self._decode_pax_field(value,
+                                               "utf-8",
+                                               "utf-8",
                                                tarfile.errors)
 
             pax_headers[keyword] = value
@@ -1396,7 +1447,10 @@
 
         self.pax_headers = pax_headers.copy()
 
-    def _decode_pax_field(self, value, encoding, fallback_encoding,
+    def _decode_pax_field(self,
+                          value,
+                          encoding,
+                          fallback_encoding,
                           fallback_errors):
         """Decode a single field from a pax record.
         """
@@ -1510,8 +1564,11 @@
             fileobj = bltn_open(name, self._mode)
             self._extfileobj = False
         else:
-            if (name is None and hasattr(fileobj, "name")
-                    and isinstance(fileobj.name, (str, bytes))):
+            if (name is None and hasattr(fileobj,
+                                         "name")
+                    and isinstance(fileobj.name,
+                                   (str,
+                                    bytes))):
                 name = fileobj.name
             if hasattr(fileobj, "mode"):
                 self._mode = fileobj.mode
@@ -1575,8 +1632,8 @@
                 self._loaded = True
 
                 if self.pax_headers:
-                    buf = self.tarinfo.create_pax_global_header(
-                        self.pax_headers.copy())
+                    buf = self.tarinfo.create_pax_global_header(self.pax_headers
+                                                                .copy())
                     self.fileobj.write(buf)
                     self.offset += len(buf)
         except:
@@ -1668,8 +1725,7 @@
             if comptype in cls.OPEN_METH:
                 func = getattr(cls, cls.OPEN_METH[comptype])
             else:
-                raise CompressionError("unknown compression type %r" %
-                                       comptype)
+                raise CompressionError("unknown compression type %r" % comptype)
             return func(name, filemode, fileobj, **kwargs)
 
         elif "|" in mode:
@@ -1969,9 +2025,8 @@
                 _safe_print("%s/%s" % (tarinfo.uname or tarinfo.uid,
                                        tarinfo.gname or tarinfo.gid))
                 if tarinfo.ischr() or tarinfo.isblk():
-                    _safe_print("%10s" %
-                                ("%d,%d" %
-                                 (tarinfo.devmajor, tarinfo.devminor)))
+                    _safe_print("%10s" % ("%d,%d" % (tarinfo.devmajor,
+                                                     tarinfo.devminor)))
                 else:
                     _safe_print("%10d" % tarinfo.size)
                 _safe_print("%d-%02d-%02d %02d:%02d:%02d" \
@@ -2031,8 +2086,10 @@
             self.addfile(tarinfo)
             if recursive:
                 for f in sorted(os.listdir(name)):
-                    self.add(os.path.join(name, f),
-                             os.path.join(arcname, f),
+                    self.add(os.path.join(name,
+                                          f),
+                             os.path.join(arcname,
+                                          f),
                              recursive,
                              filter=filter)
 
@@ -2128,7 +2185,8 @@
 
         try:
             self._extract_member(tarinfo,
-                                 os.path.join(path, tarinfo.name),
+                                 os.path.join(path,
+                                              tarinfo.name),
                                  set_attrs=set_attrs,
                                  numeric_owner=numeric_owner)
         except OSError as e:
@@ -2282,8 +2340,10 @@
         else:
             mode |= stat.S_IFCHR
 
-        os.mknod(targetpath, mode,
-                 os.makedev(tarinfo.devmajor, tarinfo.devminor))
+        os.mknod(targetpath,
+                 mode,
+                 os.makedev(tarinfo.devmajor,
+                            tarinfo.devminor))
 
     def makelink(self, tarinfo, targetpath):
         """Make a (symbolic) link called targetpath. If it cannot be created
@@ -2461,7 +2521,8 @@
             # Always search the entire archive.
             linkname = "/".join(
                 filter(None,
-                       (os.path.dirname(tarinfo.name), tarinfo.linkname)))
+                       (os.path.dirname(tarinfo.name),
+                        tarinfo.linkname)))
             limit = None
         else:
             # Search the archive before the link, because a hard link is
@@ -2562,12 +2623,14 @@
     group.add_argument('-e',
                        '--extract',
                        nargs='+',
-                       metavar=('<tarfile>', '<output_dir>'),
+                       metavar=('<tarfile>',
+                                '<output_dir>'),
                        help='Extract tarfile into target dir')
     group.add_argument('-c',
                        '--create',
                        nargs='+',
-                       metavar=('<name>', '<file>'),
+                       metavar=('<name>',
+                                '<file>'),
                        help='Create tarfile from sources')
     group.add_argument('-t',
                        '--test',
@@ -2611,7 +2674,8 @@
                     msg = '{!r} file is extracted.'.format(src)
                 else:
                     msg = ('{!r} file is extracted '
-                           'into {!r} directory.').format(src, curdir)
+                           'into {!r} directory.').format(src,
+                                                          curdir)
                 print(msg)
         else:
             parser.exit(1, '{!r} is not a tar archive.\n'.format(src))
--- .\env\Lib\tempfile.py	(original)
+++ .\env\Lib\tempfile.py	(reformatted)
@@ -172,14 +172,18 @@
     # First, try the environment.
     for envname in 'TMPDIR', 'TEMP', 'TMP':
         dirname = _os.getenv(envname)
-        if dirname: dirlist.append(dirname)
+        if dirname:
+            dirlist.append(dirname)
 
     # Failing that, try OS-specific locations.
     if _os.name == 'nt':
         dirlist.extend([
             _os.path.expanduser(r'~\AppData\Local\Temp'),
-            _os.path.expandvars(r'%SYSTEMROOT%\Temp'), r'c:\temp', r'c:\tmp',
-            r'\temp', r'\tmp'
+            _os.path.expandvars(r'%SYSTEMROOT%\Temp'),
+            r'c:\temp',
+            r'c:\tmp',
+            r'\temp',
+            r'\tmp'
         ])
     else:
         dirlist.extend(['/tmp', '/var/tmp', '/usr/tmp'])
@@ -229,13 +233,15 @@
                 # This exception is thrown when a directory with the chosen name
                 # already exists on windows.
                 if (_os.name == 'nt' and _os.path.isdir(dir)
-                        and _os.access(dir, _os.W_OK)):
+                        and _os.access(dir,
+                                       _os.W_OK)):
                     continue
                 break  # no point trying more names in this directory
             except OSError:
                 break  # no point trying more names in this directory
     raise FileNotFoundError(
-        _errno.ENOENT, "No usable temporary directory found in %s" % dirlist)
+        _errno.ENOENT,
+        "No usable temporary directory found in %s" % dirlist)
 
 
 _name_sequence = None
@@ -273,7 +279,8 @@
             # This exception is thrown when a directory with the chosen name
             # already exists on windows.
             if (_os.name == 'nt' and _os.path.isdir(dir)
-                    and _os.access(dir, _os.W_OK)):
+                    and _os.access(dir,
+                                   _os.W_OK)):
                 continue
             else:
                 raise
@@ -386,7 +393,8 @@
             # This exception is thrown when a directory with the chosen name
             # already exists on windows.
             if (_os.name == 'nt' and _os.path.isdir(dir)
-                    and _os.access(dir, _os.W_OK)):
+                    and _os.access(dir,
+                                   _os.W_OK)):
                 continue
             else:
                 raise
@@ -614,8 +622,7 @@
         """
         global _O_TMPFILE_WORKS
 
-        prefix, suffix, dir, output_type = _sanitize_params(
-            prefix, suffix, dir)
+        prefix, suffix, dir, output_type = _sanitize_params(prefix, suffix, dir)
 
         flags = _bin_openflags
         if _O_TMPFILE_WORKS:
@@ -699,13 +706,15 @@
         }
 
     def _check(self, file):
-        if self._rolled: return
+        if self._rolled:
+            return
         max_size = self._max_size
         if max_size and file.tell() > max_size:
             self.rollover()
 
     def rollover(self):
-        if self._rolled: return
+        if self._rolled:
+            return
         file = self._file
         newfile = self._file = TemporaryFile(**self._TemporaryFileArgs)
         del self._TemporaryFileArgs
--- .\env\Lib\token.py	(original)
+++ .\env\Lib\token.py	(reformatted)
@@ -77,8 +77,9 @@
 
 tok_name = {
     value: name
-    for name, value in globals().items()
-    if isinstance(value, int) and not name.startswith('_')
+    for name,
+    value in globals().items() if isinstance(value,
+                                             int) and not name.startswith('_')
 }
 __all__.extend(tok_name.values())
 
--- .\env\Lib\tokenize.py	(original)
+++ .\env\Lib\tokenize.py	(reformatted)
@@ -39,7 +39,10 @@
 
 import token
 __all__ = token.__all__ + [
-    "tokenize", "detect_encoding", "untokenize", "TokenInfo"
+    "tokenize",
+    "detect_encoding",
+    "untokenize",
+    "TokenInfo"
 ]
 del token
 
@@ -94,11 +97,12 @@
 
 
 class TokenInfo(
-        collections.namedtuple('TokenInfo', 'type string start end line')):
+        collections.namedtuple('TokenInfo',
+                               'type string start end line')):
     def __repr__(self):
         annotated_type = '%d (%s)' % (self.type, tok_name[self.type])
-        return ('TokenInfo(type=%s, string=%r, start=%r, end=%r, line=%r)' %
-                self._replace(type=annotated_type))
+        return ('TokenInfo(type=%s, string=%r, start=%r, end=%r, line=%r)'
+                % self._replace(type=annotated_type))
 
     @property
     def exact_type(self):
@@ -182,8 +186,14 @@
 # Because of leftmost-then-longest match semantics, be sure to put the
 # longest operators first (e.g., if = came before ==, == would get
 # recognized as two instances of =).
-Operator = group(r"\*\*=?", r">>=?", r"<<=?", r"!=", r"//=?", r"->",
-                 r"[+\-*/%&@|^=<>]=?", r"~")
+Operator = group(r"\*\*=?",
+                 r">>=?",
+                 r"<<=?",
+                 r"!=",
+                 r"//=?",
+                 r"->",
+                 r"[+\-*/%&@|^=<>]=?",
+                 r"~")
 
 Bracket = '[][(){}]'
 Special = group(r'\r?\n', r'\.\.\.', r'[:;.,@]')
@@ -194,8 +204,10 @@
 
 # First (or only) line of ' or " string.
 ContStr = group(
-    StringPrefix + r"'[^\n'\\]*(?:\\.[^\n'\\]*)*" + group("'", r'\\\r?\n'),
-    StringPrefix + r'"[^\n"\\]*(?:\\.[^\n"\\]*)*' + group('"', r'\\\r?\n'))
+    StringPrefix + r"'[^\n'\\]*(?:\\.[^\n'\\]*)*" + group("'",
+                                                          r'\\\r?\n'),
+    StringPrefix + r'"[^\n"\\]*(?:\\.[^\n"\\]*)*' + group('"',
+                                                          r'\\\r?\n'))
 PseudoExtras = group(r'\\\r?\n|\Z', Comment, Triple)
 PseudoToken = Whitespace + group(PseudoExtras, Number, Funny, ContStr, Name)
 
@@ -240,9 +252,11 @@
     def add_whitespace(self, start):
         row, col = start
         if row < self.prev_row or row == self.prev_row and col < self.prev_col:
-            raise ValueError(
-                "start ({},{}) precedes previous end ({},{})".format(
-                    row, col, self.prev_row, self.prev_col))
+            raise ValueError("start ({},{}) precedes previous end ({},{})"
+                             .format(row,
+                                     col,
+                                     self.prev_row,
+                                     self.prev_col))
         row_offset = row - self.prev_row
         if row_offset:
             self.tokens.append("\\\n" * row_offset)
@@ -418,8 +432,7 @@
             if filename is None:
                 msg = "unknown encoding: " + encoding
             else:
-                msg = "unknown encoding for {!r}: {}".format(
-                    filename, encoding)
+                msg = "unknown encoding for {!r}: {}".format(filename, encoding)
             raise SyntaxError(msg)
 
         if bom_found:
@@ -538,13 +551,21 @@
             endmatch = endprog.match(line)
             if endmatch:
                 pos = end = endmatch.end(0)
-                yield TokenInfo(STRING, contstr + line[:end], strstart,
-                                (lnum, end), contline + line)
+                yield TokenInfo(STRING,
+                                contstr + line[:end],
+                                strstart,
+                                (lnum,
+                                 end),
+                                contline + line)
                 contstr, needcont = '', 0
                 contline = None
             elif needcont and line[-2:] != '\\\n' and line[-3:] != '\\\r\n':
-                yield TokenInfo(ERRORTOKEN, contstr + line, strstart,
-                                (lnum, len(line)), contline)
+                yield TokenInfo(ERRORTOKEN,
+                                contstr + line,
+                                strstart,
+                                (lnum,
+                                 len(line)),
+                                contline)
                 contstr = ''
                 contline = None
                 continue
@@ -554,7 +575,8 @@
                 continue
 
         elif parenlev == 0 and not continued:  # new statement
-            if not line: break
+            if not line:
+                break
             column = 0
             while pos < max:  # measure leading whitespace
                 if line[pos] == ' ':
@@ -572,23 +594,41 @@
             if line[pos] in '#\r\n':  # skip comments or blank lines
                 if line[pos] == '#':
                     comment_token = line[pos:].rstrip('\r\n')
-                    yield TokenInfo(COMMENT, comment_token, (lnum, pos),
-                                    (lnum, pos + len(comment_token)), line)
+                    yield TokenInfo(COMMENT,
+                                    comment_token,
+                                    (lnum,
+                                     pos),
+                                    (lnum,
+                                     pos + len(comment_token)),
+                                    line)
                     pos += len(comment_token)
 
-                yield TokenInfo(NL, line[pos:], (lnum, pos), (lnum, len(line)),
+                yield TokenInfo(NL,
+                                line[pos:],
+                                (lnum,
+                                 pos),
+                                (lnum,
+                                 len(line)),
                                 line)
                 continue
 
             if column > indents[-1]:  # count indents or dedents
                 indents.append(column)
-                yield TokenInfo(INDENT, line[:pos], (lnum, 0), (lnum, pos),
+                yield TokenInfo(INDENT,
+                                line[:pos],
+                                (lnum,
+                                 0),
+                                (lnum,
+                                 pos),
                                 line)
             while column < indents[-1]:
                 if column not in indents:
                     raise IndentationError(
                         "unindent does not match any outer indentation level",
-                        ("<tokenize>", lnum, pos, line))
+                        ("<tokenize>",
+                         lnum,
+                         pos,
+                         line))
                 indents = indents[:-1]
 
                 yield TokenInfo(DEDENT, '', (lnum, pos), (lnum, pos), line)
@@ -673,14 +713,24 @@
                         parenlev -= 1
                     yield TokenInfo(OP, token, spos, epos, line)
             else:
-                yield TokenInfo(ERRORTOKEN, line[pos], (lnum, pos),
-                                (lnum, pos + 1), line)
+                yield TokenInfo(ERRORTOKEN,
+                                line[pos],
+                                (lnum,
+                                 pos),
+                                (lnum,
+                                 pos + 1),
+                                line)
                 pos += 1
 
     # Add an implicit NEWLINE if the input doesn't end in one
     if last_line and last_line[-1] not in '\r\n':
-        yield TokenInfo(NEWLINE, '', (lnum - 1, len(last_line)),
-                        (lnum - 1, len(last_line) + 1), '')
+        yield TokenInfo(NEWLINE,
+                        '',
+                        (lnum - 1,
+                         len(last_line)),
+                        (lnum - 1,
+                         len(last_line) + 1),
+                        '')
     for indent in indents[1:]:  # pop remaining indent levels
         yield TokenInfo(DEDENT, '', (lnum, 0), (lnum, 0), '')
     yield TokenInfo(ENDMARKER, '', (lnum, 0), (lnum, 0), '')
@@ -738,8 +788,9 @@
             if args.exact:
                 token_type = token.exact_type
             token_range = "%d,%d-%d,%d:" % (token.start + token.end)
-            print("%-20s%-15s%-15r" %
-                  (token_range, tok_name[token_type], token.string))
+            print("%-20s%-15s%-15r" % (token_range,
+                                       tok_name[token_type],
+                                       token.string))
     except IndentationError as err:
         line, column = err.args[1][1:3]
         error(err.args[0], filename, (line, column))
--- .\env\Lib\types.py	(original)
+++ .\env\Lib\types.py	(reformatted)
@@ -183,7 +183,9 @@
         self.overwrite_doc = doc is None
         # support for abstract methods
         self.__isabstractmethod__ = bool(
-            getattr(fget, '__isabstractmethod__', False))
+            getattr(fget,
+                    '__isabstractmethod__',
+                    False))
 
     def __get__(self, instance, ownerclass=None):
         if instance is None:
@@ -276,8 +278,9 @@
     if not callable(func):
         raise TypeError('types.coroutine() expects a callable')
 
-    if (func.__class__ is FunctionType
-            and getattr(func, '__code__', None).__class__ is CodeType):
+    if (func.__class__ is FunctionType and getattr(func,
+                                                   '__code__',
+                                                   None).__class__ is CodeType):
 
         co_flags = func.__code__.co_flags
 
@@ -324,8 +327,10 @@
                 and coro.gi_code.co_flags & 0x100):
             # 'coro' is a native coroutine object or an iterable coroutine
             return coro
-        if (isinstance(coro, _collections_abc.Generator)
-                and not isinstance(coro, _collections_abc.Coroutine)):
+        if (isinstance(coro,
+                       _collections_abc.Generator)
+                and not isinstance(coro,
+                                   _collections_abc.Coroutine)):
             # 'coro' is either a pure Python generator iterator, or it
             # implements collections.abc.Generator (and does not implement
             # collections.abc.Coroutine).
--- .\env\Lib\warnings.py	(original)
+++ .\env\Lib\warnings.py	(reformatted)
@@ -3,8 +3,14 @@
 import sys
 
 __all__ = [
-    "warn", "warn_explicit", "showwarning", "formatwarning", "filterwarnings",
-    "simplefilter", "resetwarnings", "catch_warnings"
+    "warn",
+    "warn_explicit",
+    "showwarning",
+    "formatwarning",
+    "filterwarnings",
+    "simplefilter",
+    "resetwarnings",
+    "catch_warnings"
 ]
 
 
@@ -76,8 +82,8 @@
         if tb is not None:
             s += 'Object allocated at (most recent call last):\n'
             for frame in tb:
-                s += ('  File "%s", lineno %s\n' %
-                      (frame.filename, frame.lineno))
+                s += ('  File "%s", lineno %s\n' % (frame.filename,
+                                                    frame.lineno))
 
                 try:
                     if linecache is not None:
@@ -112,7 +118,11 @@
                 raise TypeError("warnings.showwarning() must be set to a "
                                 "function or method")
 
-            sw(msg.message, msg.category, msg.filename, msg.lineno, msg.file,
+            sw(msg.message,
+               msg.category,
+               msg.filename,
+               msg.lineno,
+               msg.file,
                msg.line)
             return
     _showwarnmsg_impl(msg)
@@ -262,7 +272,8 @@
 def _getaction(action):
     if not action:
         return "default"
-    if action == "all": return "always"  # Alias
+    if action == "all":
+        return "always"  # Alias
     for a in ('default', 'always', 'ignore', 'module', 'once', 'error'):
         if a.startswith(action):
             return a
@@ -278,8 +289,8 @@
         try:
             cat = eval(category)
         except NameError:
-            raise _OptionError("unknown warning category: %r" %
-                               (category, )) from None
+            raise _OptionError("unknown warning category: %r" % (category,
+                                                                 )) from None
     else:
         i = category.rfind(".")
         module = category[:i]
@@ -287,13 +298,12 @@
         try:
             m = __import__(module, None, None, [klass])
         except ImportError:
-            raise _OptionError("invalid module name: %r" %
-                               (module, )) from None
+            raise _OptionError("invalid module name: %r" % (module, )) from None
         try:
             cat = getattr(m, klass)
         except AttributeError:
-            raise _OptionError("unknown warning category: %r" %
-                               (category, )) from None
+            raise _OptionError("unknown warning category: %r" % (category,
+                                                                 )) from None
     if not issubclass(cat, Warning):
         raise _OptionError("invalid warning category: %r" % (category, ))
     return cat
@@ -363,8 +373,14 @@
         if not filename:
             filename = module
     registry = globals.setdefault("__warningregistry__", {})
-    warn_explicit(message, category, filename, lineno, module, registry,
-                  globals, source)
+    warn_explicit(message,
+                  category,
+                  filename,
+                  lineno,
+                  module,
+                  registry,
+                  globals,
+                  source)
 
 
 def warn_explicit(message,
@@ -398,7 +414,8 @@
     # Search the filters
     for item in filters:
         action, msg, cat, mod, ln = item
-        if ((msg is None or msg.match(text)) and issubclass(category, cat)
+        if ((msg is None or msg.match(text)) and issubclass(category,
+                                                            cat)
                 and (mod is None or mod.match(module))
                 and (ln == 0 or lineno == ln)):
             break
@@ -434,9 +451,9 @@
         registry[key] = 1
     else:
         # Unrecognized actions are errors
-        raise RuntimeError(
-            "Unrecognized action (%r) in warnings.filters:\n %s" %
-            (action, item))
+        raise RuntimeError("Unrecognized action (%r) in warnings.filters:\n %s"
+                           % (action,
+                              item))
     # Print message and context
     msg = WarningMessage(message, category, filename, lineno, source)
     _showwarnmsg(msg)
@@ -444,8 +461,13 @@
 
 class WarningMessage(object):
 
-    _WARNING_DETAILS = ("message", "category", "filename", "lineno", "file",
-                        "line", "source")
+    _WARNING_DETAILS = ("message",
+                        "category",
+                        "filename",
+                        "lineno",
+                        "file",
+                        "line",
+                        "source")
 
     def __init__(self,
                  message,
@@ -466,8 +488,11 @@
 
     def __str__(self):
         return ("{message : %r, category : %r, filename : %r, lineno : %s, "
-                "line : %r}" % (self.message, self._category_name,
-                                self.filename, self.lineno, self.line))
+                "line : %r}" % (self.message,
+                                self._category_name,
+                                self.filename,
+                                self.lineno,
+                                self.line))
 
 
 class catch_warnings(object):
@@ -566,8 +591,12 @@
 # - a line number for the line being warning, or 0 to mean any line
 # If either if the compiled regexs are None, match anything.
 try:
-    from _warnings import (filters, _defaultaction, _onceregistry, warn,
-                           warn_explicit, _filters_mutated)
+    from _warnings import (filters,
+                           _defaultaction,
+                           _onceregistry,
+                           warn,
+                           warn_explicit,
+                           _filters_mutated)
     defaultaction = _defaultaction
     onceregistry = _onceregistry
     _warnings_defaults = True
--- .\env\Lib\weakref.py	(original)
+++ .\env\Lib\weakref.py	(reformatted)
@@ -9,8 +9,13 @@
 # they are called this instead of "ref" to avoid name collisions with
 # the module-global ref() function imported from _weakref.
 
-from _weakref import (getweakrefcount, getweakrefs, ref, proxy,
-                      CallableProxyType, ProxyType, ReferenceType,
+from _weakref import (getweakrefcount,
+                      getweakrefs,
+                      ref,
+                      proxy,
+                      CallableProxyType,
+                      ProxyType,
+                      ReferenceType,
                       _remove_dead_weakref)
 
 from _weakrefset import WeakSet, _IterationGuard
@@ -22,9 +27,19 @@
 ProxyTypes = (ProxyType, CallableProxyType)
 
 __all__ = [
-    "ref", "proxy", "getweakrefcount", "getweakrefs", "WeakKeyDictionary",
-    "ReferenceType", "ProxyType", "CallableProxyType", "ProxyTypes",
-    "WeakValueDictionary", "WeakSet", "WeakMethod", "finalize"
+    "ref",
+    "proxy",
+    "getweakrefcount",
+    "getweakrefs",
+    "WeakKeyDictionary",
+    "ReferenceType",
+    "ProxyType",
+    "CallableProxyType",
+    "ProxyTypes",
+    "WeakValueDictionary",
+    "WeakSet",
+    "WeakMethod",
+    "finalize"
 ]
 
 
@@ -41,8 +56,8 @@
             obj = meth.__self__
             func = meth.__func__
         except AttributeError:
-            raise TypeError("argument should be a bound method, not {}".format(
-                type(meth))) from None
+            raise TypeError("argument should be a bound method, not {}"
+                            .format(type(meth))) from None
 
         def _cb(arg):
             # The self-weakref trick is needed to avoid creating a reference
@@ -71,8 +86,7 @@
         if isinstance(other, WeakMethod):
             if not self._alive or not other._alive:
                 return self is other
-            return ref.__eq__(self,
-                              other) and self._func_ref == other._func_ref
+            return ref.__eq__(self, other) and self._func_ref == other._func_ref
         return False
 
     def __ne__(self, other):
@@ -106,9 +120,7 @@
         if len(args) > 1:
             raise TypeError('expected at most 1 arguments, got %d' % len(args))
 
-        def remove(wr,
-                   selfref=ref(self),
-                   _atomic_removal=_remove_dead_weakref):
+        def remove(wr, selfref=ref(self), _atomic_removal=_remove_dead_weakref):
             self = selfref()
             if self is not None:
                 if self._iterating:
--- .\env\Lib\_collections_abc.py	(original)
+++ .\env\Lib\_collections_abc.py	(reformatted)
@@ -259,8 +259,12 @@
     @classmethod
     def __subclasshook__(cls, C):
         if cls is AsyncGenerator:
-            return _check_methods(C, '__aiter__', '__anext__', 'asend',
-                                  'athrow', 'aclose')
+            return _check_methods(C,
+                                  '__aiter__',
+                                  '__anext__',
+                                  'asend',
+                                  'athrow',
+                                  'aclose')
         return NotImplemented
 
 
@@ -377,7 +381,11 @@
     @classmethod
     def __subclasshook__(cls, C):
         if cls is Generator:
-            return _check_methods(C, '__iter__', '__next__', 'send', 'throw',
+            return _check_methods(C,
+                                  '__iter__',
+                                  '__next__',
+                                  'send',
+                                  'throw',
                                   'close')
         return NotImplemented
 
@@ -863,8 +871,8 @@
                             "needs an argument")
         self, *args = args
         if len(args) > 1:
-            raise TypeError('update expected at most 1 arguments, got %d' %
-                            len(args))
+            raise TypeError('update expected at most 1 arguments, got %d'
+                            % len(args))
         if args:
             other = args[0]
             if isinstance(other, Mapping):
--- .\env\Lib\_dummy_thread.py	(original)
+++ .\env\Lib\_dummy_thread.py	(reformatted)
@@ -14,8 +14,13 @@
 # Exports only things specified by thread documentation;
 # skipping obsolete synonyms allocate(), start_new(), exit_thread().
 __all__ = [
-    'error', 'start_new_thread', 'exit', 'get_ident', 'allocate_lock',
-    'interrupt_main', 'LockType'
+    'error',
+    'start_new_thread',
+    'exit',
+    'get_ident',
+    'allocate_lock',
+    'interrupt_main',
+    'LockType'
 ]
 
 # A dummy value
@@ -149,10 +154,11 @@
         return self.locked_status
 
     def __repr__(self):
-        return "<%s %s.%s object at %s>" % (
-            "locked" if self.locked_status else "unlocked",
-            self.__class__.__module__, self.__class__.__qualname__,
-            hex(id(self)))
+        return "<%s %s.%s object at %s>" % ("locked" if self.locked_status else
+                                            "unlocked",
+                                            self.__class__.__module__,
+                                            self.__class__.__qualname__,
+                                            hex(id(self)))
 
 
 # Used to signal that interrupt_main was called in a "thread"
--- .\env\Lib\_weakrefset.py	(original)
+++ .\env\Lib\_weakrefset.py	(reformatted)
@@ -77,8 +77,7 @@
         return wr in self.data
 
     def __reduce__(self):
-        return (self.__class__, (list(self), ),
-                getattr(self, '__dict__', None))
+        return (self.__class__, (list(self), ), getattr(self, '__dict__', None))
 
     def add(self, item):
         if self._pending_removals:
@@ -196,7 +195,8 @@
             self.data.clear()
         else:
             self.data.symmetric_difference_update(
-                ref(item, self._remove) for item in other)
+                ref(item,
+                    self._remove) for item in other)
         return self
 
     def union(self, other):
--- .\env\Lib\__future__.py	(original)
+++ .\env\Lib\__future__.py	(reformatted)
@@ -102,36 +102,117 @@
         return self.mandatory
 
     def __repr__(self):
-        return "_Feature" + repr(
-            (self.optional, self.mandatory, self.compiler_flag))
-
-
-nested_scopes = _Feature((2, 1, 0, "beta", 1), (2, 2, 0, "alpha", 0),
-                         CO_NESTED)
-
-generators = _Feature((2, 2, 0, "alpha", 1), (2, 3, 0, "final", 0),
+        return "_Feature" + repr((self.optional,
+                                  self.mandatory,
+                                  self.compiler_flag))
+
+
+nested_scopes = _Feature((2, 1, 0, "beta", 1), (2, 2, 0, "alpha", 0), CO_NESTED)
+
+generators = _Feature((2,
+                       2,
+                       0,
+                       "alpha",
+                       1),
+                      (2,
+                       3,
+                       0,
+                       "final",
+                       0),
                       CO_GENERATOR_ALLOWED)
 
-division = _Feature((2, 2, 0, "alpha", 2), (3, 0, 0, "alpha", 0),
+division = _Feature((2,
+                     2,
+                     0,
+                     "alpha",
+                     2),
+                    (3,
+                     0,
+                     0,
+                     "alpha",
+                     0),
                     CO_FUTURE_DIVISION)
 
-absolute_import = _Feature((2, 5, 0, "alpha", 1), (3, 0, 0, "alpha", 0),
+absolute_import = _Feature((2,
+                            5,
+                            0,
+                            "alpha",
+                            1),
+                           (3,
+                            0,
+                            0,
+                            "alpha",
+                            0),
                            CO_FUTURE_ABSOLUTE_IMPORT)
 
-with_statement = _Feature((2, 5, 0, "alpha", 1), (2, 6, 0, "alpha", 0),
+with_statement = _Feature((2,
+                           5,
+                           0,
+                           "alpha",
+                           1),
+                          (2,
+                           6,
+                           0,
+                           "alpha",
+                           0),
                           CO_FUTURE_WITH_STATEMENT)
 
-print_function = _Feature((2, 6, 0, "alpha", 2), (3, 0, 0, "alpha", 0),
+print_function = _Feature((2,
+                           6,
+                           0,
+                           "alpha",
+                           2),
+                          (3,
+                           0,
+                           0,
+                           "alpha",
+                           0),
                           CO_FUTURE_PRINT_FUNCTION)
 
-unicode_literals = _Feature((2, 6, 0, "alpha", 2), (3, 0, 0, "alpha", 0),
+unicode_literals = _Feature((2,
+                             6,
+                             0,
+                             "alpha",
+                             2),
+                            (3,
+                             0,
+                             0,
+                             "alpha",
+                             0),
                             CO_FUTURE_UNICODE_LITERALS)
 
-barry_as_FLUFL = _Feature((3, 1, 0, "alpha", 2), (3, 9, 0, "alpha", 0),
+barry_as_FLUFL = _Feature((3,
+                           1,
+                           0,
+                           "alpha",
+                           2),
+                          (3,
+                           9,
+                           0,
+                           "alpha",
+                           0),
                           CO_FUTURE_BARRY_AS_BDFL)
 
-generator_stop = _Feature((3, 5, 0, "beta", 1), (3, 7, 0, "alpha", 0),
+generator_stop = _Feature((3,
+                           5,
+                           0,
+                           "beta",
+                           1),
+                          (3,
+                           7,
+                           0,
+                           "alpha",
+                           0),
                           CO_FUTURE_GENERATOR_STOP)
 
-annotations = _Feature((3, 7, 0, "beta", 1), (4, 0, 0, "alpha", 0),
+annotations = _Feature((3,
+                        7,
+                        0,
+                        "beta",
+                        1),
+                       (4,
+                        0,
+                        0,
+                        "alpha",
+                        0),
                        CO_FUTURE_ANNOTATIONS)
--- .\env\Lib\collections\__init__.py	(original)
+++ .\env\Lib\collections\__init__.py	(reformatted)
@@ -15,8 +15,15 @@
 '''
 
 __all__ = [
-    'deque', 'defaultdict', 'namedtuple', 'UserDict', 'UserList', 'UserString',
-    'Counter', 'OrderedDict', 'ChainMap'
+    'deque',
+    'defaultdict',
+    'namedtuple',
+    'UserDict',
+    'UserList',
+    'UserString',
+    'Counter',
+    'OrderedDict',
+    'ChainMap'
 ]
 
 import _collections_abc
@@ -394,7 +401,8 @@
         if len(defaults) > len(field_names):
             raise TypeError('Got more default values than field names')
         field_defaults = dict(
-            reversed(list(zip(reversed(field_names), reversed(defaults)))))
+            reversed(list(zip(reversed(field_names),
+                              reversed(defaults)))))
 
     # Variables used in the methods and docstrings
     field_names = tuple(map(_sys.intern, field_names))
@@ -449,7 +457,11 @@
 
     # Modify function metadata to help with introspection and debugging
 
-    for method in (__new__, _make.__func__, _replace, __repr__, _asdict,
+    for method in (__new__,
+                   _make.__func__,
+                   _replace,
+                   __repr__,
+                   _asdict,
                    __getnewargs__):
         method.__qualname__ = f'{typename}.{method.__name__}'
 
@@ -668,8 +680,9 @@
                     for elem, count in iterable.items():
                         self[elem] = count + self_get(elem, 0)
                 else:
-                    super(Counter, self).update(
-                        iterable)  # fast path when counter is empty
+                    super(Counter,
+                          self).update(iterable
+                                       )  # fast path when counter is empty
             else:
                 _count_elements(self, iterable)
         if kwds:
@@ -933,15 +946,15 @@
                     key]  # can't use 'key in mapping' with defaultdict
             except KeyError:
                 pass
-        return self.__missing__(
-            key)  # support subclasses that define __missing__
+        return self.__missing__(key
+                                )  # support subclasses that define __missing__
 
     def get(self, key, default=None):
         return self[key] if key in self else default
 
     def __len__(self):
-        return len(
-            set().union(*self.maps))  # reuses stored hash values if possible
+        return len(set().union(
+            *self.maps))  # reuses stored hash values if possible
 
     def __iter__(self):
         d = {}
@@ -958,7 +971,9 @@
     @_recursive_repr()
     def __repr__(self):
         return '{0.__class__.__name__}({1})'.format(
-            self, ', '.join(map(repr, self.maps)))
+            self,
+            ', '.join(map(repr,
+                          self.maps)))
 
     @classmethod
     def fromkeys(cls, iterable, *args):
@@ -991,8 +1006,8 @@
         try:
             del self.maps[0][key]
         except KeyError:
-            raise KeyError(
-                'Key not found in the first mapping: {!r}'.format(key))
+            raise KeyError('Key not found in the first mapping: {!r}'.format(
+                key))
 
     def popitem(self):
         'Remove and return an item pair from maps[0]. Raise KeyError is maps[0] is empty.'
@@ -1006,8 +1021,8 @@
         try:
             return self.maps[0].pop(key, *args)
         except KeyError:
-            raise KeyError(
-                'Key not found in the first mapping: {!r}'.format(key))
+            raise KeyError('Key not found in the first mapping: {!r}'.format(
+                key))
 
     def clear(self):
         'Clear maps[0], leaving maps[1:] intact.'
--- .\env\Lib\distutils\__init__.py	(original)
+++ .\env\Lib\distutils\__init__.py	(reformatted)
@@ -11,16 +11,19 @@
 dirname = os.path.dirname
 
 distutils_path = os.path.join(os.path.dirname(opcode.__file__), "distutils")
-if os.path.normpath(distutils_path) == os.path.dirname(
-        os.path.normpath(__file__)):
+if os.path.normpath(
+        distutils_path) == os.path.dirname(os.path.normpath(__file__)):
     warnings.warn(
         "The virtualenv distutils package at %s appears to be in the same location as the system distutils?"
     )
 else:
     __path__.insert(0, distutils_path)  # noqa: F821
-    real_distutils = imp.load_module("_virtualenv_distutils", None,
+    real_distutils = imp.load_module("_virtualenv_distutils",
+                                     None,
                                      distutils_path,
-                                     ("", "", imp.PKG_DIRECTORY))
+                                     ("",
+                                      "",
+                                      imp.PKG_DIRECTORY))
     # Copy the relevant attributes
     try:
         __revision__ = real_distutils.__revision__
--- .\env\Lib\encodings\punycode.py	(original)
+++ .\env\Lib\encodings\punycode.py	(reformatted)
@@ -75,8 +75,10 @@
 def T(j, bias):
     # Punycode parameters: tmin = 1, tmax = 26, base = 36
     res = 36 * (j + 1) - bias
-    if res < 1: return 1
-    if res > 26: return 26
+    if res < 1:
+        return 1
+    if res > 26:
+        return 26
     return res
 
 
@@ -154,8 +156,8 @@
         elif 0x30 <= char <= 0x39:
             digit = char - 22  # 0x30-26
         elif errors == "strict":
-            raise UnicodeError("Invalid extended code point '%s'" %
-                               extended[extpos])
+            raise UnicodeError("Invalid extended code point '%s'"
+                               % extended[extpos])
         else:
             return extpos, None
         t = T(j, bias)
--- .\env\Lib\encodings\utf_8_sig.py	(original)
+++ .\env\Lib\encodings\utf_8_sig.py	(reformatted)
@@ -13,8 +13,7 @@
 
 
 def encode(input, errors='strict'):
-    return (codecs.BOM_UTF8 + codecs.utf_8_encode(input, errors)[0],
-            len(input))
+    return (codecs.BOM_UTF8 + codecs.utf_8_encode(input, errors)[0], len(input))
 
 
 def decode(input, errors='strict'):
--- .\env\Lib\encodings\__init__.py	(original)
+++ .\env\Lib\encodings\__init__.py	(reformatted)
@@ -125,18 +125,21 @@
     if not isinstance(entry, codecs.CodecInfo):
         if not 4 <= len(entry) <= 7:
             raise CodecRegistryError('module "%s" (%s) failed to register' %
-                                     (mod.__name__, mod.__file__))
+                                     (mod.__name__,
+                                      mod.__file__))
         if not callable(entry[0]) or not callable(entry[1]) or \
            (entry[2] is not None and not callable(entry[2])) or \
            (entry[3] is not None and not callable(entry[3])) or \
            (len(entry) > 4 and entry[4] is not None and not callable(entry[4])) or \
            (len(entry) > 5 and entry[5] is not None and not callable(entry[5])):
-            raise CodecRegistryError(
-                'incompatible codecs in module "%s" (%s)' %
-                (mod.__name__, mod.__file__))
+            raise CodecRegistryError('incompatible codecs in module "%s" (%s)' %
+                                     (mod.__name__,
+                                      mod.__file__))
         if len(entry) < 7 or entry[6] is None:
-            entry += (None, ) * (6 - len(entry)) + (mod.__name__.split(".",
-                                                                       1)[1], )
+            entry += (None,
+                      ) * (6 - len(entry)) + (mod.__name__.split(".",
+                                                                 1)[1],
+                                              )
         entry = codecs.CodecInfo(*entry)
 
     # Cache the codec registry entry
--- .\env\Lib\importlib\abc.py	(original)
+++ .\env\Lib\importlib\abc.py	(reformatted)
@@ -79,8 +79,11 @@
         """
 
 
-_register(MetaPathFinder, machinery.BuiltinImporter, machinery.FrozenImporter,
-          machinery.PathFinder, machinery.WindowsRegistryFinder)
+_register(MetaPathFinder,
+          machinery.BuiltinImporter,
+          machinery.FrozenImporter,
+          machinery.PathFinder,
+          machinery.WindowsRegistryFinder)
 
 
 class PathEntryFinder(Finder):
@@ -280,17 +283,20 @@
 _register(ExecutionLoader, machinery.ExtensionFileLoader)
 
 
-class FileLoader(_bootstrap_external.FileLoader, ResourceLoader,
+class FileLoader(_bootstrap_external.FileLoader,
+                 ResourceLoader,
                  ExecutionLoader):
     """Abstract base class partially implementing the ResourceLoader and
     ExecutionLoader ABCs."""
 
 
-_register(FileLoader, machinery.SourceFileLoader,
+_register(FileLoader,
+          machinery.SourceFileLoader,
           machinery.SourcelessFileLoader)
 
 
-class SourceLoader(_bootstrap_external.SourceLoader, ResourceLoader,
+class SourceLoader(_bootstrap_external.SourceLoader,
+                   ResourceLoader,
                    ExecutionLoader):
     """Abstract base class for loading source code (and optionally any
     corresponding bytecode).
--- .\env\Lib\importlib\machinery.py	(original)
+++ .\env\Lib\importlib\machinery.py	(reformatted)
@@ -5,9 +5,11 @@
 from ._bootstrap import ModuleSpec
 from ._bootstrap import BuiltinImporter
 from ._bootstrap import FrozenImporter
-from ._bootstrap_external import (SOURCE_SUFFIXES, DEBUG_BYTECODE_SUFFIXES,
+from ._bootstrap_external import (SOURCE_SUFFIXES,
+                                  DEBUG_BYTECODE_SUFFIXES,
                                   OPTIMIZED_BYTECODE_SUFFIXES,
-                                  BYTECODE_SUFFIXES, EXTENSION_SUFFIXES)
+                                  BYTECODE_SUFFIXES,
+                                  EXTENSION_SUFFIXES)
 from ._bootstrap_external import WindowsRegistryFinder
 from ._bootstrap_external import PathFinder
 from ._bootstrap_external import FileFinder
--- .\env\Lib\importlib\resources.py	(original)
+++ .\env\Lib\importlib\resources.py	(reformatted)
@@ -37,8 +37,8 @@
     """
     if hasattr(package, '__spec__'):
         if package.__spec__.submodule_search_locations is None:
-            raise TypeError('{!r} is not a package'.format(
-                package.__spec__.name))
+            raise TypeError('{!r} is not a package'.format(package.__spec__.name
+                                                           ))
         else:
             return package
     else:
@@ -61,8 +61,8 @@
         return file_name
 
 
-def _get_resource_reader(
-        package: ModuleType) -> Optional[resources_abc.ResourceReader]:
+def _get_resource_reader(package: ModuleType
+                         ) -> Optional[resources_abc.ResourceReader]:
     # Return the package's loader if it's a ResourceReader.  We can't use
     # a issubclass() check here because apparently abc.'s __subclasscheck__()
     # hook wants to create a weak reference to the object, but
@@ -105,7 +105,8 @@
         if data is None:
             package_name = package.__spec__.name
             message = '{!r} resource not found in {!r}'.format(
-                resource, package_name)
+                resource,
+                package_name)
             raise FileNotFoundError(message)
         else:
             return BytesIO(data)
@@ -139,7 +140,8 @@
         if data is None:
             package_name = package.__spec__.name
             message = '{!r} resource not found in {!r}'.format(
-                resource, package_name)
+                resource,
+                package_name)
             raise FileNotFoundError(message)
         else:
             return TextIOWrapper(BytesIO(data), encoding, errors)
--- .\env\Lib\importlib\util.py	(original)
+++ .\env\Lib\importlib\util.py	(reformatted)
@@ -150,10 +150,9 @@
     """
     @functools.wraps(fxn)
     def set_package_wrapper(*args, **kwargs):
-        warnings.warn(
-            'The import system now takes care of this automatically.',
-            DeprecationWarning,
-            stacklevel=2)
+        warnings.warn('The import system now takes care of this automatically.',
+                      DeprecationWarning,
+                      stacklevel=2)
         module = fxn(*args, **kwargs)
         if getattr(module, '__package__', None) is None:
             module.__package__ = module.__name__
@@ -172,10 +171,9 @@
     """
     @functools.wraps(fxn)
     def set_loader_wrapper(self, *args, **kwargs):
-        warnings.warn(
-            'The import system now takes care of this automatically.',
-            DeprecationWarning,
-            stacklevel=2)
+        warnings.warn('The import system now takes care of this automatically.',
+                      DeprecationWarning,
+                      stacklevel=2)
         module = fxn(self, *args, **kwargs)
         if getattr(module, '__loader__', None) is None:
             module.__loader__ = self
--- .\env\Lib\importlib\_bootstrap.py	(original)
+++ .\env\Lib\importlib\_bootstrap.py	(reformatted)
@@ -387,13 +387,14 @@
 
     def __repr__(self):
         args = [
-            'name={!r}'.format(self.name), 'loader={!r}'.format(self.loader)
+            'name={!r}'.format(self.name),
+            'loader={!r}'.format(self.loader)
         ]
         if self.origin is not None:
             args.append('origin={!r}'.format(self.origin))
         if self.submodule_search_locations is not None:
-            args.append('submodule_search_locations={}'.format(
-                self.submodule_search_locations))
+            args.append('submodule_search_locations={}'
+                        .format(self.submodule_search_locations))
         return '{}({})'.format(self.__class__.__name__, ', '.join(args))
 
     def __eq__(self, other):
@@ -750,8 +751,7 @@
     def create_module(self, spec):
         """Create a built-in module"""
         if spec.name not in sys.builtin_module_names:
-            raise ImportError('{!r} is not a built-in module'.format(
-                spec.name),
+            raise ImportError('{!r} is not a built-in module'.format(spec.name),
                               name=spec.name)
         return _call_with_frames_removed(_imp.create_builtin, spec)
 
@@ -1046,8 +1046,9 @@
                     # Backwards-compatibility dictates we ignore failed
                     # imports triggered by fromlist for modules that don't
                     # exist.
-                    if (exc.name == from_name and sys.modules.get(
-                            from_name, _NEEDS_LOADING) is not None):
+                    if (exc.name == from_name
+                            and sys.modules.get(from_name,
+                                                _NEEDS_LOADING) is not None):
                         continue
                     raise
     return module
@@ -1114,8 +1115,7 @@
             cut_off = len(name) - len(name.partition('.')[0])
             # Slice end needs to be positive to alleviate need to special-case
             # when ``'.' not in name``.
-            return sys.modules[module.__name__[:len(module.__name__) -
-                                               cut_off]]
+            return sys.modules[module.__name__[:len(module.__name__) - cut_off]]
     else:
         return _handle_fromlist(module, fromlist, _gcd_import)
 
--- .\env\Lib\importlib\_bootstrap_external.py	(original)
+++ .\env\Lib\importlib\_bootstrap_external.py	(reformatted)
@@ -22,8 +22,8 @@
 # Bootstrap-related code ######################################################
 _CASE_INSENSITIVE_PLATFORMS_STR_KEY = 'win',
 _CASE_INSENSITIVE_PLATFORMS_BYTES_KEY = 'cygwin', 'darwin'
-_CASE_INSENSITIVE_PLATFORMS = (_CASE_INSENSITIVE_PLATFORMS_BYTES_KEY +
-                               _CASE_INSENSITIVE_PLATFORMS_STR_KEY)
+_CASE_INSENSITIVE_PLATFORMS = (_CASE_INSENSITIVE_PLATFORMS_BYTES_KEY
+                               + _CASE_INSENSITIVE_PLATFORMS_STR_KEY)
 
 
 def _make_relax_case():
@@ -110,7 +110,8 @@
     temporary file is attempted."""
     # id() is used to generate a pseudo-random filename.
     path_tmp = '{}.{}'.format(path, id(path))
-    fd = _os.open(path_tmp, _os.O_EXCL | _os.O_CREAT | _os.O_WRONLY,
+    fd = _os.open(path_tmp,
+                  _os.O_EXCL | _os.O_CREAT | _os.O_WRONLY,
                   mode & 0o666)
     try:
         # We first write data to a temporary file, and then use os.replace() to
@@ -291,7 +292,8 @@
     if debug_override is not None:
         _warnings.warn(
             'the debug_override parameter is deprecated; use '
-            "'optimization' instead", DeprecationWarning)
+            "'optimization' instead",
+            DeprecationWarning)
         if optimization is not None:
             message = 'debug_override or optimization must be set to None'
             raise TypeError(message)
@@ -332,7 +334,8 @@
     head, pycache = _path_split(head)
     if pycache != _PYCACHE:
         raise ValueError('{} not bottom-level directory in '
-                         '{!r}'.format(_PYCACHE, path))
+                         '{!r}'.format(_PYCACHE,
+                                       path))
     dot_count = pycache_filename.count('.')
     if dot_count not in {2, 3}:
         raise ValueError('expected only 2 or 3 dots in '
@@ -405,8 +408,8 @@
         if name is None:
             name = self.name
         elif self.name != name:
-            raise ImportError('loader for %s cannot handle %s' %
-                              (self.name, name),
+            raise ImportError('loader for %s cannot handle %s' % (self.name,
+                                                                  name),
                               name=name)
         return method(self, name, *args, **kwargs)
 
@@ -416,7 +419,10 @@
         # XXX yuck
         def _wrap(new, old):
             for replace in [
-                    '__module__', '__name__', '__qualname__', '__doc__'
+                    '__module__',
+                    '__name__',
+                    '__qualname__',
+                    '__doc__'
             ]:
                 if hasattr(old, replace):
                     setattr(new, replace, getattr(old, replace))
@@ -476,8 +482,7 @@
     return flags
 
 
-def _validate_timestamp_pyc(data, source_mtime, source_size, name,
-                            exc_details):
+def _validate_timestamp_pyc(data, source_mtime, source_size, name, exc_details):
     """Validate a pyc against the source last-modified time.
 
     *data* is the contents of the pyc file. (Only the first 16 bytes are
@@ -695,7 +700,8 @@
         for loader, suffixes in _get_supported_file_loaders():
             if filepath.endswith(tuple(suffixes)):
                 spec = _bootstrap.spec_from_loader(fullname,
-                                                   loader(fullname, filepath),
+                                                   loader(fullname,
+                                                          filepath),
                                                    origin=filepath)
                 return spec
 
@@ -847,7 +853,9 @@
                                     _RAW_MAGIC_NUMBER,
                                     source_bytes,
                                 )
-                                _validate_hash_pyc(data, source_hash, fullname,
+                                _validate_hash_pyc(data,
+                                                   source_hash,
+                                                   fullname,
                                                    exc_details)
                         else:
                             _validate_timestamp_pyc(
@@ -861,7 +869,8 @@
                         pass
                     else:
                         _bootstrap._verbose_message('{} matches {}',
-                                                    bytecode_path, source_path)
+                                                    bytecode_path,
+                                                    source_path)
                         return _compile_bytecode(bytes_data,
                                                  name=fullname,
                                                  bytecode_path=bytecode_path,
@@ -875,10 +884,10 @@
             if hash_based:
                 if source_hash is None:
                     source_hash = _imp.source_hash(source_bytes)
-                data = _code_to_hash_pyc(code_object, source_hash,
-                                         check_source)
+                data = _code_to_hash_pyc(code_object, source_hash, check_source)
             else:
-                data = _code_to_timestamp_pyc(code_object, source_mtime,
+                data = _code_to_timestamp_pyc(code_object,
+                                              source_mtime,
                                               len(source_bytes))
             try:
                 self._cache_bytecode(source_path, bytecode_path, data)
@@ -986,14 +995,16 @@
                 # Could be a permission error, read-only filesystem: just forget
                 # about writing the data.
                 _bootstrap._verbose_message('could not create {!r}: {!r}',
-                                            parent, exc)
+                                            parent,
+                                            exc)
                 return
         try:
             _write_atomic(path, data, _mode)
             _bootstrap._verbose_message('created {!r}', path)
         except OSError as exc:
             # Same as above: just don't write the bytecode.
-            _bootstrap._verbose_message('could not create {!r}: {!r}', path,
+            _bootstrap._verbose_message('could not create {!r}: {!r}',
+                                        path,
                                         exc)
 
 
@@ -1043,17 +1054,18 @@
 
     def create_module(self, spec):
         """Create an unitialized extension module"""
-        module = _bootstrap._call_with_frames_removed(_imp.create_dynamic,
-                                                      spec)
+        module = _bootstrap._call_with_frames_removed(_imp.create_dynamic, spec)
         _bootstrap._verbose_message('extension module {!r} loaded from {!r}',
-                                    spec.name, self.path)
+                                    spec.name,
+                                    self.path)
         return module
 
     def exec_module(self, module):
         """Initialize an extension module"""
         _bootstrap._call_with_frames_removed(_imp.exec_dynamic, module)
         _bootstrap._verbose_message('extension module {!r} executed from {!r}',
-                                    self.name, self.path)
+                                    self.name,
+                                    self.path)
 
     def is_package(self, fullname):
         """Return True if the extension module is a package."""
@@ -1289,7 +1301,9 @@
                 # can create the namespace package.
                 spec.origin = None
                 spec.submodule_search_locations = _NamespacePath(
-                    fullname, namespace_path, cls._get_spec)
+                    fullname,
+                    namespace_path,
+                    cls._get_spec)
                 return spec
             else:
                 return None
@@ -1384,8 +1398,11 @@
                 init_filename = '__init__' + suffix
                 full_path = _path_join(base_path, init_filename)
                 if _path_isfile(full_path):
-                    return self._get_spec(loader_class, fullname, full_path,
-                                          [base_path], target)
+                    return self._get_spec(loader_class,
+                                          fullname,
+                                          full_path,
+                                          [base_path],
+                                          target)
             else:
                 # If a namespace package, return the path if we don't
                 #  find a module in the next section.
@@ -1396,8 +1413,11 @@
             _bootstrap._verbose_message('trying {}', full_path, verbosity=2)
             if cache_module + suffix in cache:
                 if _path_isfile(full_path):
-                    return self._get_spec(loader_class, fullname, full_path,
-                                          None, target)
+                    return self._get_spec(loader_class,
+                                          fullname,
+                                          full_path,
+                                          None,
+                                          target)
         if is_namespace:
             _bootstrap._verbose_message('possible namespace for {}', base_path)
             spec = _bootstrap.ModuleSpec(fullname, None)
--- .\env\Lib\importlib\__init__.py	(original)
+++ .\env\Lib\importlib\__init__.py	(reformatted)
@@ -41,7 +41,8 @@
     _bootstrap_external.__package__ = 'importlib'
     try:
         _bootstrap_external.__file__ = __file__.replace(
-            '__init__.py', '_bootstrap_external.py')
+            '__init__.py',
+            '_bootstrap_external.py')
     except NameError:
         # __file__ is not guaranteed to be defined, e.g. if this code gets
         # frozen by a tool like cx_Freeze.
@@ -166,8 +167,8 @@
         target = module
         spec = module.__spec__ = _bootstrap._find_spec(name, pkgpath, target)
         if spec is None:
-            raise ModuleNotFoundError(
-                f"spec not found for the module {name!r}", name=name)
+            raise ModuleNotFoundError(f"spec not found for the module {name!r}",
+                                      name=name)
         _bootstrap._exec(spec, module)
         # The module may have replaced itself in sys.modules!
         return sys.modules[name]
--- .\env\Lib\site-packages\pyparsing.py	(original)
+++ .\env\Lib\site-packages\pyparsing.py	(reformatted)
@@ -333,7 +333,17 @@
 
     # build list of single arg builtins, that can be used as parse actions
     singleArgBuiltins = [
-        sum, len, sorted, reversed, list, tuple, set, any, all, min, max
+        sum,
+        len,
+        sorted,
+        reversed,
+        list,
+        tuple,
+        set,
+        any,
+        all,
+        min,
+        max
     ]
 
 else:
@@ -454,13 +464,17 @@
             if self.loc >= len(self.pstr):
                 foundstr = ', found end of text'
             else:
-                foundstr = (', found %r' %
-                            self.pstr[self.loc:self.loc + 1]).replace(
-                                r'\\', '\\')
+                foundstr = (
+                    ', found %r'
+                    % self.pstr[self.loc:self.loc + 1]).replace(r'\\',
+                                                                '\\')
         else:
             foundstr = ''
-        return ("%s%s  (at char %d), (line:%d, col:%d)" %
-                (self.msg, foundstr, self.loc, self.lineno, self.column))
+        return ("%s%s  (at char %d), (line:%d, col:%d)" % (self.msg,
+                                                           foundstr,
+                                                           self.loc,
+                                                           self.lineno,
+                                                           self.column))
 
     def __repr__(self):
         return _ustr(self)
@@ -472,8 +486,9 @@
         line_str = self.line
         line_column = self.column - 1
         if markerString:
-            line_str = "".join(
-                (line_str[:line_column], markerString, line_str[line_column:]))
+            line_str = "".join((line_str[:line_column],
+                                markerString,
+                                line_str[line_column:]))
         return line_str.strip()
 
     def __dir__(self):
@@ -544,8 +559,7 @@
 
                 f_self = frm.f_locals.get('self', None)
                 if isinstance(f_self, ParserElement):
-                    if frm.f_code.co_name not in ('parseImpl',
-                                                  '_parseNoCache'):
+                    if frm.f_code.co_name not in ('parseImpl', '_parseNoCache'):
                         continue
                     if f_self in seen:
                         continue
@@ -710,17 +724,23 @@
                     name
                 )  # will always return a str, but use _ustr for consistency
             self.__name = name
-            if not (isinstance(toklist, (type(None), basestring, list))
-                    and toklist in (None, '', [])):
+            if not (isinstance(toklist,
+                               (type(None),
+                                basestring,
+                                list)) and toklist in (None,
+                                                       '',
+                                                       [])):
                 if isinstance(toklist, basestring):
                     toklist = [toklist]
                 if asList:
                     if isinstance(toklist, ParseResults):
                         self[name] = _ParseResultsWithOffset(
-                            ParseResults(toklist.__toklist), 0)
+                            ParseResults(toklist.__toklist),
+                            0)
                     else:
                         self[name] = _ParseResultsWithOffset(
-                            ParseResults(toklist[0]), 0)
+                            ParseResults(toklist[0]),
+                            0)
                     self[name].__name = name
                 else:
                     try:
@@ -746,7 +766,9 @@
             sub = v
         else:
             self.__tokdict[k] = self.__tokdict.get(
-                k, list()) + [_ParseResultsWithOffset(v, 0)]
+                k,
+                list()) + [_ParseResultsWithOffset(v,
+                                                   0)]
             sub = v
         if isinstance(sub, ParseResults):
             sub.__parent = wkref(self)
@@ -769,7 +791,8 @@
                 for j in removed:
                     for k, (value, position) in enumerate(occurrences):
                         occurrences[k] = _ParseResultsWithOffset(
-                            value, position - (position > j))
+                            value,
+                            position - (position > j))
         else:
             del self.__tokdict[i]
 
@@ -881,8 +904,8 @@
             if k == 'default':
                 args = (args[0], v)
             else:
-                raise TypeError(
-                    "pop() got an unexpected keyword argument '%s'" % k)
+                raise TypeError("pop() got an unexpected keyword argument '%s'"
+                                % k)
         if (isinstance(args[0], int) or len(args) == 1 or args[0] in self):
             index = args[0]
             ret = self[index]
@@ -935,7 +958,8 @@
         for name, occurrences in self.__tokdict.items():
             for k, (value, position) in enumerate(occurrences):
                 occurrences[k] = _ParseResultsWithOffset(
-                    value, position + (position > index))
+                    value,
+                    position + (position > index))
 
     def append(self, item):
         """
@@ -995,8 +1019,9 @@
             addoffset = lambda a: offset if a < 0 else a + offset
             otheritems = other.__tokdict.items()
             otherdictitems = [(k,
-                               _ParseResultsWithOffset(v[0], addoffset(v[1])))
-                              for k, vlist in otheritems for v in vlist]
+                               _ParseResultsWithOffset(v[0],
+                                                       addoffset(v[1]))) for k,
+                              vlist in otheritems for v in vlist]
             for k, v in otherdictitems:
                 self[k] = v
                 if isinstance(v[0], ParseResults):
@@ -1019,7 +1044,8 @@
 
     def __str__(self):
         return '[' + ', '.join(
-            _ustr(i) if isinstance(i, ParseResults) else repr(i)
+            _ustr(i) if isinstance(i,
+                                   ParseResults) else repr(i)
             for i in self.__toklist) + ']'
 
     def _asStringList(self, sep=''):
@@ -1049,7 +1075,8 @@
             print(type(result_list), result_list) # -> <class 'list'> ['sldkj', 'lsdkj', 'sldkj']
         """
         return [
-            res.asList() if isinstance(res, ParseResults) else res
+            res.asList() if isinstance(res,
+                                       ParseResults) else res
             for res in self.__toklist
         ]
 
@@ -1110,8 +1137,10 @@
         """
         nl = "\n"
         out = []
-        namedItems = dict(
-            (v[1], k) for (k, vlist) in self.__tokdict.items() for v in vlist)
+        namedItems = dict((v[1],
+                           k) for (k,
+                                   vlist) in self.__tokdict.items()
+                          for v in vlist)
         nextLevelIndent = indent + "  "
 
         # collapse out indents if formatting is not desired
@@ -1139,14 +1168,17 @@
             if isinstance(res, ParseResults):
                 if i in namedItems:
                     out += [
-                        res.asXML(namedItems[i], namedItemsOnly
-                                  and doctag is None, nextLevelIndent,
+                        res.asXML(namedItems[i],
+                                  namedItemsOnly and doctag is None,
+                                  nextLevelIndent,
                                   formatted)
                     ]
                 else:
                     out += [
-                        res.asXML(None, namedItemsOnly and doctag is None,
-                                  nextLevelIndent, formatted)
+                        res.asXML(None,
+                                  namedItemsOnly and doctag is None,
+                                  nextLevelIndent,
+                                  formatted)
                     ]
             else:
                 # individual token, see if there is a name for it
@@ -1160,8 +1192,15 @@
                         resTag = "ITEM"
                 xmlBodyText = _xml_escape(_ustr(res))
                 out += [
-                    nl, nextLevelIndent, "<", resTag, ">", xmlBodyText, "</",
-                    resTag, ">"
+                    nl,
+                    nextLevelIndent,
+                    "<",
+                    resTag,
+                    ">",
+                    xmlBodyText,
+                    "</",
+                    resTag,
+                    ">"
                 ]
 
         out += [nl, indent, "</", selfTag, ">"]
@@ -1208,7 +1247,8 @@
             else:
                 return None
         elif (len(self) == 1 and len(self.__tokdict) == 1
-              and next(iter(self.__tokdict.values()))[0][1] in (0, -1)):
+              and next(iter(self.__tokdict.values()))[0][1] in (0,
+                                                                -1)):
             return next(iter(self.__tokdict.keys()))
         else:
             return None
@@ -1264,16 +1304,23 @@
                 for i, vv in enumerate(v):
                     if isinstance(vv, ParseResults):
                         out.append("\n%s%s[%d]:\n%s%s%s" %
-                                   (indent, ('  ' * (_depth)), i, indent,
+                                   (indent,
+                                    ('  ' * (_depth)),
+                                    i,
+                                    indent,
                                     ('  ' * (_depth + 1)),
                                     vv.dump(indent=indent,
                                             full=full,
                                             include_list=include_list,
                                             _depth=_depth + 1)))
                     else:
-                        out.append("\n%s%s[%d]:\n%s%s%s" %
-                                   (indent, ('  ' * (_depth)), i, indent,
-                                    ('  ' * (_depth + 1)), _ustr(vv)))
+                        out.append("\n%s%s[%d]:\n%s%s%s" % (indent,
+                                                            ('  ' * (_depth)),
+                                                            i,
+                                                            indent,
+                                                            ('  ' *
+                                                             (_depth + 1)),
+                                                            _ustr(vv)))
 
         return "".join(out)
 
@@ -1306,9 +1353,11 @@
 
     # add support for pickle protocol
     def __getstate__(self):
-        return (self.__toklist, (self.__tokdict.copy(),
-                                 self.__parent is not None and self.__parent()
-                                 or None, self.__accumNames, self.__name))
+        return (self.__toklist,
+                (self.__tokdict.copy(),
+                 self.__parent is not None and self.__parent() or None,
+                 self.__accumNames,
+                 self.__name))
 
     def __setstate__(self, state):
         self.__toklist = state[0]
@@ -1371,7 +1420,9 @@
    """
     s = strg
     return 1 if 0 < loc < len(s) and s[loc - 1] == '\n' else loc - s.rfind(
-        "\n", 0, loc)
+        "\n",
+        0,
+        loc)
 
 
 def lineno(loc, strg):
@@ -1400,7 +1451,10 @@
 
 def _defaultStartDebugAction(instring, loc, expr):
     print(("Match " + _ustr(expr) + " at loc " + _ustr(loc) + "(%d,%d)" %
-           (lineno(loc, instring), col(loc, instring))))
+           (lineno(loc,
+                   instring),
+            col(loc,
+                instring))))
 
 
 def _defaultSuccessDebugAction(instring, startloc, endloc, expr, toks):
@@ -1453,8 +1507,8 @@
         def extract_stack(limit=0):
             # special handling for Python 3.5.0 - extra deep call stack by 1
             offset = -3 if system_version == (3, 5, 0) else -2
-            frame_summary = traceback.extract_stack(limit=-offset + limit -
-                                                    1)[offset]
+            frame_summary = traceback.extract_stack(limit=-offset + limit
+                                                    - 1)[offset]
             return [frame_summary[:2]]
 
         def extract_tb(tb, limit=0):
@@ -1488,7 +1542,8 @@
                     try:
                         tb = sys.exc_info()[-1]
                         if not extract_tb(
-                                tb, limit=2)[-1][:2] == pa_call_line_synth:
+                                tb,
+                                limit=2)[-1][:2] == pa_call_line_synth:
                             raise
                     finally:
                         try:
@@ -1504,8 +1559,10 @@
     # copy func name to wrapper for sensible debug output
     func_name = "<parse action>"
     try:
-        func_name = getattr(func, '__name__',
-                            getattr(func, '__class__').__name__)
+        func_name = getattr(func,
+                            '__name__',
+                            getattr(func,
+                                    '__class__').__name__)
     except Exception:
         func_name = str(func)
     wrapper.__name__ = func_name
@@ -1741,7 +1798,8 @@
         """
         self.parseAction += list(map(_trim_arity, list(fns)))
         self.callDuringTry = self.callDuringTry or kwargs.get(
-            "callDuringTry", False)
+            "callDuringTry",
+            False)
         return self
 
     def addCondition(self, *fns, **kwargs):
@@ -1766,10 +1824,12 @@
             self.parseAction.append(
                 conditionAsParseAction(fn,
                                        message=kwargs.get('message'),
-                                       fatal=kwargs.get('fatal', False)))
+                                       fatal=kwargs.get('fatal',
+                                                        False)))
 
         self.callDuringTry = self.callDuringTry or kwargs.get(
-            "callDuringTry", False)
+            "callDuringTry",
+            False)
         return self
 
     def setFailAction(self, fn):
@@ -1836,8 +1896,10 @@
                         loc, tokens = self.parseImpl(instring, preloc,
                                                      doActions)
                     except IndexError:
-                        raise ParseException(instring, len(instring),
-                                             self.errmsg, self)
+                        raise ParseException(instring,
+                                             len(instring),
+                                             self.errmsg,
+                                             self)
                 else:
                     loc, tokens = self.parseImpl(instring, preloc, doActions)
             except Exception as err:
@@ -1857,7 +1919,9 @@
                 try:
                     loc, tokens = self.parseImpl(instring, preloc, doActions)
                 except IndexError:
-                    raise ParseException(instring, len(instring), self.errmsg,
+                    raise ParseException(instring,
+                                         len(instring),
+                                         self.errmsg,
                                          self)
             else:
                 loc, tokens = self.parseImpl(instring, preloc, doActions)
@@ -1881,16 +1945,20 @@
                             raise exc
 
                         if tokens is not None and tokens is not retTokens:
-                            retTokens = ParseResults(
-                                tokens,
-                                self.resultsName,
-                                asList=self.saveAsList
-                                and isinstance(tokens, (ParseResults, list)),
-                                modal=self.modalResults)
+                            retTokens = ParseResults(tokens,
+                                                     self.resultsName,
+                                                     asList=self.saveAsList
+                                                     and isinstance(
+                                                         tokens,
+                                                         (ParseResults,
+                                                          list)),
+                                                     modal=self.modalResults)
                 except Exception as err:
                     # ~ print "Exception raised in user parse action:", err
                     if self.debugActions[FAIL]:
-                        self.debugActions[FAIL](instring, tokensStart, self,
+                        self.debugActions[FAIL](instring,
+                                                tokensStart,
+                                                self,
                                                 err)
                     raise
             else:
@@ -1898,22 +1966,26 @@
                     try:
                         tokens = fn(instring, tokensStart, retTokens)
                     except IndexError as parse_action_exc:
-                        exc = ParseException(
-                            "exception raised in parse action")
+                        exc = ParseException("exception raised in parse action")
                         exc.__cause__ = parse_action_exc
                         raise exc
 
                     if tokens is not None and tokens is not retTokens:
-                        retTokens = ParseResults(
-                            tokens,
-                            self.resultsName,
-                            asList=self.saveAsList
-                            and isinstance(tokens, (ParseResults, list)),
-                            modal=self.modalResults)
+                        retTokens = ParseResults(tokens,
+                                                 self.resultsName,
+                                                 asList=self.saveAsList
+                                                 and isinstance(
+                                                     tokens,
+                                                     (ParseResults,
+                                                      list)),
+                                                 modal=self.modalResults)
         if debugging:
             # ~ print ("Matched", self, "->", retTokens.asList())
             if self.debugActions[MATCH]:
-                self.debugActions[MATCH](instring, tokensStart, loc, self,
+                self.debugActions[MATCH](instring,
+                                         tokensStart,
+                                         loc,
+                                         self,
                                          retTokens)
 
         return loc, retTokens
@@ -2031,7 +2103,9 @@
             if value is cache.not_in_cache:
                 ParserElement.packrat_cache_stats[MISS] += 1
                 try:
-                    value = self._parseNoCache(instring, loc, doActions,
+                    value = self._parseNoCache(instring,
+                                               loc,
+                                               doActions,
                                                callPreParse)
                 except ParseBaseException as pe:
                     # cache a copy of the exception, without the traceback
@@ -2297,7 +2371,10 @@
         """
         try:
             return ParseResults(
-                [t for t, s, e in self.scanString(instring, maxMatches)])
+                [t for t,
+                 s,
+                 e in self.scanString(instring,
+                                      maxMatches)])
         except ParseBaseException as exc:
             if ParserElement.verbose_stacktrace:
                 raise
@@ -2365,11 +2442,10 @@
         if isinstance(other, basestring):
             other = self._literalStringClass(other)
         if not isinstance(other, ParserElement):
-            warnings.warn(
-                "Cannot combine element of type %s with ParserElement" %
-                type(other),
-                SyntaxWarning,
-                stacklevel=2)
+            warnings.warn("Cannot combine element of type %s with ParserElement"
+                          % type(other),
+                          SyntaxWarning,
+                          stacklevel=2)
             return None
         return And([self, other])
 
@@ -2383,11 +2459,10 @@
         if isinstance(other, basestring):
             other = self._literalStringClass(other)
         if not isinstance(other, ParserElement):
-            warnings.warn(
-                "Cannot combine element of type %s with ParserElement" %
-                type(other),
-                SyntaxWarning,
-                stacklevel=2)
+            warnings.warn("Cannot combine element of type %s with ParserElement"
+                          % type(other),
+                          SyntaxWarning,
+                          stacklevel=2)
             return None
         return other + self
 
@@ -2398,11 +2473,10 @@
         if isinstance(other, basestring):
             other = self._literalStringClass(other)
         if not isinstance(other, ParserElement):
-            warnings.warn(
-                "Cannot combine element of type %s with ParserElement" %
-                type(other),
-                SyntaxWarning,
-                stacklevel=2)
+            warnings.warn("Cannot combine element of type %s with ParserElement"
+                          % type(other),
+                          SyntaxWarning,
+                          stacklevel=2)
             return None
         return self + And._ErrorStop() + other
 
@@ -2413,11 +2487,10 @@
         if isinstance(other, basestring):
             other = self._literalStringClass(other)
         if not isinstance(other, ParserElement):
-            warnings.warn(
-                "Cannot combine element of type %s with ParserElement" %
-                type(other),
-                SyntaxWarning,
-                stacklevel=2)
+            warnings.warn("Cannot combine element of type %s with ParserElement"
+                          % type(other),
+                          SyntaxWarning,
+                          stacklevel=2)
             return None
         return other - self
 
@@ -2466,7 +2539,8 @@
             else:
                 raise TypeError(
                     "cannot multiply 'ParserElement' and ('%s', '%s') objects",
-                    type(other[0]), type(other[1]))
+                    type(other[0]),
+                    type(other[1]))
         else:
             raise TypeError("cannot multiply 'ParserElement' and '%s' objects",
                             type(other))
@@ -2516,11 +2590,10 @@
         if isinstance(other, basestring):
             other = self._literalStringClass(other)
         if not isinstance(other, ParserElement):
-            warnings.warn(
-                "Cannot combine element of type %s with ParserElement" %
-                type(other),
-                SyntaxWarning,
-                stacklevel=2)
+            warnings.warn("Cannot combine element of type %s with ParserElement"
+                          % type(other),
+                          SyntaxWarning,
+                          stacklevel=2)
             return None
         return MatchFirst([self, other])
 
@@ -2531,11 +2604,10 @@
         if isinstance(other, basestring):
             other = self._literalStringClass(other)
         if not isinstance(other, ParserElement):
-            warnings.warn(
-                "Cannot combine element of type %s with ParserElement" %
-                type(other),
-                SyntaxWarning,
-                stacklevel=2)
+            warnings.warn("Cannot combine element of type %s with ParserElement"
+                          % type(other),
+                          SyntaxWarning,
+                          stacklevel=2)
             return None
         return other | self
 
@@ -2546,11 +2618,10 @@
         if isinstance(other, basestring):
             other = self._literalStringClass(other)
         if not isinstance(other, ParserElement):
-            warnings.warn(
-                "Cannot combine element of type %s with ParserElement" %
-                type(other),
-                SyntaxWarning,
-                stacklevel=2)
+            warnings.warn("Cannot combine element of type %s with ParserElement"
+                          % type(other),
+                          SyntaxWarning,
+                          stacklevel=2)
             return None
         return Or([self, other])
 
@@ -2561,11 +2632,10 @@
         if isinstance(other, basestring):
             other = self._literalStringClass(other)
         if not isinstance(other, ParserElement):
-            warnings.warn(
-                "Cannot combine element of type %s with ParserElement" %
-                type(other),
-                SyntaxWarning,
-                stacklevel=2)
+            warnings.warn("Cannot combine element of type %s with ParserElement"
+                          % type(other),
+                          SyntaxWarning,
+                          stacklevel=2)
             return None
         return other ^ self
 
@@ -2576,11 +2646,10 @@
         if isinstance(other, basestring):
             other = self._literalStringClass(other)
         if not isinstance(other, ParserElement):
-            warnings.warn(
-                "Cannot combine element of type %s with ParserElement" %
-                type(other),
-                SyntaxWarning,
-                stacklevel=2)
+            warnings.warn("Cannot combine element of type %s with ParserElement"
+                          % type(other),
+                          SyntaxWarning,
+                          stacklevel=2)
             return None
         return Each([self, other])
 
@@ -2591,11 +2660,10 @@
         if isinstance(other, basestring):
             other = self._literalStringClass(other)
         if not isinstance(other, ParserElement):
-            warnings.warn(
-                "Cannot combine element of type %s with ParserElement" %
-                type(other),
-                SyntaxWarning,
-                stacklevel=2)
+            warnings.warn("Cannot combine element of type %s with ParserElement"
+                          % type(other),
+                          SyntaxWarning,
+                          stacklevel=2)
             return None
         return other & self
 
@@ -2639,9 +2707,9 @@
 
         if len(key) > 2:
             warnings.warn(
-                "only 1 or 2 index arguments supported ({0}{1})".format(
-                    key[:5],
-                    '... [{0}]'.format(len(key)) if len(key) > 5 else ''))
+                "only 1 or 2 index arguments supported ({0}{1})"
+                .format(key[:5],
+                        '... [{0}]'.format(len(key)) if len(key) > 5 else ''))
 
         # clip to 2 elements
         ret = self * tuple(key[:2])
@@ -2729,10 +2797,9 @@
         """
         Enable display of debugging messages while doing pattern matching.
         """
-        self.debugActions = (startAction
-                             or _defaultStartDebugAction, successAction
-                             or _defaultSuccessDebugAction, exceptionAction
-                             or _defaultExceptionDebugAction)
+        self.debugActions = (startAction or _defaultStartDebugAction,
+                             successAction or _defaultSuccessDebugAction,
+                             exceptionAction or _defaultExceptionDebugAction)
         self.debug = True
         return self
 
@@ -2977,12 +3044,13 @@
         allResults = []
         comments = []
         success = True
-        NL = Literal(r'\n').addParseAction(
-            replaceWith('\n')).ignore(quotedString)
+        NL = Literal(r'\n').addParseAction(replaceWith('\n')).ignore(
+            quotedString)
         BOM = u'\ufeff'
         for t in tests:
             if comment is not None and comment.matches(
-                    t, False) or comments and not t:
+                    t,
+                    False) or comments and not t:
                 comments.append(t)
                 continue
             if not t:
@@ -2994,8 +3062,7 @@
                 t = NL.transformString(t.lstrip(BOM))
                 result = self.parseString(t, parseAll=parseAll)
             except ParseBaseException as pe:
-                fatal = "(FATAL)" if isinstance(pe,
-                                                ParseFatalException) else ""
+                fatal = "(FATAL)" if isinstance(pe, ParseFatalException) else ""
                 if '\n' in t:
                     out.append(line(pe.loc, t))
                     out.append(' ' * (col(pe.loc, t) - 1) + '^' + fatal)
@@ -3022,9 +3089,10 @@
                             out.append(result.dump())
                     except Exception as e:
                         out.append(result.dump(full=fullDump))
-                        out.append("{0} failed: {1}: {2}".format(
-                            postParse.__name__,
-                            type(e).__name__, e))
+                        out.append("{0} failed: {1}: {2}"
+                                   .format(postParse.__name__,
+                                           type(e).__name__,
+                                           e))
                 else:
                     out.append(result.dump(full=fullDump))
 
@@ -3145,7 +3213,8 @@
 
     def parseImpl(self, instring, loc, doActions=True):
         if instring[loc] == self.firstMatchChar and instring.startswith(
-                self.match, loc):
+                self.match,
+                loc):
             return loc + self.matchLen, self.match
         raise ParseException(instring, loc, self.errmsg, self)
 
@@ -3216,14 +3285,14 @@
                  == self.caselessmatch) and
                 (loc >= len(instring) - self.matchLen or
                  instring[loc + self.matchLen].upper() not in self.identChars)
-                    and (loc == 0
-                         or instring[loc - 1].upper() not in self.identChars)):
+                    and
+                (loc == 0 or instring[loc - 1].upper() not in self.identChars)):
                 return loc + self.matchLen, self.match
 
         else:
             if instring[loc] == self.firstMatchChar:
-                if ((self.matchLen == 1
-                     or instring.startswith(self.match, loc)) and
+                if ((self.matchLen == 1 or instring.startswith(self.match,
+                                                               loc)) and
                     (loc >= len(instring) - self.matchLen
                      or instring[loc + self.matchLen] not in self.identChars)
                         and
@@ -3279,9 +3348,10 @@
     (Contrast with example for :class:`CaselessLiteral`.)
     """
     def __init__(self, matchString, identChars=None):
-        super(CaselessKeyword, self).__init__(matchString,
-                                              identChars,
-                                              caseless=True)
+        super(CaselessKeyword,
+              self).__init__(matchString,
+                             identChars,
+                             caseless=True)
 
 
 class CloseMatch(Token):
@@ -3323,7 +3393,8 @@
         self.match_string = match_string
         self.maxMismatches = maxMismatches
         self.errmsg = "Expected %r (with up to %d mismatches)" % (
-            self.match_string, self.maxMismatches)
+            self.match_string,
+            self.maxMismatches)
         self.mayIndexError = False
         self.mayReturnEmpty = False
 
@@ -3497,8 +3568,7 @@
         throwException = False
         if loc - start < self.minLen:
             throwException = True
-        elif self.maxSpecified and loc < instrlen and instring[
-                loc] in bodychars:
+        elif self.maxSpecified and loc < instrlen and instring[loc] in bodychars:
             throwException = True
         elif self.asKeyword:
             if (start > 0 and instring[start - 1] in bodychars
@@ -3525,8 +3595,8 @@
                     return s
 
             if self.initCharsOrig != self.bodyCharsOrig:
-                self.strRepr = "W:(%s, %s)" % (charsAsStr(
-                    self.initCharsOrig), charsAsStr(self.bodyCharsOrig))
+                self.strRepr = "W:(%s, %s)" % (charsAsStr(self.initCharsOrig),
+                                               charsAsStr(self.bodyCharsOrig))
             else:
                 self.strRepr = "W:(%s)" % charsAsStr(self.initCharsOrig)
 
@@ -3549,12 +3619,12 @@
     characters.
     """
     def __init__(self, charset, asKeyword=False, excludeChars=None):
-        super(Char, self).__init__(charset,
-                                   exact=1,
-                                   asKeyword=asKeyword,
-                                   excludeChars=excludeChars)
-        self.reString = "[%s]" % _escapeRegexRangeChars(''.join(
-            self.initChars))
+        super(Char,
+              self).__init__(charset,
+                             exact=1,
+                             asKeyword=asKeyword,
+                             excludeChars=excludeChars)
+        self.reString = "[%s]" % _escapeRegexRangeChars(''.join(self.initChars))
         if asKeyword:
             self.reString = r"\b%s\b" % self.reString
         self.re = re.compile(self.reString)
@@ -3795,20 +3865,20 @@
             self.pattern = r'%s(?:[^%s%s]' % (
                 re.escape(self.quoteChar),
                 _escapeRegexRangeChars(self.endQuoteChar[0]),
-                (escChar is not None and _escapeRegexRangeChars(escChar)
-                 or ''))
+                (escChar is not None and _escapeRegexRangeChars(escChar) or ''))
         else:
             self.flags = 0
             self.pattern = r'%s(?:[^%s\n\r%s]' % (
                 re.escape(self.quoteChar),
                 _escapeRegexRangeChars(self.endQuoteChar[0]),
-                (escChar is not None and _escapeRegexRangeChars(escChar)
-                 or ''))
+                (escChar is not None and _escapeRegexRangeChars(escChar) or ''))
         if len(self.endQuoteChar) > 1:
             self.pattern += ('|(?:' + ')|(?:'.join(
                 "%s[^%s]" % (re.escape(self.endQuoteChar[:i]),
                              _escapeRegexRangeChars(self.endQuoteChar[i]))
-                for i in range(len(self.endQuoteChar) - 1, 0, -1)) + ')')
+                for i in range(len(self.endQuoteChar) - 1,
+                               0,
+                               -1)) + ')')
 
         if escQuote:
             self.pattern += (r'|(?:%s)' % re.escape(escQuote))
@@ -3822,8 +3892,7 @@
             self.reString = self.pattern
             self.re_match = self.re.match
         except sre_constants.error:
-            warnings.warn("invalid pattern (%s) passed to Regex" %
-                          self.pattern,
+            warnings.warn("invalid pattern (%s) passed to Regex" % self.pattern,
                           SyntaxWarning,
                           stacklevel=2)
             raise
@@ -3835,7 +3904,8 @@
 
     def parseImpl(self, instring, loc, doActions=True):
         result = instring[loc] == self.firstQuoteChar and self.re_match(
-            instring, loc) or None
+            instring,
+            loc) or None
         if not result:
             raise ParseException(instring, loc, self.errmsg, self)
 
@@ -3877,7 +3947,8 @@
 
         if self.strRepr is None:
             self.strRepr = "quoted string, starting with %s ending with %s" % (
-                self.quoteChar, self.endQuoteChar)
+                self.quoteChar,
+                self.endQuoteChar)
 
         return self.strRepr
 
@@ -3910,8 +3981,7 @@
         if min < 1:
             raise ValueError(
                 "cannot specify a minimum length < 1; use "
-                "Optional(CharsNotIn()) if zero-length char group is permitted"
-            )
+                "Optional(CharsNotIn()) if zero-length char group is permitted")
 
         self.minLen = min
 
@@ -4054,14 +4124,17 @@
             if self.ignoreExprs:
                 loc = self._skipIgnorables(instring, loc)
             while loc < instrlen and instring[loc].isspace() and col(
-                    loc, instring) != self.col:
+                    loc,
+                    instring) != self.col:
                 loc += 1
         return loc
 
     def parseImpl(self, instring, loc, doActions=True):
         thiscol = col(loc, instring)
         if thiscol > self.col:
-            raise ParseException(instring, loc, "Text not in expected column",
+            raise ParseException(instring,
+                                 loc,
+                                 "Text not in expected column",
                                  self)
         newloc = loc + self.col - thiscol
         ret = instring[loc:newloc]
@@ -4107,7 +4180,8 @@
     def __init__(self):
         super(LineEnd, self).__init__()
         self.setWhitespaceChars(
-            ParserElement.DEFAULT_WHITE_CHARS.replace("\n", ""))
+            ParserElement.DEFAULT_WHITE_CHARS.replace("\n",
+                                                      ""))
         self.errmsg = "Expected end of line"
 
     def parseImpl(self, instring, loc, doActions=True):
@@ -4219,7 +4293,8 @@
             # if sequence of strings provided, wrap with Literal
             if any(isinstance(expr, basestring) for expr in exprs):
                 exprs = (self._literalStringClass(e) if isinstance(
-                    e, basestring) else e for e in exprs)
+                    e,
+                    basestring) else e for e in exprs)
             self.exprs = list(exprs)
         else:
             try:
@@ -4276,7 +4351,8 @@
         # (likewise for Or's and MatchFirst's)
         if len(self.exprs) == 2:
             other = self.exprs[0]
-            if (isinstance(other, self.__class__) and not other.parseAction
+            if (isinstance(other,
+                           self.__class__) and not other.parseAction
                     and other.resultsName is None and not other.debug):
                 self.exprs = other.exprs[:] + [self.exprs[1]]
                 self.strRepr = None
@@ -4284,7 +4360,8 @@
                 self.mayIndexError |= other.mayIndexError
 
             other = self.exprs[-1]
-            if (isinstance(other, self.__class__) and not other.parseAction
+            if (isinstance(other,
+                           self.__class__) and not other.parseAction
                     and other.resultsName is None and not other.debug):
                 self.exprs = self.exprs[:-1] + other.exprs[:]
                 self.strRepr = None
@@ -4312,13 +4389,16 @@
                 if isinstance(e, ParserElement) and e.resultsName:
                     warnings.warn(
                         "{0}: setting results name {1!r} on {2} expression "
-                        "collides with {3!r} on contained expression".format(
-                            "warn_ungrouped_named_tokens_in_collection", name,
-                            type(self).__name__, e.resultsName),
+                        "collides with {3!r} on contained expression"
+                        .format("warn_ungrouped_named_tokens_in_collection",
+                                name,
+                                type(self).__name__,
+                                e.resultsName),
                         stacklevel=3)
 
         return super(ParseExpression,
-                     self)._setResultsName(name, listAllMatches)
+                     self)._setResultsName(name,
+                                           listAllMatches)
 
 
 class And(ParseExpression):
@@ -4369,14 +4449,17 @@
         # collapse any _PendingSkip's
         if self.exprs:
             if any(
-                    isinstance(e, ParseExpression) and e.exprs
-                    and isinstance(e.exprs[-1], _PendingSkip)
-                    for e in self.exprs[:-1]):
+                    isinstance(e,
+                               ParseExpression) and e.exprs
+                    and isinstance(e.exprs[-1],
+                                   _PendingSkip) for e in self.exprs[:-1]):
                 for i, e in enumerate(self.exprs[:-1]):
                     if e is None:
                         continue
-                    if (isinstance(e, ParseExpression) and e.exprs
-                            and isinstance(e.exprs[-1], _PendingSkip)):
+                    if (isinstance(e,
+                                   ParseExpression) and e.exprs
+                            and isinstance(e.exprs[-1],
+                                           _PendingSkip)):
                         e.exprs[-1] = e.exprs[-1] + self.exprs[i + 1]
                         self.exprs[i + 1] = None
                 self.exprs = [e for e in self.exprs if e is not None]
@@ -4406,8 +4489,10 @@
                     pe.__traceback__ = None
                     raise ParseSyntaxException._from_exception(pe)
                 except IndexError:
-                    raise ParseSyntaxException(instring, len(instring),
-                                               self.errmsg, self)
+                    raise ParseSyntaxException(instring,
+                                               len(instring),
+                                               self.errmsg,
+                                               self)
             else:
                 loc, exprtokens = e._parse(instring, loc, doActions)
             if exprtokens or exprtokens.haskeys():
@@ -4480,8 +4565,10 @@
                     maxExcLoc = err.loc
             except IndexError:
                 if len(instring) > maxExcLoc:
-                    maxException = ParseException(instring, len(instring),
-                                                  e.errmsg, self)
+                    maxException = ParseException(instring,
+                                                  len(instring),
+                                                  e.errmsg,
+                                                  self)
                     maxExcLoc = len(instring)
             else:
                 # save match among all matches, to retry longest to shortest
@@ -4525,8 +4612,10 @@
             maxException.msg = self.errmsg
             raise maxException
         else:
-            raise ParseException(instring, loc,
-                                 "no defined alternatives to match", self)
+            raise ParseException(instring,
+                                 loc,
+                                 "no defined alternatives to match",
+                                 self)
 
     def __ixor__(self, other):
         if isinstance(other, basestring):
@@ -4554,9 +4643,10 @@
                 warnings.warn(
                     "{0}: setting results name {1!r} on {2} expression "
                     "may only return a single token for an And alternative, "
-                    "in future will return the full list of tokens".format(
-                        "warn_multiple_tokens_in_named_alternation", name,
-                        type(self).__name__),
+                    "in future will return the full list of tokens"
+                    .format("warn_multiple_tokens_in_named_alternation",
+                            name,
+                            type(self).__name__),
                     stacklevel=3)
 
         return super(Or, self)._setResultsName(name, listAllMatches)
@@ -4605,8 +4695,10 @@
                     maxExcLoc = err.loc
             except IndexError:
                 if len(instring) > maxExcLoc:
-                    maxException = ParseException(instring, len(instring),
-                                                  e.errmsg, self)
+                    maxException = ParseException(instring,
+                                                  len(instring),
+                                                  e.errmsg,
+                                                  self)
                     maxExcLoc = len(instring)
 
         # only got here if no expression matched, raise exception for match that made it the furthest
@@ -4615,8 +4707,10 @@
                 maxException.msg = self.errmsg
                 raise maxException
             else:
-                raise ParseException(instring, loc,
-                                     "no defined alternatives to match", self)
+                raise ParseException(instring,
+                                     loc,
+                                     "no defined alternatives to match",
+                                     self)
 
     def __ior__(self, other):
         if isinstance(other, basestring):
@@ -4644,9 +4738,10 @@
                 warnings.warn(
                     "{0}: setting results name {1!r} on {2} expression "
                     "may only return a single token for an And alternative, "
-                    "in future will return the full list of tokens".format(
-                        "warn_multiple_tokens_in_named_alternation", name,
-                        type(self).__name__),
+                    "in future will return the full list of tokens"
+                    .format("warn_multiple_tokens_in_named_alternation",
+                            name,
+                            type(self).__name__),
                     stacklevel=3)
 
         return super(MatchFirst, self)._setResultsName(name, listAllMatches)
@@ -4723,23 +4818,31 @@
 
     def parseImpl(self, instring, loc, doActions=True):
         if self.initExprGroups:
-            self.opt1map = dict(
-                (id(e.expr), e) for e in self.exprs if isinstance(e, Optional))
+            self.opt1map = dict((id(e.expr),
+                                 e) for e in self.exprs
+                                if isinstance(e,
+                                              Optional))
             opt1 = [e.expr for e in self.exprs if isinstance(e, Optional)]
             opt2 = [
                 e for e in self.exprs
-                if e.mayReturnEmpty and not isinstance(e, (Optional, Regex))
+                if e.mayReturnEmpty and not isinstance(e,
+                                                       (Optional,
+                                                        Regex))
             ]
             self.optionals = opt1 + opt2
             self.multioptionals = [
-                e.expr for e in self.exprs if isinstance(e, ZeroOrMore)
+                e.expr for e in self.exprs if isinstance(e,
+                                                         ZeroOrMore)
             ]
             self.multirequired = [
-                e.expr for e in self.exprs if isinstance(e, OneOrMore)
+                e.expr for e in self.exprs if isinstance(e,
+                                                         OneOrMore)
             ]
             self.required = [
-                e for e in self.exprs
-                if not isinstance(e, (Optional, ZeroOrMore, OneOrMore))
+                e for e in self.exprs if not isinstance(e,
+                                                        (Optional,
+                                                         ZeroOrMore,
+                                                         OneOrMore))
             ]
             self.required += self.multirequired
             self.initExprGroups = False
@@ -4769,13 +4872,14 @@
         if tmpReqd:
             missing = ", ".join(_ustr(e) for e in tmpReqd)
             raise ParseException(
-                instring, loc,
+                instring,
+                loc,
                 "Missing one or more required elements (%s)" % missing)
 
         # add any unmatched Optionals, in case they have default values defined
         matchOrder += [
-            e for e in self.exprs
-            if isinstance(e, Optional) and e.expr in tmpOpt
+            e for e in self.exprs if isinstance(e,
+                                                Optional) and e.expr in tmpOpt
         ]
 
         resultlist = []
@@ -4968,8 +5072,10 @@
         self.retreat = retreat
         self.errmsg = "not preceded by " + str(expr)
         self.skipWhitespace = False
-        self.parseAction.append(
-            lambda s, l, t: t.__delitem__(slice(None, None)))
+        self.parseAction.append(lambda s,
+                                l,
+                                t: t.__delitem__(slice(None,
+                                                       None)))
 
     def parseImpl(self, instring, loc=0, doActions=True):
         if self.exact:
@@ -5094,13 +5200,14 @@
                 if isinstance(e, ParserElement) and e.resultsName:
                     warnings.warn(
                         "{0}: setting results name {1!r} on {2} expression "
-                        "collides with {3!r} on contained expression".format(
-                            "warn_ungrouped_named_tokens_in_collection", name,
-                            type(self).__name__, e.resultsName),
+                        "collides with {3!r} on contained expression"
+                        .format("warn_ungrouped_named_tokens_in_collection",
+                                name,
+                                type(self).__name__,
+                                e.resultsName),
                         stacklevel=3)
 
-        return super(_MultipleMatch,
-                     self)._setResultsName(name, listAllMatches)
+        return super(_MultipleMatch, self)._setResultsName(name, listAllMatches)
 
 
 class OneOrMore(_MultipleMatch):
@@ -5473,9 +5580,10 @@
             if self.expr is None:
                 warnings.warn(
                     "{0}: setting results name {0!r} on {1} expression "
-                    "that has no contained expression".format(
-                        "warn_name_set_on_empty_Forward", name,
-                        type(self).__name__),
+                    "that has no contained expression"
+                    .format("warn_name_set_on_empty_Forward",
+                            name,
+                            type(self).__name__),
                     stacklevel=3)
 
         return super(Forward, self)._setResultsName(name, listAllMatches)
@@ -5528,9 +5636,10 @@
     def postParse(self, instring, loc, tokenlist):
         retToks = tokenlist.copy()
         del retToks[:]
-        retToks += ParseResults(
-            ["".join(tokenlist._asStringList(self.joinString))],
-            modal=self.modalResults)
+        retToks += ParseResults([
+            "".join(tokenlist._asStringList(self.joinString))
+        ],
+                                modal=self.modalResults)
 
         if self.resultsName and retToks.haskeys():
             return [retToks]
@@ -5618,7 +5727,8 @@
             else:
                 dictvalue = tok.copy()  # ParseResults(i)
                 del dictvalue[0]
-                if len(dictvalue) != 1 or (isinstance(dictvalue, ParseResults)
+                if len(dictvalue) != 1 or (isinstance(dictvalue,
+                                                      ParseResults)
                                            and dictvalue.haskeys()):
                     tokenlist[ikey] = _ParseResultsWithOffset(dictvalue, i)
                 else:
@@ -5709,13 +5819,15 @@
         s, l, t = paArgs[-3:]
         if len(paArgs) > 3:
             thisFunc = paArgs[0].__class__.__name__ + '.' + thisFunc
-        sys.stderr.write(">>entering %s(line: '%s', %d, %r)\n" %
-                         (thisFunc, line(l, s), l, t))
+        sys.stderr.write(">>entering %s(line: '%s', %d, %r)\n" % (thisFunc,
+                                                                  line(l,
+                                                                       s),
+                                                                  l,
+                                                                  t))
         try:
             ret = f(*paArgs)
         except Exception as exc:
-            sys.stderr.write("<<leaving %s (exception: %s)\n" %
-                             (thisFunc, exc))
+            sys.stderr.write("<<leaving %s (exception: %s)\n" % (thisFunc, exc))
             raise
         sys.stderr.write("<<leaving %s (ret: %r)\n" % (thisFunc, ret))
         return ret
@@ -5957,14 +6069,12 @@
         # ~ print (strs, "->", "|".join([_escapeRegexChars(sym) for sym in symbols]))
         try:
             if len(symbols) == len("".join(symbols)):
-                return Regex(
-                    "[%s]" %
-                    "".join(_escapeRegexRangeChars(sym)
-                            for sym in symbols)).setName(' | '.join(symbols))
+                return Regex("[%s]" % "".join(
+                    _escapeRegexRangeChars(sym)
+                    for sym in symbols)).setName(' | '.join(symbols))
             else:
-                return Regex("|".join(re.escape(sym)
-                                      for sym in symbols)).setName(
-                                          ' | '.join(symbols))
+                return Regex("|".join(re.escape(sym) for sym in
+                                      symbols)).setName(' | '.join(symbols))
         except Exception:
             warnings.warn(
                 "Exception creating Regex for oneOf, building MatchFirst",
@@ -6096,8 +6206,8 @@
     """
     locator = Empty().setParseAction(lambda s, l, t: l)
     return Group(
-        locator("locn_start") + expr("value") +
-        locator.copy().leaveWhitespace()("locn_end"))
+        locator("locn_start") + expr("value")
+        + locator.copy().leaveWhitespace()("locn_end"))
 
 
 # convenience constants for positional expressions
@@ -6107,14 +6217,23 @@
 stringStart = StringStart().setName("stringStart")
 stringEnd = StringEnd().setName("stringEnd")
 
-_escapedPunc = Word(_bslash, r"\[]-*.$+^?()~ ",
-                    exact=2).setParseAction(lambda s, l, t: t[0][1])
+_escapedPunc = Word(_bslash,
+                    r"\[]-*.$+^?()~ ",
+                    exact=2).setParseAction(lambda s,
+                                            l,
+                                            t: t[0][1])
 _escapedHexChar = Regex(r"\\0?[xX][0-9a-fA-F]+").setParseAction(
-    lambda s, l, t: unichr(int(t[0].lstrip(r'\0x'), 16)))
-_escapedOctChar = Regex(r"\\0[0-7]+").setParseAction(
-    lambda s, l, t: unichr(int(t[0][1:], 8)))
+    lambda s,
+    l,
+    t: unichr(int(t[0].lstrip(r'\0x'),
+                  16)))
+_escapedOctChar = Regex(r"\\0[0-7]+").setParseAction(lambda s,
+                                                     l,
+                                                     t: unichr(int(t[0][1:],
+                                                                   8)))
 _singleChar = _escapedPunc | _escapedHexChar | _escapedOctChar | CharsNotIn(
-    r'\]', exact=1)
+    r'\]',
+    exact=1)
 _charRange = Group(_singleChar + Suppress("-") + _singleChar)
 _reBracketExpr = Literal("[") + Optional("^").setResultsName("negate") + Group(
     OneOrMore(_charRange | _singleChar)).setResultsName("body") + "]"
@@ -6146,9 +6265,11 @@
      - any combination of the above (``'aeiouy'``,
        ``'a-zA-Z0-9_$'``, etc.)
     """
-    _expanded = lambda p: p if not isinstance(p, ParseResults) else ''.join(
-        unichr(c) for c in range(ord(p[0]),
-                                 ord(p[1]) + 1))
+    _expanded = lambda p: p if not isinstance(p,
+                                              ParseResults) else ''.join(
+                                                  unichr(c) for c in range(
+                                                      ord(p[0]),
+                                                      ord(p[1]) + 1))
     try:
         return "".join(
             _expanded(part) for part in _reBracketExpr.parseString(s).body)
@@ -6162,7 +6283,8 @@
     """
     def verifyCol(strg, locn, toks):
         if col(locn, strg) != n:
-            raise ParseException(strg, locn,
+            raise ParseException(strg,
+                                 locn,
                                  "matched token not at column %d" % n)
 
     return verifyCol
@@ -6240,8 +6362,10 @@
         return [func(tokn, *args) for tokn in t]
 
     try:
-        func_name = getattr(func, '__name__',
-                            getattr(func, '__class__').__name__)
+        func_name = getattr(func,
+                            '__name__',
+                            getattr(func,
+                                    '__class__').__name__)
     except Exception:
         func_name = str(func)
     pa.__name__ = func_name
@@ -6272,32 +6396,42 @@
     tagAttrName = Word(alphas, alphanums + "_-:")
     if xml:
         tagAttrValue = dblQuotedString.copy().setParseAction(removeQuotes)
-        openTag = (suppress_LT + tagStr("tag") + Dict(
-            ZeroOrMore(Group(tagAttrName + Suppress("=") + tagAttrValue))) +
-                   Optional("/", default=[False])
-                   ("empty").setParseAction(lambda s, l, t: t[0] == '/') +
-                   suppress_GT)
+        openTag = (
+            suppress_LT + tagStr("tag") + Dict(
+                ZeroOrMore(Group(tagAttrName + Suppress("=") + tagAttrValue)))
+            + Optional("/",
+                       default=[False])("empty").setParseAction(lambda s,
+                                                                l,
+                                                                t: t[0] == '/')
+            + suppress_GT)
     else:
         tagAttrValue = quotedString.copy().setParseAction(removeQuotes) | Word(
-            printables, excludeChars=">")
-        openTag = (suppress_LT + tagStr("tag") + Dict(
-            ZeroOrMore(
-                Group(
-                    tagAttrName.setParseAction(downcaseTokens) +
-                    Optional(Suppress("=") + tagAttrValue)))) +
-                   Optional("/", default=[False])
-                   ("empty").setParseAction(lambda s, l, t: t[0] == '/') +
-                   suppress_GT)
+            printables,
+            excludeChars=">")
+        openTag = (
+            suppress_LT + tagStr("tag") + Dict(
+                ZeroOrMore(
+                    Group(
+                        tagAttrName.setParseAction(downcaseTokens)
+                        + Optional(Suppress("=") + tagAttrValue))))
+            + Optional("/",
+                       default=[False])("empty").setParseAction(lambda s,
+                                                                l,
+                                                                t: t[0] == '/')
+            + suppress_GT)
     closeTag = Combine(_L("</") + tagStr + ">", adjacent=False)
 
     openTag.setName("<%s>" % resname)
     # add start<tagname> results name in parse action now that ungrouped names are not reported at two levels
     openTag.addParseAction(lambda t: t.__setitem__(
-        "start" + "".join(resname.replace(":", " ").title().split()), t.copy())
-                           )
+        "start" + "".join(resname.replace(":",
+                                          " ").title().split()),
+        t.copy()))
     closeTag = closeTag(
-        "end" + "".join(resname.replace(":", " ").title().split())).setName(
-            "</%s>" % resname)
+        "end"
+        + "".join(resname.replace(":",
+                                  " ").title().split())).setName("</%s>"
+                                                                 % resname)
     openTag.tag = resname
     closeTag.tag = resname
     openTag.tag_body = SkipTo(closeTag())
@@ -6407,8 +6541,12 @@
             if attrValue != withAttribute.ANY_VALUE and tokens[
                     attrName] != attrValue:
                 raise ParseException(
-                    s, l, "attribute '%s' has value '%s', must be '%s'" %
-                    (attrName, tokens[attrName], attrValue))
+                    s,
+                    l,
+                    "attribute '%s' has value '%s', must be '%s'" %
+                    (attrName,
+                     tokens[attrName],
+                     attrValue))
 
     return pa
 
@@ -6552,21 +6690,21 @@
         thisExpr = Forward().setName(termName)
         if rightLeftAssoc == opAssoc.LEFT:
             if arity == 1:
-                matchExpr = _FB(lastExpr + opExpr) + Group(lastExpr +
-                                                           OneOrMore(opExpr))
+                matchExpr = _FB(lastExpr + opExpr) + Group(lastExpr
+                                                           + OneOrMore(opExpr))
             elif arity == 2:
                 if opExpr is not None:
                     matchExpr = _FB(lastExpr + opExpr + lastExpr) + Group(
                         lastExpr + OneOrMore(opExpr + lastExpr))
                 else:
-                    matchExpr = _FB(lastExpr +
-                                    lastExpr) + Group(lastExpr +
-                                                      OneOrMore(lastExpr))
+                    matchExpr = _FB(lastExpr
+                                    + lastExpr) + Group(lastExpr
+                                                        + OneOrMore(lastExpr))
             elif arity == 3:
                 matchExpr = (
                     _FB(lastExpr + opExpr1 + lastExpr + opExpr2 + lastExpr) +
-                    Group(lastExpr +
-                          OneOrMore(opExpr1 + lastExpr + opExpr2 + lastExpr)))
+                    Group(lastExpr
+                          + OneOrMore(opExpr1 + lastExpr + opExpr2 + lastExpr)))
             else:
                 raise ValueError(
                     "operator must be unary (1), binary (2), or ternary (3)")
@@ -6575,20 +6713,20 @@
                 # try to avoid LR with this extra test
                 if not isinstance(opExpr, Optional):
                     opExpr = Optional(opExpr)
-                matchExpr = _FB(opExpr.expr + thisExpr) + Group(opExpr +
-                                                                thisExpr)
+                matchExpr = _FB(opExpr.expr + thisExpr) + Group(opExpr
+                                                                + thisExpr)
             elif arity == 2:
                 if opExpr is not None:
                     matchExpr = _FB(lastExpr + opExpr + thisExpr) + Group(
                         lastExpr + OneOrMore(opExpr + thisExpr))
                 else:
-                    matchExpr = _FB(lastExpr +
-                                    thisExpr) + Group(lastExpr +
-                                                      OneOrMore(thisExpr))
+                    matchExpr = _FB(lastExpr
+                                    + thisExpr) + Group(lastExpr
+                                                        + OneOrMore(thisExpr))
             elif arity == 3:
                 matchExpr = (
-                    _FB(lastExpr + opExpr1 + thisExpr + opExpr2 + thisExpr) +
-                    Group(lastExpr + opExpr1 + thisExpr + opExpr2 + thisExpr))
+                    _FB(lastExpr + opExpr1 + thisExpr + opExpr2 + thisExpr)
+                    + Group(lastExpr + opExpr1 + thisExpr + opExpr2 + thisExpr))
             else:
                 raise ValueError(
                     "operator must be unary (1), binary (2), or ternary (3)")
@@ -6611,17 +6749,17 @@
 dropped in a future release."""
 
 dblQuotedString = Combine(
-    Regex(r'"(?:[^"\n\r\\]|(?:"")|(?:\\(?:[^x]|x[0-9a-fA-F]+)))*') +
-    '"').setName("string enclosed in double quotes")
+    Regex(r'"(?:[^"\n\r\\]|(?:"")|(?:\\(?:[^x]|x[0-9a-fA-F]+)))*')
+    + '"').setName("string enclosed in double quotes")
 sglQuotedString = Combine(
-    Regex(r"'(?:[^'\n\r\\]|(?:'')|(?:\\(?:[^x]|x[0-9a-fA-F]+)))*") +
-    "'").setName("string enclosed in single quotes")
+    Regex(r"'(?:[^'\n\r\\]|(?:'')|(?:\\(?:[^x]|x[0-9a-fA-F]+)))*")
+    + "'").setName("string enclosed in single quotes")
 quotedString = Combine(
     Regex(r'"(?:[^"\n\r\\]|(?:"")|(?:\\(?:[^x]|x[0-9a-fA-F]+)))*') + '"'
-    | Regex(r"'(?:[^'\n\r\\]|(?:'')|(?:\\(?:[^x]|x[0-9a-fA-F]+)))*") +
-    "'").setName("quotedString using single or double quotes")
-unicodeString = Combine(_L('u') +
-                        quotedString.copy()).setName("unicode string literal")
+    | Regex(r"'(?:[^'\n\r\\]|(?:'')|(?:\\(?:[^x]|x[0-9a-fA-F]+)))*")
+    + "'").setName("quotedString using single or double quotes")
+unicodeString = Combine(_L('u')
+                        + quotedString.copy()).setName("unicode string literal")
 
 
 def nestedExpr(opener="(",
@@ -6699,30 +6837,29 @@
             if len(opener) == 1 and len(closer) == 1:
                 if ignoreExpr is not None:
                     content = (Combine(
-                        OneOrMore(~ignoreExpr +
-                                  CharsNotIn(opener + closer +
-                                             ParserElement.DEFAULT_WHITE_CHARS,
-                                             exact=1))).setParseAction(
-                                                 lambda t: t[0].strip()))
+                        OneOrMore(~ignoreExpr + CharsNotIn(
+                            opener + closer + ParserElement.DEFAULT_WHITE_CHARS,
+                            exact=1))).setParseAction(lambda t: t[0].strip()))
                 else:
-                    content = (empty.copy() +
-                               CharsNotIn(opener + closer +
-                                          ParserElement.DEFAULT_WHITE_CHARS)
+                    content = (empty.copy()
+                               + CharsNotIn(opener + closer
+                                            + ParserElement.DEFAULT_WHITE_CHARS)
                                .setParseAction(lambda t: t[0].strip()))
             else:
                 if ignoreExpr is not None:
                     content = (Combine(
-                        OneOrMore(~ignoreExpr + ~Literal(opener) +
-                                  ~Literal(closer) +
-                                  CharsNotIn(ParserElement.DEFAULT_WHITE_CHARS,
-                                             exact=1))).setParseAction(
-                                                 lambda t: t[0].strip()))
+                        OneOrMore(
+                            ~ignoreExpr + ~Literal(opener) + ~Literal(closer)
+                            + CharsNotIn(ParserElement.DEFAULT_WHITE_CHARS,
+                                         exact=1))).setParseAction(
+                                             lambda t: t[0].strip()))
                 else:
                     content = (Combine(
-                        OneOrMore(~Literal(opener) + ~Literal(closer) +
-                                  CharsNotIn(ParserElement.DEFAULT_WHITE_CHARS,
-                                             exact=1))).setParseAction(
-                                                 lambda t: t[0].strip()))
+                        OneOrMore(
+                            ~Literal(opener) + ~Literal(closer)
+                            + CharsNotIn(ParserElement.DEFAULT_WHITE_CHARS,
+                                         exact=1))).setParseAction(
+                                             lambda t: t[0].strip()))
         else:
             raise ValueError(
                 "opening and closing arguments must be strings if no content expression is given"
@@ -6730,8 +6867,8 @@
     ret = Forward()
     if ignoreExpr is not None:
         ret <<= Group(
-            Suppress(opener) + ZeroOrMore(ignoreExpr | ret | content) +
-            Suppress(closer))
+            Suppress(opener) + ZeroOrMore(ignoreExpr | ret | content)
+            + Suppress(closer))
     else:
         ret <<= Group(
             Suppress(opener) + ZeroOrMore(ret | content) + Suppress(closer))
@@ -6826,7 +6963,8 @@
         indentStack[:] = backup_stack
 
     def checkPeerIndent(s, l, t):
-        if l >= len(s): return
+        if l >= len(s):
+            return
         curCol = col(l, s)
         if curCol != indentStack[-1]:
             if curCol > indentStack[-1]:
@@ -6841,7 +6979,8 @@
             raise ParseException(s, l, "not a subentry")
 
     def checkUnindent(s, l, t):
-        if l >= len(s): return
+        if l >= len(s):
+            return
         curCol = col(l, s)
         if not (indentStack and curCol in indentStack):
             raise ParseException(s, l, "not an unindent")
@@ -6850,20 +6989,20 @@
 
     NL = OneOrMore(LineEnd().setWhitespaceChars("\t ").suppress(),
                    stopOn=StringEnd())
-    INDENT = (Empty() +
-              Empty().setParseAction(checkSubIndent)).setName('INDENT')
+    INDENT = (Empty()
+              + Empty().setParseAction(checkSubIndent)).setName('INDENT')
     PEER = Empty().setParseAction(checkPeerIndent).setName('')
     UNDENT = Empty().setParseAction(checkUnindent).setName('UNINDENT')
     if indent:
         smExpr = Group(
-            Optional(NL) + INDENT +
-            OneOrMore(PEER + Group(blockStatementExpr) + Optional(NL),
-                      stopOn=StringEnd()) + UNDENT)
+            Optional(NL) + INDENT
+            + OneOrMore(PEER + Group(blockStatementExpr) + Optional(NL),
+                        stopOn=StringEnd()) + UNDENT)
     else:
         smExpr = Group(
-            Optional(NL) +
-            OneOrMore(PEER + Group(blockStatementExpr) + Optional(NL),
-                      stopOn=StringEnd()) + UNDENT)
+            Optional(NL)
+            + OneOrMore(PEER + Group(blockStatementExpr) + Optional(NL),
+                        stopOn=StringEnd()) + UNDENT)
     smExpr.setFailAction(lambda a, b, c, d: reset_stack())
     blockStatementExpr.ignore(_bslash + LineEnd())
     return smExpr.setName('indented block')
@@ -6875,8 +7014,8 @@
 anyOpenTag, anyCloseTag = makeHTMLTags(
     Word(alphas, alphanums + "_:").setName('any tag'))
 _htmlEntityMap = dict(zip("gt lt amp nbsp quot apos".split(), '><& "\''))
-commonHTMLEntity = Regex('&(?P<entity>' + '|'.join(_htmlEntityMap.keys()) +
-                         ");").setName("common HTML entity")
+commonHTMLEntity = Regex('&(?P<entity>' + '|'.join(_htmlEntityMap.keys())
+                         + ");").setName("common HTML entity")
 
 
 def replaceHTMLEntity(t):
@@ -6885,8 +7024,8 @@
 
 
 # it's easy to get these comment structures wrong - they're very common, so may as well make them available
-cStyleComment = Combine(Regex(r"/\*(?:[^*]|\*(?!/))*") +
-                        '*/').setName("C style comment")
+cStyleComment = Combine(Regex(r"/\*(?:[^*]|\*(?!/))*")
+                        + '*/').setName("C style comment")
 "Comment of the form ``/* ... */``"
 
 htmlComment = Regex(r"<!--[\s\S]*?-->").setName("HTML comment")
@@ -6909,9 +7048,10 @@
 
 _commasepitem = Combine(
     OneOrMore(
-        Word(printables, excludeChars=',') +
-        Optional(Word(" \t") + ~Literal(",") +
-                 ~LineEnd()))).streamline().setName("commaItem")
+        Word(printables,
+             excludeChars=',')
+        + Optional(Word(" \t") + ~Literal(",")
+                   + ~LineEnd()))).streamline().setName("commaItem")
 commaSeparatedList = delimitedList(
     Optional(quotedString.copy() | _commasepitem,
              default="")).setName("commaSeparatedList")
@@ -7081,8 +7221,9 @@
     integer = Word(nums).setName("integer").setParseAction(convertToInteger)
     """expression that parses an unsigned integer, returns an int"""
 
-    hex_integer = Word(hexnums).setName("hex integer").setParseAction(
-        tokenMap(int, 16))
+    hex_integer = Word(hexnums).setName(
+        "hex integer").setParseAction(tokenMap(int,
+                                               16))
     """expression that parses a hexadecimal integer, returns an int"""
 
     signed_integer = Regex(r'[+-]?\d+').setName(
@@ -7090,13 +7231,13 @@
     """expression that parses an integer with optional leading sign, returns an int"""
 
     fraction = (
-        signed_integer().setParseAction(convertToFloat) + '/' +
-        signed_integer().setParseAction(convertToFloat)).setName("fraction")
+        signed_integer().setParseAction(convertToFloat) + '/'
+        + signed_integer().setParseAction(convertToFloat)).setName("fraction")
     """fractional expression of an integer divided by an integer, returns a float"""
     fraction.addParseAction(lambda t: t[0] / t[-1])
 
-    mixed_integer = (fraction | signed_integer +
-                     Optional(Optional('-').suppress() + fraction)
+    mixed_integer = (fraction | signed_integer
+                     + Optional(Optional('-').suppress() + fraction)
                      ).setName("fraction or mixed integer-fraction")
     """mixed integer of the form 'integer - fraction', with optional leading integer, returns float"""
     mixed_integer.addParseAction(sum)
@@ -7131,17 +7272,19 @@
     _ipv6_part = Regex(r'[0-9a-fA-F]{1,4}').setName("hex_integer")
     _full_ipv6_address = (_ipv6_part +
                           (':' + _ipv6_part) * 7).setName("full IPv6 address")
-    _short_ipv6_address = (Optional(_ipv6_part + (':' + _ipv6_part) *
-                                    (0, 6)) + "::" +
-                           Optional(_ipv6_part + (':' + _ipv6_part) *
-                                    (0, 6))).setName("short IPv6 address")
+    _short_ipv6_address = (Optional(_ipv6_part + (':' + _ipv6_part) * (0,
+                                                                       6))
+                           + "::"
+                           + Optional(_ipv6_part + (':' + _ipv6_part) * (0,
+                                                                         6))
+                           ).setName("short IPv6 address")
     _short_ipv6_address.addCondition(lambda t: sum(
         1 for tt in t if pyparsing_common._ipv6_part.matches(tt)) < 8)
-    _mixed_ipv6_address = ("::ffff:" +
-                           ipv4_address).setName("mixed IPv6 address")
+    _mixed_ipv6_address = ("::ffff:"
+                           + ipv4_address).setName("mixed IPv6 address")
     ipv6_address = Combine(
-        (_full_ipv6_address | _mixed_ipv6_address |
-         _short_ipv6_address).setName("IPv6 address")).setName("IPv6 address")
+        (_full_ipv6_address | _mixed_ipv6_address
+         | _short_ipv6_address).setName("IPv6 address")).setName("IPv6 address")
     "IPv6 address (long, short, or mixed form)"
 
     mac_address = Regex(
@@ -7211,8 +7354,8 @@
     ).setName("ISO8601 datetime")
     "ISO8601 datetime (``yyyy-mm-ddThh:mm:ss.s(Z|+-00:00)``) - trailing seconds, milliseconds, and timezone optional; accepts separating ``'T'`` or ``' '``"
 
-    uuid = Regex(
-        r'[0-9a-fA-F]{8}(-[0-9a-fA-F]{4}){3}-[0-9a-fA-F]{12}').setName("UUID")
+    uuid = Regex(r'[0-9a-fA-F]{8}(-[0-9a-fA-F]{4}){3}-[0-9a-fA-F]{12}').setName(
+        "UUID")
     "UUID (``xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx``)"
 
     _html_stripper = anyOpenTag.suppress() | anyCloseTag.suppress()
@@ -7236,12 +7379,13 @@
         return pyparsing_common._html_stripper.transformString(tokens[0])
 
     _commasepitem = Combine(
-        OneOrMore(~Literal(",") + ~LineEnd() +
-                  Word(printables, excludeChars=',') +
-                  Optional(White(" \t")))).streamline().setName("commaItem")
+        OneOrMore(~Literal(",") + ~LineEnd() + Word(printables,
+                                                    excludeChars=',')
+                  + Optional(White(" \t")))).streamline().setName("commaItem")
     comma_separated_list = delimitedList(
         Optional(quotedString.copy()
-                 | _commasepitem, default='')).setName("comma separated list")
+                 | _commasepitem,
+                 default='')).setName("comma separated list")
     """Predefined expression of 1 or more printable words or quoted strings, separated by commas."""
 
     upcaseTokens = staticmethod(tokenMap(lambda t: _ustr(t).upper()))
@@ -7260,9 +7404,12 @@
     def __get__(self, obj, cls):
         if cls is None:
             cls = type(obj)
-        if not hasattr(cls, '_intern') or any(
-                cls._intern is getattr(superclass, '_intern', [])
-                for superclass in cls.__mro__[1:]):
+        if not hasattr(cls,
+                       '_intern') or any(
+                           cls._intern is getattr(superclass,
+                                                  '_intern',
+                                                  [])
+                           for superclass in cls.__mro__[1:]):
             cls._intern = {}
         attrname = self.fn.__name__
         if attrname not in cls._intern:
@@ -7300,7 +7447,8 @@
     def printables(cls):
         "all non-whitespace characters in this range"
         return u''.join(
-            filterfalse(unicode.isspace, cls._get_chars_for_ranges()))
+            filterfalse(unicode.isspace,
+                        cls._get_chars_for_ranges()))
 
     @_lazyclassproperty
     def alphas(cls):
@@ -7327,42 +7475,63 @@
     class Latin1(unicode_set):
         "Unicode set for Latin-1 Unicode Character Range"
         _ranges = [
-            (0x0020, 0x007e),
-            (0x00a0, 0x00ff),
+            (0x0020,
+             0x007e),
+            (0x00a0,
+             0x00ff),
         ]
 
     class LatinA(unicode_set):
         "Unicode set for Latin-A Unicode Character Range"
         _ranges = [
-            (0x0100, 0x017f),
+            (0x0100,
+             0x017f),
         ]
 
     class LatinB(unicode_set):
         "Unicode set for Latin-B Unicode Character Range"
         _ranges = [
-            (0x0180, 0x024f),
+            (0x0180,
+             0x024f),
         ]
 
     class Greek(unicode_set):
         "Unicode set for Greek Unicode Character Ranges"
         _ranges = [
-            (0x0370, 0x03ff),
-            (0x1f00, 0x1f15),
-            (0x1f18, 0x1f1d),
-            (0x1f20, 0x1f45),
-            (0x1f48, 0x1f4d),
-            (0x1f50, 0x1f57),
-            (0x1f59, ),
-            (0x1f5b, ),
-            (0x1f5d, ),
-            (0x1f5f, 0x1f7d),
-            (0x1f80, 0x1fb4),
-            (0x1fb6, 0x1fc4),
-            (0x1fc6, 0x1fd3),
-            (0x1fd6, 0x1fdb),
-            (0x1fdd, 0x1fef),
-            (0x1ff2, 0x1ff4),
-            (0x1ff6, 0x1ffe),
+            (0x0370,
+             0x03ff),
+            (0x1f00,
+             0x1f15),
+            (0x1f18,
+             0x1f1d),
+            (0x1f20,
+             0x1f45),
+            (0x1f48,
+             0x1f4d),
+            (0x1f50,
+             0x1f57),
+            (0x1f59,
+             ),
+            (0x1f5b,
+             ),
+            (0x1f5d,
+             ),
+            (0x1f5f,
+             0x1f7d),
+            (0x1f80,
+             0x1fb4),
+            (0x1fb6,
+             0x1fc4),
+            (0x1fc6,
+             0x1fd3),
+            (0x1fd6,
+             0x1fdb),
+            (0x1fdd,
+             0x1fef),
+            (0x1ff2,
+             0x1ff4),
+            (0x1ff6,
+             0x1ffe),
         ]
 
     class Cyrillic(unicode_set):
@@ -7372,8 +7541,10 @@
     class Chinese(unicode_set):
         "Unicode set for Chinese Unicode Character Range"
         _ranges = [
-            (0x4e00, 0x9fff),
-            (0x3000, 0x303f),
+            (0x4e00,
+             0x9fff),
+            (0x3000,
+             0x303f),
         ]
 
     class Japanese(unicode_set):
@@ -7383,31 +7554,41 @@
         class Kanji(unicode_set):
             "Unicode set for Kanji Unicode Character Range"
             _ranges = [
-                (0x4E00, 0x9Fbf),
-                (0x3000, 0x303f),
+                (0x4E00,
+                 0x9Fbf),
+                (0x3000,
+                 0x303f),
             ]
 
         class Hiragana(unicode_set):
             "Unicode set for Hiragana Unicode Character Range"
             _ranges = [
-                (0x3040, 0x309f),
+                (0x3040,
+                 0x309f),
             ]
 
         class Katakana(unicode_set):
             "Unicode set for Katakana  Unicode Character Range"
             _ranges = [
-                (0x30a0, 0x30ff),
+                (0x30a0,
+                 0x30ff),
             ]
 
     class Korean(unicode_set):
         "Unicode set for Korean Unicode Character Range"
         _ranges = [
-            (0xac00, 0xd7af),
-            (0x1100, 0x11ff),
-            (0x3130, 0x318f),
-            (0xa960, 0xa97f),
-            (0xd7b0, 0xd7ff),
-            (0x3000, 0x303f),
+            (0xac00,
+             0xd7af),
+            (0x1100,
+             0x11ff),
+            (0x3130,
+             0x318f),
+            (0xa960,
+             0xa97f),
+            (0xd7b0,
+             0xd7ff),
+            (0x3000,
+             0x303f),
         ]
 
     class CJK(Chinese, Japanese, Korean):
@@ -7417,22 +7598,28 @@
     class Thai(unicode_set):
         "Unicode set for Thai Unicode Character Range"
         _ranges = [
-            (0x0e01, 0x0e3a),
-            (0x0e3f, 0x0e5b),
+            (0x0e01,
+             0x0e3a),
+            (0x0e3f,
+             0x0e5b),
         ]
 
     class Arabic(unicode_set):
         "Unicode set for Arabic Unicode Character Range"
         _ranges = [
-            (0x0600, 0x061b),
-            (0x061e, 0x06ff),
-            (0x0700, 0x077f),
+            (0x0600,
+             0x061b),
+            (0x061e,
+             0x06ff),
+            (0x0700,
+             0x077f),
         ]
 
     class Hebrew(unicode_set):
         "Unicode set for Hebrew Unicode Character Range"
         _ranges = [
-            (0x0590, 0x05ff),
+            (0x0590,
+             0x05ff),
         ]
 
     class Devanagari(unicode_set):
@@ -7441,9 +7628,9 @@
 
 
 pyparsing_unicode.Japanese._ranges = (
-    pyparsing_unicode.Japanese.Kanji._ranges +
-    pyparsing_unicode.Japanese.Hiragana._ranges +
-    pyparsing_unicode.Japanese.Katakana._ranges)
+    pyparsing_unicode.Japanese.Kanji._ranges
+    + pyparsing_unicode.Japanese.Hiragana._ranges
+    + pyparsing_unicode.Japanese.Katakana._ranges)
 
 # define ranges in language character sets
 if PY_3:
@@ -7453,11 +7640,12 @@
     setattr(pyparsing_unicode, u"", pyparsing_unicode.Greek)
     setattr(pyparsing_unicode, u"", pyparsing_unicode.Hebrew)
     setattr(pyparsing_unicode, u"", pyparsing_unicode.Japanese)
-    setattr(pyparsing_unicode.Japanese, u"",
-            pyparsing_unicode.Japanese.Kanji)
-    setattr(pyparsing_unicode.Japanese, u"",
+    setattr(pyparsing_unicode.Japanese, u"", pyparsing_unicode.Japanese.Kanji)
+    setattr(pyparsing_unicode.Japanese,
+            u"",
             pyparsing_unicode.Japanese.Katakana)
-    setattr(pyparsing_unicode.Japanese, u"",
+    setattr(pyparsing_unicode.Japanese,
+            u"",
             pyparsing_unicode.Japanese.Hiragana)
     setattr(pyparsing_unicode, u"", pyparsing_unicode.Korean)
     setattr(pyparsing_unicode, u"", pyparsing_unicode.Thai)
@@ -7504,7 +7692,8 @@
                 "packrat_enabled"] = ParserElement._packratEnabled
             self._save_context["packrat_parse"] = ParserElement._parse
             self._save_context["__diag__"] = {
-                name: getattr(__diag__, name)
+                name: getattr(__diag__,
+                              name)
                 for name in __diag__._all_names
             }
             self._save_context["__compat__"] = {
@@ -7527,8 +7716,7 @@
             ParserElement._packratEnabled = self._save_context[
                 "packrat_enabled"]
             ParserElement._parse = self._save_context["packrat_parse"]
-            __compat__.collect_all_And_tokens = self._save_context[
-                "__compat__"]
+            __compat__.collect_all_And_tokens = self._save_context["__compat__"]
 
         def __enter__(self):
             return self.save()
@@ -7604,18 +7792,24 @@
             run_test_success, run_test_results = run_tests_report
 
             if expected_parse_results is not None:
-                merged = [(rpt[0], rpt[1], expected) for rpt, expected in zip(
-                    run_test_results, expected_parse_results)]
+                merged = [(rpt[0],
+                           rpt[1],
+                           expected) for rpt,
+                          expected in zip(run_test_results,
+                                          expected_parse_results)]
                 for test_string, result, expected in merged:
                     # expected should be a tuple containing a list and/or a dict or an exception,
                     # and optional failure message string
                     # an empty tuple will skip any result validation
                     fail_msg = next(
-                        (exp for exp in expected if isinstance(exp, str)),
+                        (exp for exp in expected if isinstance(exp,
+                                                               str)),
                         None)
                     expected_exception = next(
-                        (exp for exp in expected if isinstance(exp, type)
-                         and issubclass(exp, Exception)),
+                        (exp for exp in expected
+                         if isinstance(exp,
+                                       type) and issubclass(exp,
+                                                            Exception)),
                         None,
                     )
                     if expected_exception is not None:
@@ -7626,10 +7820,12 @@
                                 raise result
                     else:
                         expected_list = next(
-                            (exp for exp in expected if isinstance(exp, list)),
+                            (exp for exp in expected if isinstance(exp,
+                                                                   list)),
                             None)
                         expected_dict = next(
-                            (exp for exp in expected if isinstance(exp, dict)),
+                            (exp for exp in expected if isinstance(exp,
+                                                                   dict)),
                             None)
                         if (expected_list, expected_dict) != (None, None):
                             self.assertParseResultsEquals(
@@ -7647,9 +7843,7 @@
                             msg=msg if msg is not None else "failed runTests")
 
         @contextmanager
-        def assertRaisesParseException(self,
-                                       exc_type=ParseException,
-                                       msg=None):
+        def assertRaisesParseException(self, exc_type=ParseException, msg=None):
             with self.assertRaises(exc_type, msg=msg):
                 yield
 
@@ -7661,12 +7855,14 @@
 
     ident = Word(alphas, alphanums + "_$")
 
-    columnName = delimitedList(ident, ".",
+    columnName = delimitedList(ident,
+                               ".",
                                combine=True).setParseAction(upcaseTokens)
     columnNameList = Group(delimitedList(columnName)).setName("columns")
     columnSpec = ('*' | columnNameList)
 
-    tableName = delimitedList(ident, ".",
+    tableName = delimitedList(ident,
+                              ".",
                               combine=True).setParseAction(upcaseTokens)
     tableNameList = Group(delimitedList(tableName)).setName("tables")
 
--- .\env\Lib\site-packages\six.py	(original)
+++ .\env\Lib\site-packages\six.py	(reformatted)
@@ -226,93 +226,229 @@
 
 
 _moved_attributes = [
-    MovedAttribute("cStringIO", "cStringIO", "io", "StringIO"),
-    MovedAttribute("filter", "itertools", "builtins", "ifilter", "filter"),
-    MovedAttribute("filterfalse", "itertools", "itertools", "ifilterfalse",
+    MovedAttribute("cStringIO",
+                   "cStringIO",
+                   "io",
+                   "StringIO"),
+    MovedAttribute("filter",
+                   "itertools",
+                   "builtins",
+                   "ifilter",
+                   "filter"),
+    MovedAttribute("filterfalse",
+                   "itertools",
+                   "itertools",
+                   "ifilterfalse",
                    "filterfalse"),
-    MovedAttribute("input", "__builtin__", "builtins", "raw_input", "input"),
-    MovedAttribute("intern", "__builtin__", "sys"),
-    MovedAttribute("map", "itertools", "builtins", "imap", "map"),
-    MovedAttribute("getcwd", "os", "os", "getcwdu", "getcwd"),
-    MovedAttribute("getcwdb", "os", "os", "getcwd", "getcwdb"),
-    MovedAttribute("getoutput", "commands", "subprocess"),
-    MovedAttribute("range", "__builtin__", "builtins", "xrange", "range"),
-    MovedAttribute("reload_module", "__builtin__",
-                   "importlib" if PY34 else "imp", "reload"),
-    MovedAttribute("reduce", "__builtin__", "functools"),
-    MovedAttribute("shlex_quote", "pipes", "shlex", "quote"),
-    MovedAttribute("StringIO", "StringIO", "io"),
-    MovedAttribute("UserDict", "UserDict", "collections"),
-    MovedAttribute("UserList", "UserList", "collections"),
-    MovedAttribute("UserString", "UserString", "collections"),
-    MovedAttribute("xrange", "__builtin__", "builtins", "xrange", "range"),
-    MovedAttribute("zip", "itertools", "builtins", "izip", "zip"),
-    MovedAttribute("zip_longest", "itertools", "itertools", "izip_longest",
+    MovedAttribute("input",
+                   "__builtin__",
+                   "builtins",
+                   "raw_input",
+                   "input"),
+    MovedAttribute("intern",
+                   "__builtin__",
+                   "sys"),
+    MovedAttribute("map",
+                   "itertools",
+                   "builtins",
+                   "imap",
+                   "map"),
+    MovedAttribute("getcwd",
+                   "os",
+                   "os",
+                   "getcwdu",
+                   "getcwd"),
+    MovedAttribute("getcwdb",
+                   "os",
+                   "os",
+                   "getcwd",
+                   "getcwdb"),
+    MovedAttribute("getoutput",
+                   "commands",
+                   "subprocess"),
+    MovedAttribute("range",
+                   "__builtin__",
+                   "builtins",
+                   "xrange",
+                   "range"),
+    MovedAttribute("reload_module",
+                   "__builtin__",
+                   "importlib" if PY34 else "imp",
+                   "reload"),
+    MovedAttribute("reduce",
+                   "__builtin__",
+                   "functools"),
+    MovedAttribute("shlex_quote",
+                   "pipes",
+                   "shlex",
+                   "quote"),
+    MovedAttribute("StringIO",
+                   "StringIO",
+                   "io"),
+    MovedAttribute("UserDict",
+                   "UserDict",
+                   "collections"),
+    MovedAttribute("UserList",
+                   "UserList",
+                   "collections"),
+    MovedAttribute("UserString",
+                   "UserString",
+                   "collections"),
+    MovedAttribute("xrange",
+                   "__builtin__",
+                   "builtins",
+                   "xrange",
+                   "range"),
+    MovedAttribute("zip",
+                   "itertools",
+                   "builtins",
+                   "izip",
+                   "zip"),
+    MovedAttribute("zip_longest",
+                   "itertools",
+                   "itertools",
+                   "izip_longest",
                    "zip_longest"),
-    MovedModule("builtins", "__builtin__"),
-    MovedModule("configparser", "ConfigParser"),
+    MovedModule("builtins",
+                "__builtin__"),
+    MovedModule("configparser",
+                "ConfigParser"),
     MovedModule(
-        "collections_abc", "collections",
-        "collections.abc" if sys.version_info >= (3, 3) else "collections"),
-    MovedModule("copyreg", "copy_reg"),
-    MovedModule("dbm_gnu", "gdbm", "dbm.gnu"),
-    MovedModule("dbm_ndbm", "dbm", "dbm.ndbm"),
-    MovedModule("_dummy_thread", "dummy_thread",
-                "_dummy_thread" if sys.version_info < (3, 9) else "_thread"),
-    MovedModule("http_cookiejar", "cookielib", "http.cookiejar"),
-    MovedModule("http_cookies", "Cookie", "http.cookies"),
-    MovedModule("html_entities", "htmlentitydefs", "html.entities"),
-    MovedModule("html_parser", "HTMLParser", "html.parser"),
-    MovedModule("http_client", "httplib", "http.client"),
-    MovedModule("email_mime_base", "email.MIMEBase", "email.mime.base"),
-    MovedModule("email_mime_image", "email.MIMEImage", "email.mime.image"),
-    MovedModule("email_mime_multipart", "email.MIMEMultipart",
+        "collections_abc",
+        "collections",
+        "collections.abc" if sys.version_info >= (3,
+                                                  3) else "collections"),
+    MovedModule("copyreg",
+                "copy_reg"),
+    MovedModule("dbm_gnu",
+                "gdbm",
+                "dbm.gnu"),
+    MovedModule("dbm_ndbm",
+                "dbm",
+                "dbm.ndbm"),
+    MovedModule("_dummy_thread",
+                "dummy_thread",
+                "_dummy_thread" if sys.version_info < (3,
+                                                       9) else "_thread"),
+    MovedModule("http_cookiejar",
+                "cookielib",
+                "http.cookiejar"),
+    MovedModule("http_cookies",
+                "Cookie",
+                "http.cookies"),
+    MovedModule("html_entities",
+                "htmlentitydefs",
+                "html.entities"),
+    MovedModule("html_parser",
+                "HTMLParser",
+                "html.parser"),
+    MovedModule("http_client",
+                "httplib",
+                "http.client"),
+    MovedModule("email_mime_base",
+                "email.MIMEBase",
+                "email.mime.base"),
+    MovedModule("email_mime_image",
+                "email.MIMEImage",
+                "email.mime.image"),
+    MovedModule("email_mime_multipart",
+                "email.MIMEMultipart",
                 "email.mime.multipart"),
-    MovedModule("email_mime_nonmultipart", "email.MIMENonMultipart",
+    MovedModule("email_mime_nonmultipart",
+                "email.MIMENonMultipart",
                 "email.mime.nonmultipart"),
-    MovedModule("email_mime_text", "email.MIMEText", "email.mime.text"),
-    MovedModule("BaseHTTPServer", "BaseHTTPServer", "http.server"),
-    MovedModule("CGIHTTPServer", "CGIHTTPServer", "http.server"),
-    MovedModule("SimpleHTTPServer", "SimpleHTTPServer", "http.server"),
-    MovedModule("cPickle", "cPickle", "pickle"),
-    MovedModule("queue", "Queue"),
-    MovedModule("reprlib", "repr"),
-    MovedModule("socketserver", "SocketServer"),
-    MovedModule("_thread", "thread", "_thread"),
-    MovedModule("tkinter", "Tkinter"),
-    MovedModule("tkinter_dialog", "Dialog", "tkinter.dialog"),
-    MovedModule("tkinter_filedialog", "FileDialog", "tkinter.filedialog"),
-    MovedModule("tkinter_scrolledtext", "ScrolledText",
+    MovedModule("email_mime_text",
+                "email.MIMEText",
+                "email.mime.text"),
+    MovedModule("BaseHTTPServer",
+                "BaseHTTPServer",
+                "http.server"),
+    MovedModule("CGIHTTPServer",
+                "CGIHTTPServer",
+                "http.server"),
+    MovedModule("SimpleHTTPServer",
+                "SimpleHTTPServer",
+                "http.server"),
+    MovedModule("cPickle",
+                "cPickle",
+                "pickle"),
+    MovedModule("queue",
+                "Queue"),
+    MovedModule("reprlib",
+                "repr"),
+    MovedModule("socketserver",
+                "SocketServer"),
+    MovedModule("_thread",
+                "thread",
+                "_thread"),
+    MovedModule("tkinter",
+                "Tkinter"),
+    MovedModule("tkinter_dialog",
+                "Dialog",
+                "tkinter.dialog"),
+    MovedModule("tkinter_filedialog",
+                "FileDialog",
+                "tkinter.filedialog"),
+    MovedModule("tkinter_scrolledtext",
+                "ScrolledText",
                 "tkinter.scrolledtext"),
-    MovedModule("tkinter_simpledialog", "SimpleDialog",
+    MovedModule("tkinter_simpledialog",
+                "SimpleDialog",
                 "tkinter.simpledialog"),
-    MovedModule("tkinter_tix", "Tix", "tkinter.tix"),
-    MovedModule("tkinter_ttk", "ttk", "tkinter.ttk"),
-    MovedModule("tkinter_constants", "Tkconstants", "tkinter.constants"),
-    MovedModule("tkinter_dnd", "Tkdnd", "tkinter.dnd"),
-    MovedModule("tkinter_colorchooser", "tkColorChooser",
+    MovedModule("tkinter_tix",
+                "Tix",
+                "tkinter.tix"),
+    MovedModule("tkinter_ttk",
+                "ttk",
+                "tkinter.ttk"),
+    MovedModule("tkinter_constants",
+                "Tkconstants",
+                "tkinter.constants"),
+    MovedModule("tkinter_dnd",
+                "Tkdnd",
+                "tkinter.dnd"),
+    MovedModule("tkinter_colorchooser",
+                "tkColorChooser",
                 "tkinter.colorchooser"),
-    MovedModule("tkinter_commondialog", "tkCommonDialog",
+    MovedModule("tkinter_commondialog",
+                "tkCommonDialog",
                 "tkinter.commondialog"),
-    MovedModule("tkinter_tkfiledialog", "tkFileDialog", "tkinter.filedialog"),
-    MovedModule("tkinter_font", "tkFont", "tkinter.font"),
-    MovedModule("tkinter_messagebox", "tkMessageBox", "tkinter.messagebox"),
-    MovedModule("tkinter_tksimpledialog", "tkSimpleDialog",
+    MovedModule("tkinter_tkfiledialog",
+                "tkFileDialog",
+                "tkinter.filedialog"),
+    MovedModule("tkinter_font",
+                "tkFont",
+                "tkinter.font"),
+    MovedModule("tkinter_messagebox",
+                "tkMessageBox",
+                "tkinter.messagebox"),
+    MovedModule("tkinter_tksimpledialog",
+                "tkSimpleDialog",
                 "tkinter.simpledialog"),
-    MovedModule("urllib_parse", __name__ + ".moves.urllib_parse",
+    MovedModule("urllib_parse",
+                __name__ + ".moves.urllib_parse",
                 "urllib.parse"),
-    MovedModule("urllib_error", __name__ + ".moves.urllib_error",
+    MovedModule("urllib_error",
+                __name__ + ".moves.urllib_error",
                 "urllib.error"),
-    MovedModule("urllib", __name__ + ".moves.urllib",
+    MovedModule("urllib",
+                __name__ + ".moves.urllib",
                 __name__ + ".moves.urllib"),
-    MovedModule("urllib_robotparser", "robotparser", "urllib.robotparser"),
-    MovedModule("xmlrpc_client", "xmlrpclib", "xmlrpc.client"),
-    MovedModule("xmlrpc_server", "SimpleXMLRPCServer", "xmlrpc.server"),
+    MovedModule("urllib_robotparser",
+                "robotparser",
+                "urllib.robotparser"),
+    MovedModule("xmlrpc_client",
+                "xmlrpclib",
+                "xmlrpc.client"),
+    MovedModule("xmlrpc_server",
+                "SimpleXMLRPCServer",
+                "xmlrpc.server"),
 ]
 # Add windows specific modules.
 if sys.platform == "win32":
     _moved_attributes += [
-        MovedModule("winreg", "_winreg"),
+        MovedModule("winreg",
+                    "_winreg"),
     ]
 
 for attr in _moved_attributes:
@@ -332,32 +468,83 @@
 
 
 _urllib_parse_moved_attributes = [
-    MovedAttribute("ParseResult", "urlparse", "urllib.parse"),
-    MovedAttribute("SplitResult", "urlparse", "urllib.parse"),
-    MovedAttribute("parse_qs", "urlparse", "urllib.parse"),
-    MovedAttribute("parse_qsl", "urlparse", "urllib.parse"),
-    MovedAttribute("urldefrag", "urlparse", "urllib.parse"),
-    MovedAttribute("urljoin", "urlparse", "urllib.parse"),
-    MovedAttribute("urlparse", "urlparse", "urllib.parse"),
-    MovedAttribute("urlsplit", "urlparse", "urllib.parse"),
-    MovedAttribute("urlunparse", "urlparse", "urllib.parse"),
-    MovedAttribute("urlunsplit", "urlparse", "urllib.parse"),
-    MovedAttribute("quote", "urllib", "urllib.parse"),
-    MovedAttribute("quote_plus", "urllib", "urllib.parse"),
-    MovedAttribute("unquote", "urllib", "urllib.parse"),
-    MovedAttribute("unquote_plus", "urllib", "urllib.parse"),
-    MovedAttribute("unquote_to_bytes", "urllib", "urllib.parse", "unquote",
+    MovedAttribute("ParseResult",
+                   "urlparse",
+                   "urllib.parse"),
+    MovedAttribute("SplitResult",
+                   "urlparse",
+                   "urllib.parse"),
+    MovedAttribute("parse_qs",
+                   "urlparse",
+                   "urllib.parse"),
+    MovedAttribute("parse_qsl",
+                   "urlparse",
+                   "urllib.parse"),
+    MovedAttribute("urldefrag",
+                   "urlparse",
+                   "urllib.parse"),
+    MovedAttribute("urljoin",
+                   "urlparse",
+                   "urllib.parse"),
+    MovedAttribute("urlparse",
+                   "urlparse",
+                   "urllib.parse"),
+    MovedAttribute("urlsplit",
+                   "urlparse",
+                   "urllib.parse"),
+    MovedAttribute("urlunparse",
+                   "urlparse",
+                   "urllib.parse"),
+    MovedAttribute("urlunsplit",
+                   "urlparse",
+                   "urllib.parse"),
+    MovedAttribute("quote",
+                   "urllib",
+                   "urllib.parse"),
+    MovedAttribute("quote_plus",
+                   "urllib",
+                   "urllib.parse"),
+    MovedAttribute("unquote",
+                   "urllib",
+                   "urllib.parse"),
+    MovedAttribute("unquote_plus",
+                   "urllib",
+                   "urllib.parse"),
+    MovedAttribute("unquote_to_bytes",
+                   "urllib",
+                   "urllib.parse",
+                   "unquote",
                    "unquote_to_bytes"),
-    MovedAttribute("urlencode", "urllib", "urllib.parse"),
-    MovedAttribute("splitquery", "urllib", "urllib.parse"),
-    MovedAttribute("splittag", "urllib", "urllib.parse"),
-    MovedAttribute("splituser", "urllib", "urllib.parse"),
-    MovedAttribute("splitvalue", "urllib", "urllib.parse"),
-    MovedAttribute("uses_fragment", "urlparse", "urllib.parse"),
-    MovedAttribute("uses_netloc", "urlparse", "urllib.parse"),
-    MovedAttribute("uses_params", "urlparse", "urllib.parse"),
-    MovedAttribute("uses_query", "urlparse", "urllib.parse"),
-    MovedAttribute("uses_relative", "urlparse", "urllib.parse"),
+    MovedAttribute("urlencode",
+                   "urllib",
+                   "urllib.parse"),
+    MovedAttribute("splitquery",
+                   "urllib",
+                   "urllib.parse"),
+    MovedAttribute("splittag",
+                   "urllib",
+                   "urllib.parse"),
+    MovedAttribute("splituser",
+                   "urllib",
+                   "urllib.parse"),
+    MovedAttribute("splitvalue",
+                   "urllib",
+                   "urllib.parse"),
+    MovedAttribute("uses_fragment",
+                   "urlparse",
+                   "urllib.parse"),
+    MovedAttribute("uses_netloc",
+                   "urlparse",
+                   "urllib.parse"),
+    MovedAttribute("uses_params",
+                   "urlparse",
+                   "urllib.parse"),
+    MovedAttribute("uses_query",
+                   "urlparse",
+                   "urllib.parse"),
+    MovedAttribute("uses_relative",
+                   "urlparse",
+                   "urllib.parse"),
 ]
 for attr in _urllib_parse_moved_attributes:
     setattr(Module_six_moves_urllib_parse, attr.name, attr)
@@ -367,7 +554,8 @@
 
 _importer._add_module(
     Module_six_moves_urllib_parse(__name__ + ".moves.urllib_parse"),
-    "moves.urllib_parse", "moves.urllib.parse")
+    "moves.urllib_parse",
+    "moves.urllib.parse")
 
 
 class Module_six_moves_urllib_error(_LazyModule):
@@ -375,9 +563,15 @@
 
 
 _urllib_error_moved_attributes = [
-    MovedAttribute("URLError", "urllib2", "urllib.error"),
-    MovedAttribute("HTTPError", "urllib2", "urllib.error"),
-    MovedAttribute("ContentTooShortError", "urllib", "urllib.error"),
+    MovedAttribute("URLError",
+                   "urllib2",
+                   "urllib.error"),
+    MovedAttribute("HTTPError",
+                   "urllib2",
+                   "urllib.error"),
+    MovedAttribute("ContentTooShortError",
+                   "urllib",
+                   "urllib.error"),
 ]
 for attr in _urllib_error_moved_attributes:
     setattr(Module_six_moves_urllib_error, attr.name, attr)
@@ -387,7 +581,8 @@
 
 _importer._add_module(
     Module_six_moves_urllib_error(__name__ + ".moves.urllib.error"),
-    "moves.urllib_error", "moves.urllib.error")
+    "moves.urllib_error",
+    "moves.urllib.error")
 
 
 class Module_six_moves_urllib_request(_LazyModule):
@@ -395,42 +590,111 @@
 
 
 _urllib_request_moved_attributes = [
-    MovedAttribute("urlopen", "urllib2", "urllib.request"),
-    MovedAttribute("install_opener", "urllib2", "urllib.request"),
-    MovedAttribute("build_opener", "urllib2", "urllib.request"),
-    MovedAttribute("pathname2url", "urllib", "urllib.request"),
-    MovedAttribute("url2pathname", "urllib", "urllib.request"),
-    MovedAttribute("getproxies", "urllib", "urllib.request"),
-    MovedAttribute("Request", "urllib2", "urllib.request"),
-    MovedAttribute("OpenerDirector", "urllib2", "urllib.request"),
-    MovedAttribute("HTTPDefaultErrorHandler", "urllib2", "urllib.request"),
-    MovedAttribute("HTTPRedirectHandler", "urllib2", "urllib.request"),
-    MovedAttribute("HTTPCookieProcessor", "urllib2", "urllib.request"),
-    MovedAttribute("ProxyHandler", "urllib2", "urllib.request"),
-    MovedAttribute("BaseHandler", "urllib2", "urllib.request"),
-    MovedAttribute("HTTPPasswordMgr", "urllib2", "urllib.request"),
-    MovedAttribute("HTTPPasswordMgrWithDefaultRealm", "urllib2",
-                   "urllib.request"),
-    MovedAttribute("AbstractBasicAuthHandler", "urllib2", "urllib.request"),
-    MovedAttribute("HTTPBasicAuthHandler", "urllib2", "urllib.request"),
-    MovedAttribute("ProxyBasicAuthHandler", "urllib2", "urllib.request"),
-    MovedAttribute("AbstractDigestAuthHandler", "urllib2", "urllib.request"),
-    MovedAttribute("HTTPDigestAuthHandler", "urllib2", "urllib.request"),
-    MovedAttribute("ProxyDigestAuthHandler", "urllib2", "urllib.request"),
-    MovedAttribute("HTTPHandler", "urllib2", "urllib.request"),
-    MovedAttribute("HTTPSHandler", "urllib2", "urllib.request"),
-    MovedAttribute("FileHandler", "urllib2", "urllib.request"),
-    MovedAttribute("FTPHandler", "urllib2", "urllib.request"),
-    MovedAttribute("CacheFTPHandler", "urllib2", "urllib.request"),
-    MovedAttribute("UnknownHandler", "urllib2", "urllib.request"),
-    MovedAttribute("HTTPErrorProcessor", "urllib2", "urllib.request"),
-    MovedAttribute("urlretrieve", "urllib", "urllib.request"),
-    MovedAttribute("urlcleanup", "urllib", "urllib.request"),
-    MovedAttribute("URLopener", "urllib", "urllib.request"),
-    MovedAttribute("FancyURLopener", "urllib", "urllib.request"),
-    MovedAttribute("proxy_bypass", "urllib", "urllib.request"),
-    MovedAttribute("parse_http_list", "urllib2", "urllib.request"),
-    MovedAttribute("parse_keqv_list", "urllib2", "urllib.request"),
+    MovedAttribute("urlopen",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("install_opener",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("build_opener",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("pathname2url",
+                   "urllib",
+                   "urllib.request"),
+    MovedAttribute("url2pathname",
+                   "urllib",
+                   "urllib.request"),
+    MovedAttribute("getproxies",
+                   "urllib",
+                   "urllib.request"),
+    MovedAttribute("Request",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("OpenerDirector",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("HTTPDefaultErrorHandler",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("HTTPRedirectHandler",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("HTTPCookieProcessor",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("ProxyHandler",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("BaseHandler",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("HTTPPasswordMgr",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("HTTPPasswordMgrWithDefaultRealm",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("AbstractBasicAuthHandler",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("HTTPBasicAuthHandler",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("ProxyBasicAuthHandler",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("AbstractDigestAuthHandler",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("HTTPDigestAuthHandler",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("ProxyDigestAuthHandler",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("HTTPHandler",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("HTTPSHandler",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("FileHandler",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("FTPHandler",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("CacheFTPHandler",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("UnknownHandler",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("HTTPErrorProcessor",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("urlretrieve",
+                   "urllib",
+                   "urllib.request"),
+    MovedAttribute("urlcleanup",
+                   "urllib",
+                   "urllib.request"),
+    MovedAttribute("URLopener",
+                   "urllib",
+                   "urllib.request"),
+    MovedAttribute("FancyURLopener",
+                   "urllib",
+                   "urllib.request"),
+    MovedAttribute("proxy_bypass",
+                   "urllib",
+                   "urllib.request"),
+    MovedAttribute("parse_http_list",
+                   "urllib2",
+                   "urllib.request"),
+    MovedAttribute("parse_keqv_list",
+                   "urllib2",
+                   "urllib.request"),
 ]
 for attr in _urllib_request_moved_attributes:
     setattr(Module_six_moves_urllib_request, attr.name, attr)
@@ -440,7 +704,8 @@
 
 _importer._add_module(
     Module_six_moves_urllib_request(__name__ + ".moves.urllib.request"),
-    "moves.urllib_request", "moves.urllib.request")
+    "moves.urllib_request",
+    "moves.urllib.request")
 
 
 class Module_six_moves_urllib_response(_LazyModule):
@@ -448,10 +713,18 @@
 
 
 _urllib_response_moved_attributes = [
-    MovedAttribute("addbase", "urllib", "urllib.response"),
-    MovedAttribute("addclosehook", "urllib", "urllib.response"),
-    MovedAttribute("addinfo", "urllib", "urllib.response"),
-    MovedAttribute("addinfourl", "urllib", "urllib.response"),
+    MovedAttribute("addbase",
+                   "urllib",
+                   "urllib.response"),
+    MovedAttribute("addclosehook",
+                   "urllib",
+                   "urllib.response"),
+    MovedAttribute("addinfo",
+                   "urllib",
+                   "urllib.response"),
+    MovedAttribute("addinfourl",
+                   "urllib",
+                   "urllib.response"),
 ]
 for attr in _urllib_response_moved_attributes:
     setattr(Module_six_moves_urllib_response, attr.name, attr)
@@ -461,7 +734,8 @@
 
 _importer._add_module(
     Module_six_moves_urllib_response(__name__ + ".moves.urllib.response"),
-    "moves.urllib_response", "moves.urllib.response")
+    "moves.urllib_response",
+    "moves.urllib.response")
 
 
 class Module_six_moves_urllib_robotparser(_LazyModule):
@@ -469,7 +743,9 @@
 
 
 _urllib_robotparser_moved_attributes = [
-    MovedAttribute("RobotFileParser", "robotparser", "urllib.robotparser"),
+    MovedAttribute("RobotFileParser",
+                   "robotparser",
+                   "urllib.robotparser"),
 ]
 for attr in _urllib_robotparser_moved_attributes:
     setattr(Module_six_moves_urllib_robotparser, attr.name, attr)
@@ -478,9 +754,9 @@
 Module_six_moves_urllib_robotparser._moved_attributes = _urllib_robotparser_moved_attributes
 
 _importer._add_module(
-    Module_six_moves_urllib_robotparser(__name__ +
-                                        ".moves.urllib.robotparser"),
-    "moves.urllib_robotparser", "moves.urllib.robotparser")
+    Module_six_moves_urllib_robotparser(__name__ + ".moves.urllib.robotparser"),
+    "moves.urllib_robotparser",
+    "moves.urllib.robotparser")
 
 
 class Module_six_moves_urllib(types.ModuleType):
@@ -769,7 +1045,9 @@
             if not isinstance(data, basestring):
                 data = str(data)
             # If the file has an encoding, encode unicode with it.
-            if (isinstance(fp, file) and isinstance(data, unicode)
+            if (isinstance(fp,
+                           file) and isinstance(data,
+                                                unicode)
                     and fp.encoding is not None):
                 errors = getattr(fp, "errors", None)
                 if errors is None:
@@ -980,8 +1258,8 @@
     if PY2:
         if '__str__' not in klass.__dict__:
             raise ValueError("@python_2_unicode_compatible cannot be applied "
-                             "to %s because it doesn't define __str__()." %
-                             klass.__name__)
+                             "to %s because it doesn't define __str__()."
+                             % klass.__name__)
         klass.__unicode__ = klass.__str__
         klass.__str__ = lambda self: self.__unicode__().encode('utf-8')
     return klass
--- .\env\Lib\site-packages\amqp\abstract_channel.py	(original)
+++ .\env\Lib\site-packages\amqp\abstract_channel.py	(reformatted)
@@ -108,7 +108,8 @@
             # When channel.close() was called we must ignore all methods except
             # Channel.close and Channel.CloseOk
             AMQP_LOGGER.warning(IGNORED_METHOD_DURING_CHANNEL_CLOSE,
-                                method_sig, self.channel_id)
+                                method_sig,
+                                self.channel_id)
             return
 
         if content and \
@@ -122,8 +123,8 @@
         try:
             amqp_method = self._METHODS[method_sig]
         except KeyError:
-            raise AMQPNotImplementedError(
-                'Unknown AMQP method {0!r}'.format(method_sig))
+            raise AMQPNotImplementedError('Unknown AMQP method {0!r}'.format(
+                method_sig))
 
         try:
             listeners = [self._callbacks[method_sig]]
--- .\env\Lib\site-packages\amqp\basic_message.py	(original)
+++ .\env\Lib\site-packages\amqp\basic_message.py	(reformatted)
@@ -85,12 +85,34 @@
     #: Instances of this class have these attributes, which
     #: are passed back and forth as message properties between
     #: client and server
-    PROPERTIES = [('content_type', 's'), ('content_encoding', 's'),
-                  ('application_headers', 'F'), ('delivery_mode', 'o'),
-                  ('priority', 'o'), ('correlation_id', 's'),
-                  ('reply_to', 's'), ('expiration', 's'), ('message_id', 's'),
-                  ('timestamp', 'L'), ('type', 's'), ('user_id', 's'),
-                  ('app_id', 's'), ('cluster_id', 's')]
+    PROPERTIES = [('content_type',
+                   's'),
+                  ('content_encoding',
+                   's'),
+                  ('application_headers',
+                   'F'),
+                  ('delivery_mode',
+                   'o'),
+                  ('priority',
+                   'o'),
+                  ('correlation_id',
+                   's'),
+                  ('reply_to',
+                   's'),
+                  ('expiration',
+                   's'),
+                  ('message_id',
+                   's'),
+                  ('timestamp',
+                   'L'),
+                  ('type',
+                   's'),
+                  ('user_id',
+                   's'),
+                  ('app_id',
+                   's'),
+                  ('cluster_id',
+                   's')]
 
     def __init__(self, body='', children=None, channel=None, **properties):
         super(Message, self).__init__(**properties)
--- .\env\Lib\site-packages\amqp\channel.py	(original)
+++ .\env\Lib\site-packages\amqp\channel.py	(reformatted)
@@ -10,8 +10,11 @@
 
 from . import spec
 from .abstract_channel import AbstractChannel
-from .exceptions import (ChannelError, ConsumerCancelled, MessageNacked,
-                         RecoverableChannelError, RecoverableConnectionError,
+from .exceptions import (ChannelError,
+                         ConsumerCancelled,
+                         MessageNacked,
+                         RecoverableChannelError,
+                         RecoverableConnectionError,
                          error_for_code)
 from .five import Queue
 from .protocol import queue_declare_ok_t
@@ -59,10 +62,13 @@
     """
 
     _METHODS = {
-        spec.method(spec.Channel.Close, 'BsBB'),
+        spec.method(spec.Channel.Close,
+                    'BsBB'),
         spec.method(spec.Channel.CloseOk),
-        spec.method(spec.Channel.Flow, 'b'),
-        spec.method(spec.Channel.FlowOk, 'b'),
+        spec.method(spec.Channel.Flow,
+                    'b'),
+        spec.method(spec.Channel.FlowOk,
+                    'b'),
         spec.method(spec.Channel.OpenOk),
         spec.method(spec.Exchange.DeclareOk),
         spec.method(spec.Exchange.DeleteOk),
@@ -70,24 +76,39 @@
         spec.method(spec.Exchange.UnbindOk),
         spec.method(spec.Queue.BindOk),
         spec.method(spec.Queue.UnbindOk),
-        spec.method(spec.Queue.DeclareOk, 'sll'),
-        spec.method(spec.Queue.DeleteOk, 'l'),
-        spec.method(spec.Queue.PurgeOk, 'l'),
-        spec.method(spec.Basic.Cancel, 's'),
-        spec.method(spec.Basic.CancelOk, 's'),
-        spec.method(spec.Basic.ConsumeOk, 's'),
-        spec.method(spec.Basic.Deliver, 'sLbss', content=True),
-        spec.method(spec.Basic.GetEmpty, 's'),
-        spec.method(spec.Basic.GetOk, 'Lbssl', content=True),
+        spec.method(spec.Queue.DeclareOk,
+                    'sll'),
+        spec.method(spec.Queue.DeleteOk,
+                    'l'),
+        spec.method(spec.Queue.PurgeOk,
+                    'l'),
+        spec.method(spec.Basic.Cancel,
+                    's'),
+        spec.method(spec.Basic.CancelOk,
+                    's'),
+        spec.method(spec.Basic.ConsumeOk,
+                    's'),
+        spec.method(spec.Basic.Deliver,
+                    'sLbss',
+                    content=True),
+        spec.method(spec.Basic.GetEmpty,
+                    's'),
+        spec.method(spec.Basic.GetOk,
+                    'Lbssl',
+                    content=True),
         spec.method(spec.Basic.QosOk),
         spec.method(spec.Basic.RecoverOk),
-        spec.method(spec.Basic.Return, 'Bsss', content=True),
+        spec.method(spec.Basic.Return,
+                    'Bsss',
+                    content=True),
         spec.method(spec.Tx.CommitOk),
         spec.method(spec.Tx.RollbackOk),
         spec.method(spec.Tx.SelectOk),
         spec.method(spec.Confirm.SelectOk),
-        spec.method(spec.Basic.Ack, 'Lb'),
-        spec.method(spec.Basic.Nack, 'Lb'),
+        spec.method(spec.Basic.Ack,
+                    'Lb'),
+        spec.method(spec.Basic.Nack,
+                    'Lb'),
     }
     _METHODS = {m.method_sig: m for m in _METHODS}
 
@@ -165,7 +186,8 @@
     def close(self,
               reply_code=0,
               reply_text='',
-              method_sig=(0, 0),
+              method_sig=(0,
+                          0),
               argsig='BsBB'):
         """Request a channel close.
 
@@ -222,7 +244,10 @@
             return self.send_method(
                 spec.Channel.Close,
                 argsig,
-                (reply_code, reply_text, method_sig[0], method_sig[1]),
+                (reply_code,
+                 reply_text,
+                 method_sig[0],
+                 method_sig[1]),
                 wait=spec.Channel.CloseOk,
             )
         finally:
@@ -281,7 +306,8 @@
             raise error_for_code(
                 reply_code,
                 reply_text,
-                (class_id, method_id),
+                (class_id,
+                 method_id),
                 ChannelError,
             )
 
@@ -348,7 +374,8 @@
         return self.send_method(
             spec.Channel.Flow,
             'b',
-            (active, ),
+            (active,
+             ),
             wait=spec.Channel.FlowOk,
         )
 
@@ -442,7 +469,8 @@
         return self.send_method(
             spec.Channel.Open,
             's',
-            ('', ),
+            ('',
+             ),
             wait=spec.Channel.OpenOk,
         )
 
@@ -627,7 +655,14 @@
         self.send_method(
             spec.Exchange.Declare,
             argsig,
-            (0, exchange, type, passive, durable, auto_delete, False, nowait,
+            (0,
+             exchange,
+             type,
+             passive,
+             durable,
+             auto_delete,
+             False,
+             nowait,
              arguments),
             wait=None if nowait else spec.Exchange.DeclareOk,
         )
@@ -681,7 +716,10 @@
         return self.send_method(
             spec.Exchange.Delete,
             argsig,
-            (0, exchange, if_unused, nowait),
+            (0,
+             exchange,
+             if_unused,
+             nowait),
             wait=None if nowait else spec.Exchange.DeleteOk,
         )
 
@@ -765,7 +803,12 @@
         return self.send_method(
             spec.Exchange.Bind,
             argsig,
-            (0, destination, source, routing_key, nowait, arguments),
+            (0,
+             destination,
+             source,
+             routing_key,
+             nowait,
+             arguments),
             wait=None if nowait else spec.Exchange.BindOk,
         )
 
@@ -828,7 +871,12 @@
         return self.send_method(
             spec.Exchange.Unbind,
             argsig,
-            (0, destination, source, routing_key, nowait, arguments),
+            (0,
+             destination,
+             source,
+             routing_key,
+             nowait,
+             arguments),
             wait=None if nowait else spec.Exchange.UnbindOk,
         )
 
@@ -965,7 +1013,12 @@
         return self.send_method(
             spec.Queue.Bind,
             argsig,
-            (0, queue, exchange, routing_key, nowait, arguments),
+            (0,
+             queue,
+             exchange,
+             routing_key,
+             nowait,
+             arguments),
             wait=None if nowait else spec.Queue.BindOk,
         )
 
@@ -1028,7 +1081,11 @@
         return self.send_method(
             spec.Queue.Unbind,
             argsig,
-            (0, queue, exchange, routing_key, arguments),
+            (0,
+             queue,
+             exchange,
+             routing_key,
+             arguments),
             wait=None if nowait else spec.Queue.UnbindOk,
         )
 
@@ -1195,7 +1252,13 @@
         self.send_method(
             spec.Queue.Declare,
             argsig,
-            (0, queue, passive, durable, exclusive, auto_delete, nowait,
+            (0,
+             queue,
+             passive,
+             durable,
+             exclusive,
+             auto_delete,
+             nowait,
              arguments),
         )
         if not nowait:
@@ -1279,7 +1342,11 @@
         return self.send_method(
             spec.Queue.Delete,
             argsig,
-            (0, queue, if_unused, if_empty, nowait),
+            (0,
+             queue,
+             if_unused,
+             if_empty,
+             nowait),
             wait=None if nowait else spec.Queue.DeleteOk,
         )
 
@@ -1341,7 +1408,9 @@
         return self.send_method(
             spec.Queue.Purge,
             argsig,
-            (0, queue, nowait),
+            (0,
+             queue,
+             nowait),
             wait=None if nowait else spec.Queue.PurgeOk,
         )
 
@@ -1454,7 +1523,8 @@
         return self.send_method(
             spec.Basic.Ack,
             argsig,
-            (delivery_tag, multiple),
+            (delivery_tag,
+             multiple),
         )
 
     def basic_cancel(self, consumer_tag, nowait=False, argsig='sb'):
@@ -1501,7 +1571,8 @@
             return self.send_method(
                 spec.Basic.Cancel,
                 argsig,
-                (consumer_tag, nowait),
+                (consumer_tag,
+                 nowait),
                 wait=None if nowait else spec.Basic.CancelOk,
             )
 
@@ -1630,8 +1701,15 @@
                 be set to True in that case.
         """
         p = self.send_method(spec.Basic.Consume,
-                             argsig, (0, queue, consumer_tag, no_local, no_ack,
-                                      exclusive, nowait, arguments),
+                             argsig,
+                             (0,
+                              queue,
+                              consumer_tag,
+                              no_local,
+                              no_ack,
+                              exclusive,
+                              nowait,
+                              arguments),
                              wait=None if nowait else spec.Basic.ConsumeOk,
                              returns_tuple=True)
 
@@ -1659,8 +1737,13 @@
         else:
             return p
 
-    def _on_basic_deliver(self, consumer_tag, delivery_tag, redelivered,
-                          exchange, routing_key, msg):
+    def _on_basic_deliver(self,
+                          consumer_tag,
+                          delivery_tag,
+                          redelivered,
+                          exchange,
+                          routing_key,
+                          msg):
         msg.channel = self
         msg.delivery_info = {
             'consumer_tag': consumer_tag,
@@ -1724,8 +1807,11 @@
         ret = self.send_method(
             spec.Basic.Get,
             argsig,
-            (0, queue, no_ack),
-            wait=[spec.Basic.GetOk, spec.Basic.GetEmpty],
+            (0,
+             queue,
+             no_ack),
+            wait=[spec.Basic.GetOk,
+                  spec.Basic.GetEmpty],
             returns_tuple=True,
         )
         if not ret or len(ret) < 2:
@@ -1735,8 +1821,13 @@
     def _on_get_empty(self, cluster_id=None):
         pass
 
-    def _on_get_ok(self, delivery_tag, redelivered, exchange, routing_key,
-                   message_count, msg):
+    def _on_get_ok(self,
+                   delivery_tag,
+                   redelivered,
+                   exchange,
+                   routing_key,
+                   message_count,
+                   msg):
         msg.channel = self
         msg.delivery_info = {
             'delivery_tag': delivery_tag,
@@ -1825,8 +1916,7 @@
                     The server SHOULD implement the immediate flag.
         """
         if not self.connection:
-            raise RecoverableConnectionError(
-                'basic_publish: connection closed')
+            raise RecoverableConnectionError('basic_publish: connection closed')
 
         capabilities = self.connection.\
             client_properties.get('capabilities', {})
@@ -1839,9 +1929,14 @@
 
         try:
             with self.connection.transport.having_timeout(timeout):
-                return self.send_method(
-                    spec.Basic.Publish, argsig,
-                    (0, exchange, routing_key, mandatory, immediate), msg)
+                return self.send_method(spec.Basic.Publish,
+                                        argsig,
+                                        (0,
+                                         exchange,
+                                         routing_key,
+                                         mandatory,
+                                         immediate),
+                                        msg)
         except socket.timeout:
             raise RecoverableChannelError('basic_publish: timed out')
 
@@ -1932,7 +2027,9 @@
         return self.send_method(
             spec.Basic.Qos,
             argsig,
-            (prefetch_size, prefetch_count, a_global),
+            (prefetch_size,
+             prefetch_count,
+             a_global),
             wait=spec.Basic.QosOk,
         )
 
@@ -2042,10 +2139,15 @@
         return self.send_method(
             spec.Basic.Reject,
             argsig,
-            (delivery_tag, requeue),
+            (delivery_tag,
+             requeue),
         )
 
-    def _on_basic_return(self, reply_code, reply_text, exchange, routing_key,
+    def _on_basic_return(self,
+                         reply_code,
+                         reply_text,
+                         exchange,
+                         routing_key,
                          message):
         """Return a failed message.
 
@@ -2161,7 +2263,8 @@
         return self.send_method(
             spec.Confirm.Select,
             'b',
-            (nowait, ),
+            (nowait,
+             ),
             wait=None if nowait else spec.Confirm.SelectOk,
         )
 
